{"version":3,"sources":["components/title.js","components/description.js","components/button.js","components/canvas.js","logic/mnist.js","logic/matrix.js","logic/ffnn/ffnn-helpers.js","logic/utils.js","logic/ffnn/ffnn.js","logic/cnn/conv.js","logic/cnn/maxpool.js","logic/cnn/softmax.js","logic/cnn/cnn.js","App.js","serviceWorker.js","index.js"],"names":["Title","text","Description","split","map","index","Fragment","key","defaultProps","Button","value","onClick","className","type","e","target","blur","Canvas","findxy","res","isTouch","currX","touches","clientX","canvas","getBoundingClientRect","left","currY","clientY","top","ctx","beginPath","lineWidth","arc","LINE_WIDTH","Math","PI","stroke","closePath","fill","paths","push","paintFlag","prevX","prevY","currPath","length","draw","x1","y1","x2","y2","strokeStyle","lineCap","lineJoin","moveTo","lineTo","erase","clearRect","width","height","ctx28","canvas28","imageDataToGrayscale","imgData","grayscaleImg","y","x","offset","data","getBoundingRect","img","threshold","rows","columns","minX","minY","maxX","maxY","centerImage","meanX","meanY","sumPixels","pixel","transX","round","transY","predict","getImageData","boundingRect","trans","canvasCopy","document","createElement","copyCtx","getContext","brW","brH","scaling","translate","scale","p","i","nnInput","Array","mean","v","h","block","newVal","putImageData","this","getElementById","addEventListener","body","preventDefault","passive","id","toString","style","border","borderRadius","backgroundColor","Component","loadMNIST","Matrix","cols","matrix","j","console","log","arr","_","func","random","u","sqrt","cos","table","w","region","r","c","max","Number","NEGATIVE_INFINITY","maxR","maxC","matrix1","matrix2","sum","k","ReLUActivation","z","z_i","SoftmaxActivation","exp","softmax","fn","mul","a_i","EPSILON","BinaryCrossEntropyLoss","a","yIsOne","transpose","yIsZero","y_i","outputActivationFunction","sub","div","derivative","shuffle","randomIndex","floor","temp","FFNN","sizes","ffnn","hiddenActivationFunction","lossFunction","numLayers","size","biases","bias","weights","weight","hasOwnProperty","trainMean","trainSTD","b","randomizeNormal","input","output","add","toArray","trainDatas","epochs","miniBatchSize","learningRate","regularization","testDatas","trainDataSize","miniBatches","miniBatch","updateMiniBatch","accuracy","JSON","stringify","biasesGradient","createEmptyGradient","weightsGradient","trainData","targetOutput","gradientDelta","backprop","biasesGradientDelta","weightsGradientDelta","learningRateWithAvg","zs","activations","forward","outputError","hiddenError","nextWeightsTranspose","hiddenActivationFunctionDerivative","gradient","targetMatrix","gradientMatrix","count","testData","outputArr","targetOutputArr","indexOf","datas","cost","vectorFromArray","squaredWeights","weightOrBias","epsilon","gradApprox","original","outputPlus","lossPlus","outputMinus","lossMinus","gradApproxVal","paramSum","paramApproxSum","errorSum","gradientVal","valDatas","miniBatchOptions","learningRateOptions","regularizationOptions","bestMiniBatch","bestLearningRate","bestRegularization","bestAccuracy","bestNetwork","curMiniBatch","curLearningRate","curRegularization","curNetwork","stochasticGradientDescent","valAccuracy","generalizationAccuracy","Conv","numFilters","filterSize","conv","filters","filter","image","f","getRegion","lastInput","outputs","iterateRegions","dLdOut","dLdFilters","dLdFilter","MaxPool","poolSize","pool","s","newH","newW","channel","dLdInputs","dLdInput","Softmax","inputLen","nodes","lastInputShape","flattened","flattenedCol","lastZ","correctI","zExp","zExpCorrect","S","dOutdZ","dZdW","dZdInputs","dLdZ","dLdW","dLdB","channels","dLdInputsReshaped","dLdInputChannel","CNN","cnn","out","epoch","loss","numCorrect","label","labelNum","l","acc","test","outMax","numTests","App","props","handlePredict","undefined","inputArr","canvasRef","current","ffnnInput","cnnInput","matrixFromArray","ffnnOutputArr","ffnnPred","cnnOutputArr","cnnPred","setState","handleClear","state","ffnnModel","cnnModel","React","createRef","showSamples","samples","sampleImages","mnist","testImages","testLabels","from","createImageData","mnistSamples","images","labels","isFFNN","targetInt","targetArr","std","ffnnTrainDatas","col","row","ffnnProbs","prob","toFixed","cnnProbs","ref","href","bannerColor","octoColor","Boolean","window","location","hostname","match","ReactDOM","render","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"u+85BAWeA,EARD,SAAC,GAAc,IAAZC,EAAW,EAAXA,KACf,OAAO,4BAAKA,ICDRC,EAAc,SAAC,GAAc,IAAZD,EAAW,EAAXA,KASrB,OAAO,4BAAmBA,EAPjBE,MAAM,MAAMC,KAAI,SAACH,EAAMI,GAAP,OACrB,kBAAC,IAAMC,SAAP,CAAgBC,IAAG,UAAKN,EAAL,YAAaI,IAC7BJ,EACD,mCAORC,EAAYM,aAAe,CACzBP,KAAM,uBAOOC,QCEAO,EAtBA,SAAC,GAAwB,IAAtBC,EAAqB,EAArBA,MAAOC,EAAc,EAAdA,QAMvB,OACE,4BACEC,UAAU,yBACVC,KAAK,SACLF,QATkB,SAACG,GACrBA,EAAEC,OAAOC,OACTL,MASGD,IC+XQO,E,4MAjSbC,OAAS,SAACC,EAAKL,EAAGM,GA+BhB,GA9BY,SAARD,IAEF,EAAKE,OACFD,EAAUN,EAAEQ,QAAQ,GAAGC,QAAUT,EAAES,SACpC,EAAKC,OAAOC,wBAAwBC,KACtC,EAAKC,OACFP,EAAUN,EAAEQ,QAAQ,GAAGM,QAAUd,EAAEc,SACpC,EAAKJ,OAAOC,wBAAwBI,IAGtC,EAAKC,IAAIC,YACT,EAAKD,IAAIE,UAAY,EACrB,EAAKF,IAAIG,IAAI,EAAKZ,MAAO,EAAKM,MAAOO,GAAgB,EAAG,EAAIC,KAAKC,IACjE,EAAKN,IAAIO,SACT,EAAKP,IAAIQ,YACT,EAAKR,IAAIS,OAGT,EAAKC,MAAMC,KAAK,CAAC,CAAC,EAAKpB,OAAQ,CAAC,EAAKM,SAGrC,EAAKe,WAAY,GAIP,OAARvB,GAAwB,QAARA,IAClB,EAAKuB,WAAY,GAIP,SAARvB,GAAkB,EAAKuB,UAAW,CAEpC,EAAKC,MAAQ,EAAKtB,MAClB,EAAKuB,MAAQ,EAAKjB,MAGlB,EAAKN,OACFD,EAAUN,EAAEQ,QAAQ,GAAGC,QAAUT,EAAES,SACpC,EAAKC,OAAOC,wBAAwBC,KACtC,EAAKC,OACFP,EAAUN,EAAEQ,QAAQ,GAAGM,QAAUd,EAAEc,SACpC,EAAKJ,OAAOC,wBAAwBI,IAGtC,IAAMgB,EAAW,EAAKL,MAAM,EAAKA,MAAMM,OAAS,GAChDD,EAAS,GAAGJ,KAAK,EAAKpB,OACtBwB,EAAS,GAAGJ,KAAK,EAAKd,OACtB,EAAKa,MAAM,EAAKA,MAAMM,OAAS,GAAKD,EAGpC,EAAKE,KACH,EAAKjB,IA3JM,GA6JX,EAAKa,MACL,EAAKC,MACL,EAAKvB,MACL,EAAKM,S,EAMXoB,KAAO,SAACjB,EAAKE,EAAWgB,EAAIC,EAAIC,EAAIC,GAClCrB,EAAIC,YACJD,EAAIsB,YAvKM,QAwKVtB,EAAIE,UAAYA,EAChBF,EAAIuB,QAAU,QACdvB,EAAIwB,SAAW,QACfxB,EAAIyB,OAAOP,EAAIC,GACfnB,EAAI0B,OAAON,EAAIC,GACfrB,EAAIO,SACJP,EAAIQ,a,EAINmB,MAAQ,WACN,EAAK3B,IAAI4B,UAAU,EAAG,EAAG,EAAKlC,OAAOmC,MAAO,EAAKnC,OAAOoC,QACxD,EAAKpB,MAAQ,GAEb,EAAKqB,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,S,EAGhEG,qBAAuB,SAACC,GAItB,IAFA,IAAMC,EAAe,GAEZC,EAAI,EAAGA,EAAIF,EAAQJ,OAAQM,IAAK,CAEvCD,EAAaC,GAAK,GAElB,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAQL,MAAOQ,IAAK,CAEtC,IAAMC,EAAa,EAAJF,EAAQF,EAAQL,MAAQ,EAAIQ,EAM7B,IAHAH,EAAQK,KAAKD,EAAS,KAIlCJ,EAAQK,KAAKD,GAAU,KAIzBH,EAAaC,GAAGC,GAAKH,EAAQK,KAAKD,GAAU,KAKhD,OAAOH,G,EAGTK,gBAAkB,SAACC,EAAKC,GAQtB,IAPA,IAAMC,EAAOF,EAAIzB,OACX4B,EAAUH,EAAI,GAAGzB,OACnB6B,EAAOD,EACPE,EAAOH,EACPI,GAAQ,EACRC,GAAQ,EAEHZ,EAAI,EAAGA,EAAIO,EAAMP,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIO,EAASP,IAEvBI,EAAIL,GAAGC,GAAKK,IACVG,EAAOR,IAAGQ,EAAOR,GACjBU,EAAOV,IAAGU,EAAOV,GACjBS,EAAOV,IAAGU,EAAOV,GACjBY,EAAOZ,IAAGY,EAAOZ,IAK3B,MAAO,CAAEU,KAAMA,EAAMD,KAAMA,EAAMG,KAAMA,EAAMD,KAAMA,I,EAGrDE,YAAc,SAACR,GAQb,IAPA,IAAME,EAAOF,EAAIzB,OACX4B,EAAUH,EAAI,GAAGzB,OACnBkC,EAAQ,EACRC,EAAQ,EACRC,EAAY,EAGPhB,EAAI,EAAGA,EAAIO,EAAMP,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIO,EAASP,IAAK,CAChC,IAAIgB,EAAQ,EAAIZ,EAAIL,GAAGC,GACvBa,GAASb,EAAIgB,EACbF,GAASf,EAAIiB,EACbD,GAAaC,EASjB,OANAH,GAASE,EACTD,GAASC,EAKF,CAAEE,OAHAjD,KAAKkD,MAAMX,EAAU,EAAIM,GAGbM,OAFZnD,KAAKkD,MAAMZ,EAAO,EAAIQ,K,EAKjCM,QAAU,WAER,IAAIvB,EAAU,EAAKlC,IAAI0D,aAAa,EAAG,EA7Q7B,IACC,KA6QPvB,EAAe,EAAKF,qBAAqBC,GAGvCyB,EAAe,EAAKnB,gBAAgBL,EA9QnB,KAgRjByB,EAAQ,EAAKX,YAAYd,GAGzB0B,EAAaC,SAASC,cAAc,UAC1CF,EAAWhC,MAAQK,EAAQL,MAC3BgC,EAAW/B,OAASI,EAAQJ,OAC5B,IAAMkC,EAAUH,EAAWI,WAAW,MAGhCC,EAAMP,EAAaZ,KAAOY,EAAad,KAAO,EAC9CsB,EAAMR,EAAaX,KAAOW,EAAab,KAAO,EAC9CsB,EA5RS,KA4ReF,EAAMC,EAAMD,EAAMC,GAGhDH,EAAQK,UAAU,EAAK3E,OAAOmC,MAAQ,EAAG,EAAKnC,OAAOoC,OAAS,GAC9DkC,EAAQM,MAAMF,EAASA,GACvBJ,EAAQK,WAAW,EAAK3E,OAAOmC,MAAQ,GAAI,EAAKnC,OAAOoC,OAAS,GAGhEkC,EAAQK,UAAUT,EAAMN,OAAQM,EAAMJ,QAIpC,IAAK,IAAIe,EAAI,EAAGA,EAAI,EAAK7D,MAAMM,OAAQuD,IACrC,IAAK,IAAIC,EAAI,EAAGA,EAAI,EAAK9D,MAAM6D,GAAG,GAAGvD,OAAS,EAAGwD,IAAK,CACpD,IAAMtD,EAAK,EAAKR,MAAM6D,GAAG,GAAGC,GACtBrD,EAAK,EAAKT,MAAM6D,GAAG,GAAGC,GACtBpD,EAAK,EAAKV,MAAM6D,GAAG,GAAGC,EAAI,GAC1BnD,EAAK,EAAKX,MAAM6D,GAAG,GAAGC,EAAI,GAChC,EAAKvD,KAAK+C,EA5SD,GA4SuBI,EAASlD,EAAIC,EAAIC,EAAIC,GAQ3Da,EAAU8B,EAAQN,aAAa,EAAG,EAxTxB,IACC,KAwTXvB,EAAe,EAAKF,qBAAqBC,GAMzC,IAHA,IAAMuC,EAAU,IAAIC,MAAM,KAGjBtC,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAE3B,IADA,IAAIsC,EAAO,EACFC,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IACtBF,GAAQxC,EAAiB,GAAJC,EAASwC,GAAO,GAAJvC,EAASwC,GAK9CJ,EAAY,GAAJrC,EAASC,GAAK,EAAIsC,EAAO,IAMrC,EAAK5C,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,QAE9D,IAAK,IAAIM,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMyC,EAAQ,EAAK/C,MAAM2B,aAAarB,EAAGD,EAAG,EAAG,GACzC2C,EAAS,IAAMN,EAAY,GAAJrC,EAASC,GAEtCyC,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAK,IAEhB,EAAKR,MAAMiD,aAAaF,EAAOzC,EAAGD,GA8BtC,OAAOqC,G,kEA9WY,IAAD,OAClBQ,KAAKvF,OAASoE,SAASoB,eAAe,eACtCD,KAAKjF,IAAMiF,KAAKvF,OAAOuE,WAAW,MAClCgB,KAAKjD,SAAW8B,SAASoB,eAAe,YACxCD,KAAKlD,MAAQkD,KAAKjD,SAASiC,WAAW,MAGtCgB,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAEFiG,KAAKvF,OAAOyF,iBACV,WACA,SAACnG,GACC,EAAKI,OAAO,KAAMJ,GAAG,MAEvB,GAEFiG,KAAKvF,OAAOyF,iBACV,YACA,SAACnG,GACC,EAAKI,OAAO,MAAOJ,GAAG,MAExB,GAEFiG,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAIFiG,KAAKvF,OAAOyF,iBACV,cACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAEFiG,KAAKvF,OAAOyF,iBACV,YACA,SAACnG,GACC,EAAKI,OAAO,KAAMJ,GAAG,MAEvB,GAEFiG,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAIF8E,SAASsB,KAAKD,iBACZ,cACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAEbxB,SAASsB,KAAKD,iBACZ,YACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAEbxB,SAASsB,KAAKD,iBACZ,aACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAGbL,KAAKpE,MAAQ,EACboE,KAAK1F,MAAQ,EACb0F,KAAKnE,MAAQ,EACbmE,KAAKpF,MAAQ,EACboF,KAAKvE,MAAQ,GACbuE,KAAKrE,WAAY,I,+BAqRjB,OACE,4BACE2E,GAAG,cACH1D,MAhYM,KAgYO2D,WACb1D,OAhYO,KAgYQ0D,WACfC,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,e,GA3XNC,a,uCCgENC,I,wBCiPAC,E,WAtTb,WAAYpD,EAAMqD,EAAMC,GACtB,GAD+B,oBAC3BA,EAAQ,CAEVhB,KAAKtC,KAAOsD,EAAOtD,KACnBsC,KAAKe,KAAOC,EAAOD,KACnBf,KAAK1C,KAAO,GACZ,IAAK,IAAIiC,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAAK,CAClCS,KAAK1C,KAAK5B,KAAK,IACf,IAAK,IAAIuF,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BjB,KAAK1C,KAAKiC,GAAG7D,KAAKsF,EAAO1D,KAAKiC,GAAG0B,UAIrCjB,KAAKtC,KAAOA,EACZsC,KAAKe,KAAOA,EACZf,KAAK1C,KAAOmC,MAAM/B,GACflC,OACAnC,KAAI,kBAAMoG,MAAMsB,GAAMvF,KAAK,M,gDAS9BwF,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDG,QAAQC,IAAI,sCAGPnB,KAAK3G,KAAI,SAAC+D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAE3CjB,KAAK3G,KAAI,SAAC+D,GAAD,OAAOA,EAAI4D,O,0BAwBzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAIPnB,KAAK3G,KAAI,SAAC+D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAK3G,KAAI,SAAC+D,GAAD,OAAOA,EAAI4D,O,0BAwBzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAIPnB,KAAK3G,KAAI,SAAC+D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAK3G,KAAI,SAAC+D,GAAD,OAAOA,EAAI4D,O,0BA8BzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAIPnB,KAAK3G,KAAI,SAAC+D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAK3G,KAAI,SAAC+D,GAAD,OAAOA,EAAI4D,O,gCAwD3B,IADA,IAAMI,EAAM,GACH7B,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAC7B,IAAK,IAAI0B,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BG,EAAI1F,KAAKsE,KAAK1C,KAAKiC,GAAG0B,IAG1B,OAAOG,I,6BAOD,IAAD,OACL,OAAO,IAAIN,EAAOd,KAAKtC,KAAMsC,KAAKe,MAAM1H,KAAI,SAACgI,EAAG9B,EAAG0B,GAAP,OAAa,EAAK3D,KAAKiC,GAAG0B,Q,0BAQpEK,GACF,IAAK,IAAI/B,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAC7B,IAAK,IAAI0B,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BjB,KAAK1C,KAAKiC,GAAG0B,GAAKK,EAAKtB,KAAK1C,KAAKiC,GAAG0B,GAAI1B,EAAG0B,GAG/C,OAAOjB,O,kCAoBP,OAAOA,KAAK3G,KAAI,kBAAsB,EAAhB+B,KAAKmG,SAAe,O,wCAQ1C,OAAOvB,KAAK3G,KAAI,WAGd,IAFA,IAAImI,EAAI,EACJ7B,EAAI,EACK,IAAN6B,GAASA,EAAIpG,KAAKmG,SACzB,KAAa,IAAN5B,GAASA,EAAIvE,KAAKmG,SACzB,OAAOnG,KAAKqG,MAAM,EAAMrG,KAAK+F,IAAIK,IAAMpG,KAAKsG,IAAI,EAAMtG,KAAKC,GAAKsE,Q,8BAUlE,OADAuB,QAAQS,MAAM3B,KAAK1C,MACZ0C,O,gCAWC5C,EAAGD,EAAGyE,EAAGhC,GAEjB,IADA,IAAMiC,EAAS,IAAIf,EAAOlB,EAAGgC,GACpBE,EAAI,EAAGA,EAAIlC,EAAGkC,IACrB,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAGG,IACrBF,EAAOvE,KAAKwE,GAAGC,GAAK/B,KAAK1C,KAAKH,EAAI2E,GAAG1E,EAAI2E,GAG7C,OAAOF,I,4BAWP,IAHA,IAAIG,EAAMC,OAAOC,kBACbC,GAAQ,EACRC,GAAQ,EACHN,EAAI,EAAGA,EAAI9B,KAAKtC,KAAMoE,IAC7B,IAAK,IAAIC,EAAI,EAAGA,EAAI/B,KAAKe,KAAMgB,IACzB/B,KAAK1C,KAAKwE,GAAGC,GAAKC,IACpBA,EAAMhC,KAAK1C,KAAKwE,GAAGC,GACnBI,EAAOL,EACPM,EAAOL,GAIb,MAAO,CAACC,EAAKG,EAAMC,M,2BAvQVC,EAASC,GAClB,GAAID,EAAQ3E,OAAS4E,EAAQ5E,MAAQ2E,EAAQtB,OAASuB,EAAQvB,KAI9D,OAAO,IAAID,EAAOuB,EAAQ3E,KAAM2E,EAAQtB,MAAM1H,KAC5C,SAACgI,EAAG9B,EAAG0B,GAAP,OAAaoB,EAAQ/E,KAAKiC,GAAG0B,GAAKqB,EAAQhF,KAAKiC,GAAG0B,MAJlDC,QAAQC,IAAI,wC,0BAgCLkB,EAASC,GAClB,GAAID,EAAQ3E,OAAS4E,EAAQ5E,MAAQ2E,EAAQtB,OAASuB,EAAQvB,KAI9D,OAAO,IAAID,EAAOuB,EAAQ3E,KAAM2E,EAAQtB,MAAM1H,KAC5C,SAACgI,EAAG9B,EAAG0B,GAAP,OAAaoB,EAAQ/E,KAAKiC,GAAG0B,GAAKqB,EAAQhF,KAAKiC,GAAG0B,MAJlDC,QAAQC,IAAI,6C,0BAgCLkB,EAASC,GAClB,GAAID,EAAQtB,OAASuB,EAAQ5E,KAM7B,OAAO,IAAIoD,EAAOuB,EAAQ3E,KAAM4E,EAAQvB,MAAM1H,KAAI,SAACgI,EAAG9B,EAAG0B,GAEvD,IADA,IAAIsB,EAAM,EACDC,EAAI,EAAGA,EAAIH,EAAQtB,KAAMyB,IAChCD,GAAOF,EAAQ/E,KAAKiC,GAAGiD,GAAKF,EAAQhF,KAAKkF,GAAGvB,GAE9C,OAAOsB,KAVPrB,QAAQC,IACN,sE,0BAqCKkB,EAASC,GAClB,GAAID,EAAQ3E,OAAS4E,EAAQ5E,MAAQ2E,EAAQtB,OAASuB,EAAQvB,KAI9D,OAAO,IAAID,EAAOuB,EAAQ3E,KAAM2E,EAAQtB,MAAM1H,KAC5C,SAACgI,EAAG9B,EAAG0B,GAAP,OAAaoB,EAAQ/E,KAAKiC,GAAG0B,GAAKqB,EAAQhF,KAAKiC,GAAG0B,MAJlDC,QAAQC,IAAI,6C,gCAaCH,GACf,OAAO,IAAIF,EAAOE,EAAOD,KAAMC,EAAOtD,MAAMrE,KAC1C,SAACgI,EAAG9B,EAAG0B,GAAP,OAAaD,EAAO1D,KAAK2D,GAAG1B,Q,sCAST6B,GACrB,OAAO,IAAIN,EAAOM,EAAIrF,OAAQ,GAAG1C,KAAI,SAACgI,EAAG9B,GAAJ,OAAU6B,EAAI7B,Q,sCAU9B6B,EAAK1D,EAAMqD,GAChC,OAAO,IAAID,EAAOpD,EAAMqD,GAAM1H,KAAI,SAACgI,EAAG9B,EAAG0B,GAAP,OAAaG,EAAI7B,EAAIwB,EAAOE,Q,0BA6CrDD,EAAQM,GACjB,OAAO,IAAIR,EAAOE,EAAOtD,KAAMsD,EAAOD,MAAM1H,KAAI,SAACgI,EAAG9B,EAAG0B,GAAP,OAC9CK,EAAKN,EAAO1D,KAAKiC,GAAG0B,GAAI1B,EAAG0B,U,KCtNpBwB,EAAb,gGAMYC,GACR,OAAO5B,EAAOzH,IAAIqJ,GAAG,SAACC,GAAD,OAASvH,KAAK4G,IAAI,EAAGW,QAP9C,iCAeoBD,GAChB,OAAO5B,EAAOzH,IAAIqJ,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,SAhBjD,KA8CaC,EAAb,gGAMYF,GAER,IADA,IAAIH,EAAM,EACDT,EAAI,EAAGA,EAAIY,EAAEhF,KAAMoE,IAC1BS,GAAOnH,KAAKyH,IAAIH,EAAEpF,KAAKwE,GAAG,IAE5B,OAAOhB,EAAOzH,IAAIqJ,GAAG,SAACC,GAAD,OAASvH,KAAKyH,IAAIF,GAAOJ,OAXlD,iCAmBoBG,GAChB,IAAMI,EAAUF,EAAkBG,GAAGL,GACrC,OAAOI,EAAQE,IAAIlC,EAAOzH,IAAIyJ,GAAS,SAACG,GAAD,OAAS,EAAIA,UArBxD,KA4DMC,EAAO,SAAG,IAAO,KAKVC,EAAb,gGAOYC,EAAGjG,GACX,IAAMkG,EAASvC,EAAOkC,IACpBlC,EAAOwC,UAAUnG,GACjB2D,EAAOzH,IAAI+J,GAAG,SAACH,GAEb,OAAO7H,KAAK+F,IAAI8B,EAAMC,OAGpBK,EAAUzC,EAAOkC,IACrBlC,EAAOwC,UAAUxC,EAAOzH,IAAI8D,GAAG,SAACqG,GAAD,OAAS,EAAIA,MAC5C1C,EAAOzH,IAAI+J,GAAG,SAACH,GAEb,OAAO7H,KAAK+F,IAAI,EAAI8B,EAAMC,OAG9B,QAASG,EAAO/F,KAAK,GAAG,GAAKiG,EAAQjG,KAAK,GAAG,MAtBjD,kCAiCqBoF,EAAGU,EAAGjG,EAAGsG,GAO1B,OAN2B3C,EAAO4C,IAAIN,EAAGjG,GAAGwG,IAC1C7C,EAAOzH,IAAI+J,GAAG,SAACH,GAEb,OAAOA,GAAO,EAAIA,GAAOC,MAGHF,IAAIS,EAAyBG,WAAWlB,QAxCtE,KCvIO,SAASmB,EAAQzC,GACtB,IAAK,IAAI7B,EAAI6B,EAAIrF,OAAS,EAAGwD,EAAI,EAAGA,IAAK,CACvC,IAAMuE,EAAc1I,KAAK2I,MAAM3I,KAAKmG,UAAYhC,EAAI,IAC9CyE,EAAO5C,EAAI7B,GACjB6B,EAAI7B,GAAK6B,EAAI0C,GACb1C,EAAI0C,GAAeE,EAErB,OAAO5C,ECAT,IA2kBe6C,E,WAhkBb,WAAYC,EAAOC,GAAO,IAAD,OAKvB,GALuB,oBACvBnE,KAAKoE,yBAA2B3B,EAChCzC,KAAKyD,yBAA2Bb,EAChC5C,KAAKqE,aAAelB,EAEhBgB,EAAM,CAERnE,KAAKsE,UAAYH,EAAKD,MAAMnI,OAC5BiE,KAAKkE,MAAQ,GAHL,oBAISC,EAAKD,OAJd,IAIR,2BAA6B,CAAC,IAArBK,EAAoB,QAC3BvE,KAAKkE,MAAMxI,KAAK6I,IALV,8BASRvE,KAAKwE,OAAS,GATN,oBAUSL,EAAKK,QAVd,IAUR,2BAA8B,CAAC,IAAtBC,EAAqB,QAC5BzE,KAAKwE,OAAO9I,KAAK,IAAIoF,EAAO,KAAM,KAAM2D,KAXlC,8BAeRzE,KAAK0E,QAAU,GAfP,oBAgBWP,EAAKO,SAhBhB,IAgBR,2BAAiC,CAAC,IAAzBC,EAAwB,QAC/B3E,KAAK0E,QAAQhJ,KAAK,IAAIoF,EAAO,KAAM,KAAM6D,KAjBnC,8BAqBJR,EAAKS,eAAe,eACtB5E,KAAK6E,UAAY,IAAI/D,EAAO,KAAM,KAAMqD,EAAKU,WAC7C7E,KAAK8E,SAAW,IAAIhE,EAAO,KAAM,KAAMqD,EAAKW,eAEzC,CACL9E,KAAKsE,UAAYJ,EAAMnI,OACvBiE,KAAKkE,MAAQA,EAGblE,KAAKwE,OAAS,GACd,IAAK,IAAIjF,EAAI,EAAGA,EAAI2E,EAAMnI,OAAQwD,IAAK,CACrC,IAAMkF,EAAO,IAAI3D,EAAOoD,EAAM3E,GAAI,GAE9BS,KAAKoE,2BAA6B3B,EAEpCgC,EAAKpL,KAAI,SAAC0L,GAAD,OAAO,KAEhBN,EAAKO,kBAGPhF,KAAKwE,OAAO9I,KAAK+I,GAInBzE,KAAK0E,QAAU,GACf,IArBK,eAqBInF,GACP,IAAMoF,EAAS,IAAI7D,EAAOoD,EAAM3E,GAAI2E,EAAM3E,EAAI,IAG9CoF,EAAOK,kBACH,EAAKZ,2BAA6B3B,GACpCkC,EAAOtL,KAAI,SAACuI,GAAD,OAAOA,EAAIxG,KAAKqG,KAAK,EAAIyC,EAAM3E,EAAI,OAGhD,EAAKmF,QAAQhJ,KAAKiJ,IATXpF,EAAI,EAAGA,EAAI2E,EAAMnI,OAAQwD,IAAM,EAA/BA,I,oDAmBL0F,GAGN,IAFA,IAAIC,EAASD,EAEJ1F,EAAI,EAAGA,EAAIS,KAAKsE,UAAY,EAAG/E,IAAK,CAC3C,IAAMkF,EAAOzE,KAAKwE,OAAOjF,GACnBoF,EAAS3E,KAAK0E,QAAQnF,GAGtBmD,EAAI5B,EAAOkC,IAAI2B,EAAQO,GAC7BxC,EAAEyC,IAAIV,GACNS,EACE3F,IAAMS,KAAKsE,UAAY,EACnBtE,KAAKyD,yBAAyBV,GAAGL,GACjC1C,KAAKoE,yBAAyBrB,GAAGL,GAGzC,OAAOwC,EAAOE,Y,gDAadC,EACAC,EACAC,EACAC,EACAC,GAOA,IALC,IADDC,EACA,uDADY,KAGNC,EAAgBN,EAAWtJ,OAGxBwD,EAAI,EAAGA,EAAI+F,EAAQ/F,IAAK,CAE/BsE,EAAQwB,GAIR,IADA,IAAMO,EAAc,GACX3E,EAAI,EAAGA,EAAI0E,EAAe1E,GAAKsE,EAAe,CAKrD,IAHA,IAAMM,EAAY,GAGTrD,EAAIvB,EAAGuB,EAAIvB,EAAIsE,EAAe/C,IACrCqD,EAAUnK,KAAK2J,EAAW7C,IAE5BoD,EAAYlK,KAAKmK,GAInB,IAAK,IAAI5E,EAAI,EAAGA,EAAI2E,EAAY7J,OAAQkF,IAAK,CAC3CjB,KAAK8F,gBACHF,EAAY3E,GACZuE,EACAC,EACAE,GAqBAzE,QAAQC,IACN,wBAA0BF,EAAI,GAAK,IAAM2E,EAAY7J,QAsB3D,GAAkB,OAAd2J,EAAoB,CACtB,IAAMK,EAAW/F,KAAK+F,SAASL,GAC/BxE,QAAQC,IACN,kBACG5B,EAAI,GACL,IACA+F,EACA,KACAS,EACA,IACAL,EAAU3J,OACV,KACC,IAAMgK,EAAYL,EAAU3J,OAC7B,KAKJmF,QAAQC,IAAI6E,KAAKC,UAAUjG,U,sCAYjB6F,EAAWL,EAAcC,EAAgBE,GAEvD,IAFsE,EAEhEO,EAAiBlG,KAAKmG,oBAAoBnG,KAAKwE,QAC/C4B,EAAkBpG,KAAKmG,oBAAoBnG,KAAK0E,SAHgB,cAMhDmB,GANgD,IAMtE,2BA0BE,IA1BgC,IAAzBQ,EAAwB,QACzBpB,EAAQoB,EAAU,GAClBC,EAAeD,EAAU,GACzBE,EAAgBvG,KAAKwG,SAASvB,EAAOqB,GACrCG,EAAsBF,EAAc,GACpCG,EAAuBH,EAAc,GAqBlChH,EAAI,EAAGA,EAAIS,KAAKsE,UAAY,EAAG/E,IACtC2G,EAAe3G,GAAG4F,IAAIsB,EAAoBlH,IAC1C6G,EAAgB7G,GAAG4F,IAAIuB,EAAqBnH,IAlCsB,8BAuCtE,IAAK,IAAIA,EAAI,EAAGA,EAAIS,KAAKsE,UAAY,EAAG/E,IAAK,CAC3C,IAAMoH,EAAsBnB,EAAeK,EAAU9J,OAGrDiE,KAAKwE,OAAOjF,GAAGmE,IAAIwC,EAAe3G,GAAGyD,IAAI2D,IAGzC3G,KAAK0E,QAAQnF,GAAGyD,IAAI,EAAIwC,GAAgBC,EAAiBE,IAGzD3F,KAAK0E,QAAQnF,GAAGmE,IAAI0C,EAAgB7G,GAAGyD,IAAI2D,O,+BAUtC1B,EAAOqB,GACd,IAAMJ,EAAiBlG,KAAKmG,oBAAoBnG,KAAKwE,QAC/C4B,EAAkBpG,KAAKmG,oBAAoBnG,KAAK0E,SAGhDkC,EAAK,GACLC,EAAc,CAAC5B,GACrBjF,KAAK8G,QAAQF,EAAIC,GAGjB,IAAME,EAAc/G,KAAKqE,aAAa0C,YACpCH,EAAGA,EAAG7K,OAAS,GACf8K,EAAYA,EAAY9K,OAAS,GACjCuK,EACAtG,KAAKyD,0BAIPyC,EAAeA,EAAenK,OAAS,GAAKgL,EAG5CX,EAAgBA,EAAgBrK,OAAS,GAAK+E,EAAOkC,IACnD+D,EACAjG,EAAOwC,UAAUuD,EAAYA,EAAY9K,OAAS,KAKpD,IADA,IAAIiL,EAAcD,EACTxH,EAAI,EAAGA,EAAIS,KAAKsE,UAAW/E,IAAK,CAEvC,IAAM0H,EAAuBnG,EAAOwC,UAClCtD,KAAK0E,QAAQ1E,KAAK0E,QAAQ3I,OAASwD,EAAI,IAEnC2H,EAAqClH,KAAKoE,yBAAyBR,WACvEgD,EAAGA,EAAG7K,OAASwD,IAEjByH,EAAclG,EAAOkC,IAAIiE,EAAsBD,GAAahE,IAC1DkE,GAIFhB,EAAeA,EAAenK,OAASwD,GAAKyH,EAG5CZ,EAAgBA,EAAgBrK,OAASwD,GAAKuB,EAAOkC,IACnDgE,EACAlG,EAAOwC,UAAUuD,EAAYA,EAAY9K,OAASwD,EAAI,KAI1D,MAAO,CAAC2G,EAAgBE,K,8BAQlBQ,EAAIC,GACV,IAAK,IAAItH,EAAI,EAAGA,EAAIS,KAAKsE,UAAY,EAAG/E,IAAK,CAC3C,IAAMkF,EAAOzE,KAAKwE,OAAOjF,GACnBoF,EAAS3E,KAAK0E,QAAQnF,GAGtBmD,EAAI5B,EAAOkC,IAAI2B,EAAQkC,EAAYtH,IACzCmD,EAAEyC,IAAIV,GACNmC,EAAGlL,KAAKgH,GAER,IAAMU,EACJ7D,IAAMS,KAAKsE,UAAY,EACnBtE,KAAKyD,yBAAyBV,GAAGL,GACjC1C,KAAKoE,yBAAyBrB,GAAGL,GACvCmE,EAAYnL,KAAK0H,M,0CASDhC,GAClB,IADuB,EACjB+F,EAAW,GADM,cAEE/F,GAFF,IAEvB,2BAA8B,CAAC,IAAtBgG,EAAqB,QACtBC,EAAiB,IAAIvG,EAAOsG,EAAa1J,KAAM0J,EAAarG,MAClEoG,EAASzL,KAAK2L,IAJO,8BAMvB,OAAOF,I,+BAQAzB,GACP,IADkB,EACd4B,EAAQ,EADM,cAGG5B,GAHH,IAGlB,2BAAgC,CAAC,IAAxB6B,EAAuB,QACxBtC,EAAQsC,EAAS,GACjBC,EAAYxH,KAAKxB,QAAQyG,GACzBwC,EAAkBF,EAAS,GAAGnC,UACdoC,EAAUE,QAAQtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQoM,OACxBC,EAAgBC,QAC1CtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQqM,MAKZH,KAdc,8BAkBlB,OAAOA,I,gCASCK,EAAOlC,GACf,IAD+B,EAC3BmC,EAAO,EACPN,EAAQ,EAFmB,cAKdK,GALc,IAK/B,2BAAwB,CAAC,IAAhBrK,EAAe,QAChB2H,EAAQ3H,EAAK,GACbgJ,EAAehJ,EAAK,GAEpBkK,EAAYxH,KAAKxB,QAAQyG,GACzBwC,EAAkBnB,EAAalB,UACfoC,EAAUE,QAAQtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQoM,OACxBC,EAAgBC,QAC1CtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQqM,MAKZH,IAIFM,GACE5H,KAAKqE,aAAatB,GAAGjC,EAAO+G,gBAAgBL,GAAYlB,GACxDqB,EAAM5L,OAGR,IAtBsB,EAsBlB+L,EAAiB,EAtBC,cAuBH9H,KAAK0E,SAvBF,IAuBtB,2BACE,IADgC,IAAzBC,EAAwB,QACtB7C,EAAI,EAAGA,EAAI6C,EAAOjH,KAAMoE,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI4C,EAAO5D,KAAMgB,IAC/B+F,GAAc,SAAInD,EAAOrH,KAAKwE,GAAGC,GAAM,GA1BvB,8BA8BtB6F,GAAenC,EAAiBkC,EAAM5L,OAA9B,GAAwC+L,GAnCnB,8BAsC/B,MAAO,CAACF,EAAMN,K,oCAWFH,EAAUY,EAAc9C,EAAOqB,GAK3C,IAJA,IAAMmB,EAAkBnB,EAAalB,UAC/B4C,EAAO,SAAG,IAAO,GACjBC,EAAajI,KAAKmG,oBAAoBgB,GAEnC5H,EAAI,EAAGA,EAAI0I,EAAWlM,OAAQwD,IACrC,IAAK,IAAIuC,EAAI,EAAGA,EAAImG,EAAW1I,GAAG7B,KAAMoE,IACtC,IAAK,IAAIC,EAAI,EAAGA,EAAIkG,EAAW1I,GAAGwB,KAAMgB,IAAK,CAE3C,IAAMmG,EAAWH,EAAaxI,GAAGjC,KAAKwE,GAAGC,GAGzCgG,EAAaxI,GAAGjC,KAAKwE,GAAGC,GAAKmG,EAAWF,EAGxC,IAFA,IAAMG,EAAanI,KAAKxB,QAAQyG,GAC5BmD,EAAW,EACNnH,EAAI,EAAGA,EAAIkH,EAAWpM,OAAQkF,IACrCmH,GAAY,YAAOX,EAAgBxG,GAAKkH,EAAWlH,GAAO,GAI5D8G,EAAaxI,GAAGjC,KAAKwE,GAAGC,GAAKmG,EAAWF,EAGxC,IAFA,IAAMK,EAAcrI,KAAKxB,QAAQyG,GAC7BqD,EAAY,EACPrH,EAAI,EAAGA,EAAIoH,EAAYtM,OAAQkF,IACtCqH,GAAa,YAAOb,EAAgBxG,GAAKoH,EAAYpH,GAAO,GAI9D,IAAMsH,GAAiBH,EAAWE,IAAc,EAAIN,GACpDC,EAAW1I,GAAGjC,KAAKwE,GAAGC,GAAKwG,EAG3BR,EAAaxI,GAAGjC,KAAKwE,GAAGC,GAAKmG,EAUnC,IALA,IAAIM,EAAW,EACXC,EAAiB,EACjBC,EAAW,EAGNnJ,EAAI,EAAGA,EAAI0I,EAAWlM,OAAQwD,IACrC,IAAK,IAAIuC,EAAI,EAAGA,EAAImG,EAAW1I,GAAG7B,KAAMoE,IACtC,IAAK,IAAIC,EAAI,EAAGA,EAAIkG,EAAW1I,GAAGwB,KAAMgB,IAAK,CAC3C,IAAM4G,EAAcxB,EAAS5H,GAAGjC,KAAKwE,GAAGC,GAClCwG,EAAgBN,EAAW1I,GAAGjC,KAAKwE,GAAGC,GAE5CyG,GAAQ,SAAIG,EAAe,GAC3BF,GAAc,SAAIF,EAAiB,GACnCG,GAAQ,SAAKH,EAAgBI,EAAgB,GAKnD,OACEvN,KAAKqG,KAAKiH,IAAatN,KAAKqG,KAAKgH,GAAkBrN,KAAKqG,KAAK+G,O,4CAUrCnD,EAAYuD,EAAUlD,GAWhD,IAVA,IAAMmD,EAAmB,CAAC,EAAG,GAAI,GAAI,GAAI,KACnCC,EAAsB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACnDC,EAAwB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACvDC,EAAgB,EAChBC,EAAmB,IACnBC,EAAqB,IACrBC,EAAe,EACfC,EAAc,KAGT7J,EAAI,EAAGA,EAAIsJ,EAAiB9M,OAAQwD,IAC3C,IAAK,IAAI0B,EAAI,EAAGA,EAAI6H,EAAoB/M,OAAQkF,IAC9C,IAAK,IAAIuB,EAAI,EAAGA,EAAIuG,EAAsBhN,OAAQyG,IAAK,CACrD,IAAM6G,EAAeR,EAAiBtJ,GAChC+J,EAAkBR,EAAoB7H,GACtCsI,EAAoBR,EAAsBvG,GAG1CgH,EAAa,IAAIvF,EAAK,CAAC,IAAK,GAAI,KACtCuF,EAAWC,0BACTpE,EACA,EACAgE,EACAC,EACAC,GAIF,IAAMG,EAAcF,EAAWzD,SAAS6C,GAGpCc,EAAcP,IAChBH,EAAgBK,EAChBJ,EAAmBK,EACnBJ,EAAqBK,EACrBJ,EAAeO,EACfN,EAAcI,GAMtBtI,QAAQC,IAAI,yBAA2B6H,GACvC9H,QAAQC,IAAI,uBAAyB8H,GACrC/H,QAAQC,IAAI,wBAA0B+H,GACtChI,QAAQC,IACN,wBACEgI,EACA,IACAP,EAAS7M,OACT,KACC,IAAMoN,EAAgBP,EAAS7M,OAChC,KAIJ,IAAM4N,EAAyBP,EAAYrD,SAASL,GACpDxE,QAAQC,IACN,kBACEwI,EACA,IACAjE,EAAU3J,OACV,KACC,IAAM4N,EAA0BjE,EAAU3J,OAC3C,KAIJmF,QAAQC,IAAI,gBAAiB6E,KAAKC,UAAUmD,Q,YChejCQ,E,WA1Gb,WAAYC,GAA0C,IAA9BC,EAA6B,uDAAhB,EAAGC,EAAa,uDAAN,KAC7C,GADmD,oBACtC,OAATA,EAAe,CACjB/J,KAAK6J,WAAaE,EAAKF,WACvB7J,KAAK8J,WAAaC,EAAKD,WACvB9J,KAAKgK,QAAU,GAHE,oBAKED,EAAKC,SALP,IAKjB,2BAAiC,CAAC,IAAzBC,EAAwB,QAC/BjK,KAAKgK,QAAQtO,KAAK,IAAIoF,EAAO,KAAM,KAAMmJ,KAN1B,mCAQZ,CACLjK,KAAK6J,WAAaA,EAClB7J,KAAK8J,WAAaA,EAClB9J,KAAKgK,QAAU,GAEf,IAAK,IAAIzK,EAAI,EAAGA,EAAIsK,EAAYtK,IAC9BS,KAAKgK,QAAQtO,KACX,IAAIoF,EAAOgJ,EAAYA,GACpB9E,kBACArB,IAFH,SAEOmG,EAAc,M,uEAWbI,G,+EACRtK,EAAIsK,EAAMxM,KACVkE,EAAIsI,EAAMnJ,KACVoJ,EAAInK,KAAK8J,WAEN3M,EAAI,E,YAAGA,EAAIyC,EAAIuK,EAAI,G,iBACjB/M,EAAI,E,YAAGA,EAAIwE,EAAIuI,EAAI,G,iBAC1B,O,SAAM,CAACD,EAAME,UAAUhN,EAAGD,EAAGgN,EAAGA,GAAIhN,EAAGC,G,OADVA,I,uBADFD,I,8FAYzB8H,GACNjF,KAAKqK,UAAYpF,EAEjB,IAHa,EAGPrF,EAAIqF,EAAMvH,KACVkE,EAAIqD,EAAMlE,KACVoJ,EAAInK,KAAK8J,WAETQ,EAAU,GAPH,cAUMtK,KAAKgK,SAVX,IAUb,2BAAiC,CAAC,IAAD,EAAxBC,EAAwB,QACzB/E,EAAS,IAAIpE,EAAOlB,EAAIuK,EAAI,EAAGvI,EAAIuI,EAAI,GADd,cAIJnK,KAAKuK,eAAetF,IAJhB,IAI/B,2BAEE,IAFsD,IAAD,yBAA7CpD,EAA6C,KAArC1E,EAAqC,KAAlCC,EAAkC,KAE5C0E,EAAI,EAAGA,EAAIqI,EAAGrI,IACrB,IAAK,IAAIC,EAAI,EAAGA,EAAIoI,EAAGpI,IACrBmD,EAAO5H,KAAKH,GAAGC,IAAMyE,EAAOvE,KAAKwE,GAAGC,GAAKkI,EAAO3M,KAAKwE,GAAGC,GAR/B,8BAa/BuI,EAAQ5O,KAAKwJ,IAvBF,8BA0Bb,OAAOoF,I,+BAQAE,EAAQhF,GAIf,IAHA,IAAMiF,EAAa,GAGVlL,EAAI,EAAGA,EAAIS,KAAKgK,QAAQjO,OAAQwD,IAAK,CAC5C,IAD4C,EACtC0K,EAASjK,KAAKgK,QAAQzK,GACtBmL,EAAY,IAAI5J,EAAOmJ,EAAOvM,KAAMuM,EAAOlJ,MAFL,cAKjBf,KAAKuK,eAAevK,KAAKqK,YALR,IAK5C,2BAAgE,CAAC,IAAD,yBAAtDxI,EAAsD,KAA9C1E,EAA8C,KAA3CC,EAA2C,KAE9DsN,EAAUvF,IAAItD,EAAOmB,IAAIwH,EAAOjL,GAAGjC,KAAKH,GAAGC,MAPD,8BAS5CqN,EAAW/O,KAAKgP,GAIlB,IAAK,IAAInL,EAAI,EAAGA,EAAIS,KAAKgK,QAAQjO,OAAQwD,IAAK,CAC5C,IAAM0K,EAASjK,KAAKgK,QAAQzK,GACtBmL,EAAYD,EAAWlL,GAE7B0K,EAAOvG,IAAIgH,EAAU1H,IAAIwC,S,KCJhBmF,E,WAlGb,aAAwC,IAA5BC,EAA2B,uDAAhB,EAAGC,EAAa,uDAAN,KAAM,oBAEnC7K,KAAK4K,SADM,OAATC,EACcA,EAAKD,SAELA,E,uEASJV,G,mFACRtK,EAAIsK,EAAMxM,KACVkE,EAAIsI,EAAMnJ,KACV+J,EAAI9K,KAAK4K,SAETG,EAAO3P,KAAK2I,MAAMnE,EAAIkL,GACtBE,EAAO5P,KAAK2I,MAAMnC,EAAIkJ,GAEnB3N,EAAI,E,YAAGA,EAAI4N,G,iBACT3N,EAAI,E,YAAGA,EAAI4N,G,iBAClB,O,UAAM,CAACd,EAAME,UAAUhN,EAAI0N,EAAG3N,EAAI2N,EAAGA,EAAGA,GAAI3N,EAAGC,G,QADvBA,I,uBADFD,I,8FAYpB8H,GACNjF,KAAKqK,UAAYpF,EAEjB,IAHa,EAGPrF,EAAIqF,EAAM,GAAGvH,KACbkE,EAAIqD,EAAM,GAAGlE,KACb+J,EAAI9K,KAAK4K,SAETG,EAAO3P,KAAK2I,MAAMnE,EAAIkL,GACtBE,EAAO5P,KAAK2I,MAAMnC,EAAIkJ,GAEtBR,EAAU,GAVH,cAaOrF,GAbP,IAab,2BAA2B,CAAC,IAAD,EAAlBgG,EAAkB,QACnB/F,EAAS,IAAIpE,EAAOiK,EAAMC,GADP,cAIEhL,KAAKuK,eAAeU,IAJtB,IAIzB,2BAAyD,CAAC,IAAD,yBAA/CpJ,EAA+C,KAAvC1E,EAAuC,KAApCC,EAAoC,OAElCyE,EAAOG,MAF2B,mBAEhDA,EAFgD,eAGvDkD,EAAO5H,KAAKH,GAAGC,GAAK4E,GAPG,8BAUzBsI,EAAQ5O,KAAKwJ,IAvBF,8BA0Bb,OAAOoF,I,+BAQAE,GAIP,IAHA,IAAMU,EAAY,GAGT3L,EAAI,EAAGA,EAAIS,KAAKqK,UAAUtO,OAAQwD,IAAK,CAC9C,IAD8C,EACxC0L,EAAUjL,KAAKqK,UAAU9K,GACzB4L,EAAW,IAAIrK,EAAOmK,EAAQvN,KAAMuN,EAAQlK,MAFJ,cAKnBf,KAAKuK,eAAeU,IALD,IAK9C,2BAKE,IALwD,IAAD,yBAA/CpJ,EAA+C,KAAvC1E,EAAuC,KAApCC,EAAoC,OAElCyE,EAAOG,MAF2B,mBAEhDA,EAFgD,KAK9CF,GAL8C,UAK1C,GAAGA,EAAID,EAAOnE,KAAMoE,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAOd,KAAMgB,IAC3BF,EAAOvE,KAAKwE,GAAGC,KAAOC,IACxBmJ,EAAS7N,KAAKH,EAAI6C,KAAK4K,SAAW9I,GAAG1E,EAAI4C,KAAK4K,SAAW7I,GACvDyI,EAAOjL,GAAGjC,KAAKH,GAAGC,IAdkB,8BAoB9C8N,EAAUxP,KAAKyP,GAGjB,OAAOD,M,KCgCIE,E,WA7Hb,WAAYC,EAAUC,GAAwB,IAAjBxI,EAAgB,uDAAN,KAAM,oBAC3B,OAAZA,GACF9C,KAAK0E,QAAU,IAAI5D,EAAO,KAAM,KAAMgC,EAAQ4B,SAC9C1E,KAAKwE,OAAS,IAAI1D,EAAO,KAAM,KAAMgC,EAAQ0B,UAE7CxE,KAAK0E,QAAU,IAAI5D,EAAOuK,EAAUC,GACjCtG,kBACArB,IAAI0H,GACPrL,KAAKwE,OAAS,IAAI1D,EAAO,EAAGwK,I,oDASxBrG,GACNjF,KAAKuL,eAAiB,CAACtG,EAAMlJ,OAAQkJ,EAAM,GAAGvH,KAAMuH,EAAM,GAAGlE,MAG7D,IAJa,EAIPyK,EAAY,IAAI1K,EACpB,EACAmE,EAAM,GAAGvH,KAAOuH,EAAM,GAAGlE,KAAOkE,EAAMlJ,QAEpC0P,EAAe,EARN,cAWOxG,GAXP,IAWb,2BACE,IAD0B,IAAnBgG,EAAkB,QAChBnJ,EAAI,EAAGA,EAAImJ,EAAQvN,KAAMoE,IAChC,IAAK,IAAIC,EAAI,EAAGA,EAAIkJ,EAAQlK,KAAMgB,IAChCyJ,EAAUlO,KAAK,GAAGmO,GAAgBR,EAAQ3N,KAAKwE,GAAGC,GAClD0J,IAfO,8BAmBbzL,KAAKqK,UAAYmB,EAGjB,IAAM9I,EAAI5B,EAAOkC,IAAIwI,EAAWxL,KAAK0E,SAASS,IAAInF,KAAKwE,QACvDxE,KAAK0L,MAAQhJ,EAKb,IAFA,IAAMG,EAAM/B,EAAOzH,IAAIqJ,EAAGtH,KAAKyH,KAC3BN,EAAM,EACDR,EAAI,EAAGA,EAAIc,EAAI9B,KAAMgB,IAC5BQ,GAAOM,EAAIvF,KAAK,GAAGyE,GAErB,OAAOc,EAAIc,IAAIpB,K,+BASRiI,EAAQhF,GAGf,IADA,IAAImG,EAAW,EACNpM,EAAI,EAAGA,EAAIiL,EAAOzJ,KAAMxB,IAC/B,GAA0B,IAAtBiL,EAAOlN,KAAK,GAAGiC,GAAU,CAC3BoM,EAAWpM,EACX,MAWJ,IARA,IAAM4H,EAAWqD,EAAOlN,KAAK,GAAGqO,GAG1BC,EAAO9K,EAAOzH,IAAI2G,KAAK0L,MAAOtQ,KAAKyH,KACnCgJ,EAAcD,EAAKtO,KAAK,GAAGqO,GAG7BG,EAAI,EACC/J,EAAI,EAAGA,EAAI6J,EAAK7K,KAAMgB,IAC7B+J,GAAKF,EAAKtO,KAAK,GAAGyE,GAOpB,IAAMgK,EAASH,EAAK5I,KAAK6I,EAAD,SAAeC,EAAK,IAC5CC,EAAOzO,KAAK,GAAGqO,GAAaE,GAAeC,EAAID,GAApB,SAAoCC,EAAK,GAGpE,IAAME,EAAOhM,KAAKqK,UACZ4B,EAAYjM,KAAK0E,QAGjBwH,EAAOH,EAAO/I,IAAImE,GAGlBgF,EAAOrL,EAAOkC,IAAIlC,EAAOwC,UAAU0I,GAAOE,GAC1CE,EAAOF,EACPhB,EAAYpK,EAAOkC,IAAIkJ,EAAMpL,EAAOwC,UAAU2I,IAGpDjM,KAAK0E,QAAQhB,IAAIyI,EAAKnJ,IAAIwC,IAC1BxF,KAAKwE,OAAOd,IAAI0I,EAAKpJ,IAAIwC,IASzB,IANA,IAAM6G,EAAWrM,KAAKuL,eAAe,GAC/B7N,EAAOsC,KAAKuL,eAAe,GAC3BxK,EAAOf,KAAKuL,eAAe,GAC7BjS,EAAQ,EACNgT,EAAoB,GAEjB/M,EAAI,EAAGA,EAAI8M,EAAU9M,IAAK,CAGjC,IAFA,IAAMgN,EAAkB,IAAIzL,EAAOpD,EAAMqD,GAEhCe,EAAI,EAAGA,EAAIpE,EAAMoE,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIhB,EAAMgB,IACxBwK,EAAgBjP,KAAKwE,GAAGC,GAAKmJ,EAAU5N,KAAK,GAAGhE,GAC/CA,IAIJgT,EAAkB5Q,KAAK6Q,GAGzB,OAAOD,M,KC6BIE,E,WAlJb,aAAyB,IAAbC,EAAY,uDAAN,KAAM,oBACV,OAARA,GACFzM,KAAK+J,KAAO,IAAIH,EAAK,KAAM,KAAM6C,EAAI1C,MACrC/J,KAAK6K,KAAO,IAAIF,EAAQ,KAAM8B,EAAI5B,MAClC7K,KAAK8C,QAAU,IAAIsI,EAAQ,KAAM,KAAMqB,EAAI3J,WAE3C9C,KAAK+J,KAAO,IAAIH,EAAK,GACrB5J,KAAK6K,KAAO,IAAIF,EAChB3K,KAAK8C,QAAU,IAAIsI,EAAQ,KAAa,K,oDASpClB,GAEN,IAAIwC,EAAM1M,KAAK+J,KAAKjD,QAAQoD,GAG5B,OAFAwC,EAAM1M,KAAK6K,KAAK/D,QAAQ4F,IACxBA,EAAM1M,KAAK8C,QAAQgE,QAAQ4F,IAChBtH,Y,4BAUPC,EAAYC,EAAQE,GACxB,IADyD,IAAnBE,EAAkB,uDAAN,KACzCiH,EAAQ,EAAGA,EAAQrH,EAAQqH,IAAS,CAC3C9I,EAAQwB,GAKR,IAHA,IAAIuH,EAAO,EACPC,EAAa,EAERtN,EAAI,EAAGA,EAAI8F,EAAWtJ,OAAQwD,IAAK,CAC1C,IAAM8G,EAAYhB,EAAW9F,GACvB2K,EAAQ7D,EAAU,GAClByG,EAAQzG,EAAU,GAHkB,EAMhByG,EAAM9K,MANU,mBAMhC+K,GANgC,mBASpB/M,KAAK8G,QAAQoD,EAAO4C,IATA,mBASnCJ,EATmC,KAS9BM,EAT8B,KAS3BC,EAT2B,KAY1CL,GAAQI,EACRH,GAAcI,EAGd,IAAI9F,EAAW,IAAIrG,EAAO,EAAG,IAC7BqG,EAAS7J,KAAK,GAAGyP,IAAa,EAAIL,EAAIpP,KAAK,GAAGyP,GAG9C5F,EAAWnH,KAAK8C,QAAQ0D,SAASW,EAAU3B,GAC3C2B,EAAWnH,KAAK6K,KAAKrE,SAASW,GAC9BnH,KAAK+J,KAAKvD,SAASW,EAAU3B,GAEzBjG,EAAI,MAAQ,KACd2B,QAAQC,IACN,cACG5B,EAAI,GACL,IACA8F,EAAWtJ,OACX,oBACA6Q,EAAO,IACP,gBACAC,EACA,QAEJD,EAAO,EACPC,EAAa,GAKf3L,QAAQC,IAAI6E,KAAKC,UAAUjG,OAIb,OAAd0F,GACF1F,KAAKkN,KAAKxH,K,8BAUNwE,EAAO4C,GAEb,IAAIJ,EAAM1M,KAAK+J,KAAKjD,QAAQoD,GAC5BwC,EAAM1M,KAAK6K,KAAK/D,QAAQ4F,GACxBA,EAAM1M,KAAK8C,QAAQgE,QAAQ4F,GAJP,MAOMI,EAAM9K,MAPZ,mBAOV+K,GAPU,mBAQQL,EAAI1K,OARZ,mBAQFmL,GARE,gBAcpB,MAAO,CAACT,GAHMtR,KAAK+F,IAAIuL,EAAIpP,KAAK,GAAGyP,IACvBI,IAAWJ,EAAW,EAAI,K,2BASnCrH,GACH,IADc,EACVkH,EAAO,EACPC,EAAa,EAFH,cAKOnH,GALP,IAKd,2BAAgC,CAAC,IAAxB6B,EAAuB,QACxB2C,EAAQ3C,EAAS,GACjBuF,EAAQvF,EAAS,GAFO,EAIVvH,KAAK8G,QAAQoD,EAAO4C,GAJV,mBAIpBE,GAJoB,WAIjBC,EAJiB,KAK9BL,GAAQI,EACRH,GAAcI,GAXF,8BAed,IAAMG,EAAW1H,EAAU3J,OAC3BmF,QAAQC,IAAI,aAAcyL,EAAOQ,GACjClM,QAAQC,IACN,kBACE0L,EACA,IACAO,EACA,KACC,IAAMP,EAAcO,EACrB,S,KC2bOC,GAtjBF,SAAG,IAAO,K,kDAKrB,WAAYC,GAAQ,IAAD,8BACjB,cAAMA,IA8WRC,cAAgB,WACd,QAAkBC,IAAd,EAAKrJ,WAAmCqJ,IAAb,EAAKf,IAAmB,CACrD,IAAMgB,EAAW,EAAKC,UAAUC,QAAQnP,UAClCoP,EAAY9M,EAAO+G,gBAAgB4F,GACnCI,EAAW/M,EAAOgN,gBAAgBL,EAAU,GAAI,IArYhC,EA6YtB,IAAMM,EAAgB,EAAK5J,KAAK3F,QAAQoP,GAClCI,EAAWD,EAAcrG,QAAQtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQ2S,KAE7CE,EAAe,EAAKxB,IAAIjO,QAAQqP,GAChCK,EAAUD,EAAavG,QAAQtM,KAAK4G,IAAL,MAAA5G,KAAI,YAAQ6S,KAGjD,EAAKE,SAAS,CACZJ,gBACAE,eACAD,WACAE,cAtYa,EA8YnBE,YAAc,WACZ,EAAKV,UAAUC,QAAQjR,QAEvB,EAAKyR,SAAS,CACZJ,cAAe,GACfE,aAAc,GACdD,SAAU,GACVE,QAAS,MAnZX,EAAKG,MAAQ,CACXN,cAAe,GACfE,aAAc,GACdD,SAAU,GACVE,QAAS,IA4ET,EAAK/J,KAAO,IAAIF,EAAK,KAAMqK,GAC3B,EAAK7B,IAAM,IAAID,EAAI+B,GAGrB,EAAKb,UAAYc,IAAMC,YAtFN,E,gEA2FjBzO,KAAK0O,gB,oCAUL,IAHA,IAAMC,EAAU,GAGPpP,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAI3B,IAHA,IAAMqP,EAAe,GAGZ3N,EAAI,EAAGA,EAAIjB,KAAK6O,MAAMC,WAAW/S,SACpCiE,KAAK6O,MAAME,WAAW9N,KAAO1B,IAC/BqP,EAAalT,KAAK+D,MAAMuP,KAAKhP,KAAK6O,MAAMC,WAAW7N,KA9GnC,IAiHZ2N,EAAa7S,SAL6BkF,KAWlD0N,EAAQjT,KAAKkT,GAGf1N,QAAQC,IAAI6E,KAAKC,UAAU0I,M,oCAQ3B,IAAK,IAAIpP,EAAI,EAAGA,EAAI,GAAIA,IAEtB,IAAK,IAAI0B,EAAI,EAAGA,EApII,EAoImBA,IAKrC,IAHA,IACMlG,EADS8D,SAASoB,eAAT,iBAAkCV,EAAlC,YAAuC0B,IACnCjC,WAAW,MAErB7B,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAE3B,IAAMyC,EAAQ9E,EAAIkU,gBAAgB,EAAG,GAC/BnP,EAAS,IAAMoP,EAAa3P,GAAG0B,GAAO,GAAJ9D,EAASC,GAGjDyC,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAK,IAGhBvC,EAAIgF,aAAaF,EAAOzC,EAAGD,M,sEAyE3BgS,EAAQC,EAAQC,GAGxB,IAFA,IAAM1H,EAAQ,GAELpI,EAAI,EAAGA,EAAI4P,EAAOpT,OAAQwD,IAAK,CAKtC,IAJA,IAAMkO,EAAW0B,EAAO5P,GAClB+P,EAAYF,EAAO7P,GACnBgQ,EAAY,GAETtO,EAAI,EAAGA,EAAI,GAAIA,IAClBqO,IAAcrO,EAChBsO,EAAU7T,KAAK,GAEf6T,EAAU7T,KAAK,GAInBiM,EAAMjM,KAAK,CACT2T,EACIvO,EAAO+G,gBAAgB4F,GACvB3M,EAAOgN,gBAAgBL,EAAU,GAAI,IACzC3M,EAAO+G,gBAAgB0H,KAI3B,OAAO5H,I,iFAwDU,IAAD,OAEhB,IAAK3H,KAAKmE,KAAKS,eAAe,aAAc,CAC1C,IAAMlF,EAAO,IAAIoB,EAAO,IAAK,GACvB0O,EAAM,IAAI1O,EAAO,IAAK,GAG5BI,QAAQC,IAAI,+BAL8B,oBAMpBnB,KAAKyP,gBANe,IAM1C,2BAA2C,CAAC,IAAnCpJ,EAAkC,QACzC3G,EAAKyF,IAAIkB,EAAU,KAPqB,8BAW1C3G,EAAKrG,KAAI,SAAC+D,GAAD,OAAOA,EAAI,EAAKqS,eAAe1T,UAGxCmF,QAAQC,IAAI,6CAd8B,oBAepBnB,KAAKyP,gBAfe,IAe1C,2BAA2C,CAAC,IAAnCpJ,EAAkC,QACzCmJ,EAAIrK,IAAIrE,EAAO4C,IAAI2C,EAAU,GAAI3G,GAAMrG,KAAI,SAAC+D,GAAD,gBAAOA,EAAK,QAhBf,8BAoB1CoS,EAAInW,KAAI,SAAC+D,GAAD,OAAOhC,KAAKqG,KAAKrE,EAAI,EAAKqS,eAAe1T,WAGjDiE,KAAKmE,KAAKU,UAAYnF,EACtBM,KAAKmE,KAAKW,SAAW0K,EAIVxP,KAAKmE,KAAKU,UACX7E,KAAKmE,KAAKW,W,+BAgFtB,IADA,IAAM8J,EAAe,GACZrP,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAG3B,IAFA,IAAMwB,EAAO,GAEJE,EAAI,EAAGA,EAjaI,EAiamBA,IAAK,CAC1C,IAAMyO,EACJ,yBAAK7V,UAAU,WAAWL,IAAG,cAAS+F,EAAT,YAAc0B,IACzC,4BACEX,GAAE,iBAAYf,EAAZ,YAAiB0B,GACnBrE,MAAM,KACNC,OAAO,KACP2D,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,YAKzBI,EAAKrF,KAAKgU,GAGZ,IAAMC,EACJ,yBAAK9V,UAAU,6BAA6BL,IAAG,cAAS+F,IACrDwB,GAGL6N,EAAalT,KAAKiU,GAIpB,IADA,IAAMC,EAAY,GACTrQ,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMsQ,EACJ,yBAAKhW,UAAU,MAAML,IAAK,MAAQ+F,GAChC,yBAAK1F,UAAU,kBACb,4BAAK0F,EAAL,MAEF,yBAAK1F,UAAU,iBACb,4BACGmG,KAAKqO,MAAMN,cAAchS,OAAS,GACA,IAA9BiE,KAAKqO,MAAMN,cAAcxO,IAAUuQ,QAAQ,GAAK,IACjD,MAKZF,EAAUlU,KAAKmU,GAGjB,IADA,IAAME,EAAW,GACRxQ,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMsQ,EACJ,yBAAKhW,UAAU,MAAML,IAAK,MAAQ+F,GAChC,yBAAK1F,UAAU,kBACb,4BAAK0F,EAAL,MAEF,yBAAK1F,UAAU,iBACb,4BACGmG,KAAKqO,MAAMJ,aAAalS,OAAS,GACA,IAA7BiE,KAAKqO,MAAMJ,aAAa1O,IAAUuQ,QAAQ,GAAK,IAChD,MAKZC,EAASrU,KAAKmU,GAGhB,OACE,yBAAKhW,UAAU,kCACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAOX,KAAK,uBAGhB,yBAAKW,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CACEX,KACE,yFAKR,yBAAKW,UAAU,YACb,yBAAKA,UAAU,OACb,gDAGH+U,EACD,yBAAK/U,UAAU,mCACb,yBAAKA,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,UAAUC,QAASoG,KAAKuN,iBAExC,yBAAK1T,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,QAAQC,QAASoG,KAAKoO,gBAGxC,yBAAKvU,UAAU,YACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAQmW,IAAKhQ,KAAK0N,cAGtB,yBAAK7T,UAAU,OACb,yBAAKA,UAAU,OACb,4BACEyG,GAAG,WACH1D,MAAM,KACNC,OAAO,KACP2D,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,aAKzB,yBAAK9G,UAAU,mCACb,yBAAKA,UAAU,2BACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,kBACb,wBAAIA,UAAU,oBAAd,UAEF,yBAAKA,UAAU,iBACb,wBAAIA,UAAU,oBAAoBmG,KAAKqO,MAAML,YAGhD4B,GAEH,yBAAK/V,UAAU,2BACb,yBAAKA,UAAU,wBACb,yBAAKA,UAAU,kBACb,wBAAIA,UAAU,oBAAd,SAEF,yBAAKA,UAAU,iBACb,wBAAIA,UAAU,oBAAoBmG,KAAKqO,MAAMH,WAGhD6B,IAGL,kBAAC,IAAD,CACEE,KAAK,mDACLC,YAAY,OACZC,UAAU,UACVnW,OAAO,gB,GA3iBC4G,cCvBEwP,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASC,MACvB,2D,YCXNC,IAASC,OAAO,kBAAC,EAAD,MAAS7R,SAASoB,eAAe,SD4H3C,kBAAmB0Q,WACrBA,UAAUC,cAAcC,MAAMC,MAAK,SAAAC,GACjCA,EAAaC,kB","file":"static/js/main.ace0680b.chunk.js","sourcesContent":["import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Title = ({ text }) => {\r\n  return <h1>{text}</h1>;\r\n};\r\n\r\nTitle.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Title;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Description = ({ text }) => {\r\n  const addLineBreaks = string =>\r\n    string.split(\"\\n\").map((text, index) => (\r\n      <React.Fragment key={`${text}-${index}`}>\r\n        {text}\r\n        <br />\r\n      </React.Fragment>\r\n    ));\r\n\r\n  return <h5>{addLineBreaks(text)}</h5>;\r\n};\r\n\r\nDescription.defaultProps = {\r\n  text: \"Default description\"\r\n};\r\n\r\nDescription.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Description;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Button = ({ value, onClick }) => {\r\n  const handleOnClick = (e) => {\r\n    e.target.blur();\r\n    onClick();\r\n  };\r\n\r\n  return (\r\n    <button\r\n      className=\"btn btn-primary btn-lg\"\r\n      type=\"button\"\r\n      onClick={handleOnClick}\r\n    >\r\n      {value}\r\n    </button>\r\n  );\r\n};\r\n\r\nButton.propTypes = {\r\n  value: PropTypes.string,\r\n  onClick: PropTypes.func,\r\n};\r\n\r\nexport default Button;\r\n","import React, { Component } from \"react\";\r\n\r\nconst WIDTH = 280;\r\nconst HEIGHT = 280;\r\nconst SCALE_SIZE = 190;\r\nconst BOUNDING_THRESHOLD = 0.01;\r\nconst LINE_WIDTH = 20;\r\nconst COLOR = \"black\";\r\nconst SCALE_PATH = true;\r\n\r\nconst DEBUG = false;\r\n\r\nclass Canvas extends Component {\r\n  componentDidMount() {\r\n    this.canvas = document.getElementById(\"main-canvas\");\r\n    this.ctx = this.canvas.getContext(\"2d\");\r\n    this.canvas28 = document.getElementById(\"canvas28\");\r\n    this.ctx28 = this.canvas28.getContext(\"2d\");\r\n\r\n    // Mouse\r\n    this.canvas.addEventListener(\r\n      \"mousedown\",\r\n      (e) => {\r\n        this.findxy(\"down\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseup\",\r\n      (e) => {\r\n        this.findxy(\"up\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseout\",\r\n      (e) => {\r\n        this.findxy(\"out\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mousemove\",\r\n      (e) => {\r\n        this.findxy(\"move\", e, false);\r\n      },\r\n      false\r\n    );\r\n\r\n    // Touchscreen\r\n    this.canvas.addEventListener(\r\n      \"touchstart\",\r\n      (e) => {\r\n        this.findxy(\"down\", e, true);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"touchend\",\r\n      (e) => {\r\n        this.findxy(\"up\", e, true);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"touchmove\",\r\n      (e) => {\r\n        this.findxy(\"move\", e, true);\r\n      },\r\n      false\r\n    );\r\n\r\n    // Prevent scrolling while drawing on touchscreen\r\n    document.body.addEventListener(\r\n      \"touchstart\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n    document.body.addEventListener(\r\n      \"touchend\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n    document.body.addEventListener(\r\n      \"touchmove\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n\r\n    this.prevX = 0;\r\n    this.currX = 0;\r\n    this.prevY = 0;\r\n    this.currY = 0;\r\n    this.paths = [];\r\n    this.paintFlag = false;\r\n  }\r\n\r\n  findxy = (res, e, isTouch) => {\r\n    if (res === \"down\") {\r\n      // Get touch down point\r\n      this.currX =\r\n        (isTouch ? e.touches[0].clientX : e.clientX) -\r\n        this.canvas.getBoundingClientRect().left;\r\n      this.currY =\r\n        (isTouch ? e.touches[0].clientY : e.clientY) -\r\n        this.canvas.getBoundingClientRect().top;\r\n\r\n      // Draw circle\r\n      this.ctx.beginPath();\r\n      this.ctx.lineWidth = 1;\r\n      this.ctx.arc(this.currX, this.currY, LINE_WIDTH / 2, 0, 2 * Math.PI);\r\n      this.ctx.stroke();\r\n      this.ctx.closePath();\r\n      this.ctx.fill();\r\n\r\n      // Add start of new path\r\n      this.paths.push([[this.currX], [this.currY]]);\r\n\r\n      // Activate paint flag\r\n      this.paintFlag = true;\r\n    }\r\n\r\n    // Deactivate paint flag on touch up or mouse off canvas\r\n    if (res === \"up\" || res === \"out\") {\r\n      this.paintFlag = false;\r\n    }\r\n\r\n    // If moving and paint flag activated, draw!\r\n    if (res === \"move\" && this.paintFlag) {\r\n      // Save previous point\r\n      this.prevX = this.currX;\r\n      this.prevY = this.currY;\r\n\r\n      // Get new point\r\n      this.currX =\r\n        (isTouch ? e.touches[0].clientX : e.clientX) -\r\n        this.canvas.getBoundingClientRect().left;\r\n      this.currY =\r\n        (isTouch ? e.touches[0].clientY : e.clientY) -\r\n        this.canvas.getBoundingClientRect().top;\r\n\r\n      // Add point to last path\r\n      const currPath = this.paths[this.paths.length - 1];\r\n      currPath[0].push(this.currX);\r\n      currPath[1].push(this.currY);\r\n      this.paths[this.paths.length - 1] = currPath;\r\n\r\n      // Draw line between new point and previous point\r\n      this.draw(\r\n        this.ctx,\r\n        LINE_WIDTH,\r\n        this.prevX,\r\n        this.prevY,\r\n        this.currX,\r\n        this.currY\r\n      );\r\n    }\r\n  };\r\n\r\n  // Draw line between 2 points\r\n  draw = (ctx, lineWidth, x1, y1, x2, y2) => {\r\n    ctx.beginPath();\r\n    ctx.strokeStyle = COLOR;\r\n    ctx.lineWidth = lineWidth;\r\n    ctx.lineCap = \"round\";\r\n    ctx.lineJoin = \"round\";\r\n    ctx.moveTo(x1, y1);\r\n    ctx.lineTo(x2, y2);\r\n    ctx.stroke();\r\n    ctx.closePath();\r\n  };\r\n\r\n  // Erase canvas and clear paths\r\n  erase = () => {\r\n    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n    this.paths = [];\r\n\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n  };\r\n\r\n  imageDataToGrayscale = (imgData) => {\r\n    // 2D array\r\n    const grayscaleImg = [];\r\n\r\n    for (let y = 0; y < imgData.height; y++) {\r\n      // Row number y\r\n      grayscaleImg[y] = [];\r\n\r\n      for (let x = 0; x < imgData.width; x++) {\r\n        // Each pixel has four values, RGBA\r\n        const offset = y * 4 * imgData.width + 4 * x;\r\n\r\n        // Alpha === 0 means no drawing\r\n        const alpha = imgData.data[offset + 3];\r\n\r\n        // No drawing, set value to white\r\n        if (alpha === 0) {\r\n          imgData.data[offset] = 255;\r\n        }\r\n\r\n        // Take only RED value since grayscale and scale to [0, 1]\r\n        grayscaleImg[y][x] = imgData.data[offset] / 255;\r\n        // grayscaleImg[y][x] = imgData.data[offset];\r\n      }\r\n    }\r\n\r\n    return grayscaleImg;\r\n  };\r\n\r\n  getBoundingRect = (img, threshold) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let minX = columns;\r\n    let minY = rows;\r\n    let maxX = -1;\r\n    let maxY = -1;\r\n\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        // Black === 0, so must be lower than some darkness threshold to be considered significant\r\n        if (img[y][x] < threshold) {\r\n          if (minX > x) minX = x;\r\n          if (maxX < x) maxX = x;\r\n          if (minY > y) minY = y;\r\n          if (maxY < y) maxY = y;\r\n        }\r\n      }\r\n    }\r\n\r\n    return { minY: minY, minX: minX, maxY: maxY, maxX: maxX };\r\n  };\r\n\r\n  centerImage = (img) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let meanX = 0;\r\n    let meanY = 0;\r\n    let sumPixels = 0;\r\n\r\n    // Center of mass, weighted by color intensity\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        let pixel = 1 - img[y][x];\r\n        meanX += x * pixel;\r\n        meanY += y * pixel;\r\n        sumPixels += pixel;\r\n      }\r\n    }\r\n    meanX /= sumPixels;\r\n    meanY /= sumPixels;\r\n\r\n    let dx = Math.round(columns / 2 - meanX);\r\n    let dy = Math.round(rows / 2 - meanY);\r\n\r\n    return { transX: dx, transY: dy };\r\n  };\r\n\r\n  predict = () => {\r\n    // Get image and convert to grayscale\r\n    let imgData = this.ctx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    let grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Get bounding rectangle and center of mass translation amount\r\n    const boundingRect = this.getBoundingRect(grayscaleImg, BOUNDING_THRESHOLD);\r\n    // const boundingRect = this.getBoundingRect(grayscaleImg, 25);\r\n    const trans = this.centerImage(grayscaleImg);\r\n\r\n    // Create hidden copy of canvas context\r\n    const canvasCopy = document.createElement(\"canvas\");\r\n    canvasCopy.width = imgData.width;\r\n    canvasCopy.height = imgData.height;\r\n    const copyCtx = canvasCopy.getContext(\"2d\");\r\n\r\n    // Scale largest dimension to SCALE_SIZE\r\n    const brW = boundingRect.maxX - boundingRect.minX + 1;\r\n    const brH = boundingRect.maxY - boundingRect.minY + 1;\r\n    const scaling = SCALE_SIZE / (brW > brH ? brW : brH);\r\n\r\n    // Scale\r\n    copyCtx.translate(this.canvas.width / 2, this.canvas.height / 2);\r\n    copyCtx.scale(scaling, scaling);\r\n    copyCtx.translate(-this.canvas.width / 2, -this.canvas.height / 2);\r\n\r\n    // Center on canvas over center of mass\r\n    copyCtx.translate(trans.transX, trans.transY);\r\n\r\n    if (SCALE_PATH) {\r\n      // Scale path line width\r\n      for (let p = 0; p < this.paths.length; p++) {\r\n        for (let i = 0; i < this.paths[p][0].length - 1; i++) {\r\n          const x1 = this.paths[p][0][i];\r\n          const y1 = this.paths[p][1][i];\r\n          const x2 = this.paths[p][0][i + 1];\r\n          const y2 = this.paths[p][1][i + 1];\r\n          this.draw(copyCtx, LINE_WIDTH / scaling, x1, y1, x2, y2);\r\n        }\r\n      }\r\n    } else {\r\n      copyCtx.drawImage(this.ctx.canvas, 0, 0);\r\n    }\r\n\r\n    // Get scaled and translated image and convert to grayscale\r\n    imgData = copyCtx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Final input array for neural net\r\n    const nnInput = new Array(784);\r\n\r\n    // Convert to 28x28\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        let mean = 0;\r\n        for (let v = 0; v < 10; v++) {\r\n          for (let h = 0; h < 10; h++) {\r\n            mean += grayscaleImg[y * 10 + v][x * 10 + h];\r\n          }\r\n        }\r\n\r\n        // Average and invert color\r\n        nnInput[y * 28 + x] = 1 - mean / 100;\r\n        // nnInput[y + 28 * x] = 255 - mean / 100;\r\n      }\r\n    }\r\n\r\n    // Draw to 28x28 canvas\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        const block = this.ctx28.getImageData(x, y, 1, 1);\r\n        const newVal = 255 * nnInput[y * 28 + x];\r\n\r\n        block.data[0] = newVal;\r\n        block.data[1] = newVal;\r\n        block.data[2] = newVal;\r\n        block.data[3] = 255;\r\n\r\n        this.ctx28.putImageData(block, x, y);\r\n      }\r\n    }\r\n\r\n    // Draw neural network input back to canvas\r\n    if (DEBUG) {\r\n      // Clear canvas\r\n      this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n\r\n      for (let y = 0; y < 28; y++) {\r\n        for (let x = 0; x < 28; x++) {\r\n          // Blocks of 10\r\n          const block = this.ctx.getImageData(x * 10, y * 10, 10, 10);\r\n          const newVal = 255 * nnInput[y * 28 + x];\r\n          // const newVal = nnInput[y + 28 * x];\r\n\r\n          // R=G=B since grayscale, A=255 for full opacity\r\n          for (let i = 0; i < 4 * 10 * 10; i += 4) {\r\n            block.data[i] = newVal;\r\n            block.data[i + 1] = newVal;\r\n            block.data[i + 2] = newVal;\r\n            block.data[i + 3] = 255;\r\n          }\r\n\r\n          // Paint new data to canvas\r\n          this.ctx.putImageData(block, x * 10, y * 10);\r\n        }\r\n      }\r\n    }\r\n\r\n    return nnInput;\r\n  };\r\n\r\n  render() {\r\n    return (\r\n      <canvas\r\n        id=\"main-canvas\"\r\n        width={WIDTH.toString()}\r\n        height={HEIGHT.toString()}\r\n        style={{\r\n          border: \"5px solid aquamarine\",\r\n          borderRadius: \"5px\",\r\n          backgroundColor: \"white\",\r\n        }}\r\n      ></canvas>\r\n    );\r\n  }\r\n}\r\n\r\nexport default Canvas;\r\n","/**\r\n * Loads the MNIST data.\r\n * @param {function} callback The callback function to be called when loading is finished\r\n * @return {Promise} The resolved promise\r\n */\r\nfunction loadMNIST(callback) {\r\n  let mnist = {};\r\n  let files = {\r\n    trainImages: \"./train-images.idx3-ubyte\",\r\n    trainLabels: \"./train-labels.idx1-ubyte\",\r\n    testImages: \"./t10k-images.idx3-ubyte\",\r\n    testLabels: \"./t10k-labels.idx1-ubyte\",\r\n  };\r\n\r\n  // Load all files\r\n  return Promise.all(\r\n    Object.keys(files).map(async (file) => {\r\n      mnist[file] = await loadFile(files[file]);\r\n    })\r\n  ).then(() => callback(mnist));\r\n}\r\n\r\n/**\r\n * Parses the MNIST file into an array of data.\r\n * @param {string} file The filename\r\n * @return {Array} The MNIST data\r\n */\r\nasync function loadFile(file) {\r\n  // Fetch file response\r\n  let response = await fetch(file);\r\n\r\n  // Get 8-bit/1-byte array\r\n  let buffer = await response.arrayBuffer();\r\n\r\n  // Default header count is 4 for images, change to 2 for labels later\r\n  let headerCount = 4;\r\n\r\n  // Can't access data straight from ArrayBuffer, extract headers using DataView\r\n  let headerView = new DataView(buffer, 0, 4 * headerCount);\r\n\r\n  // Create Array of 32-bit/4-byte headers\r\n  let headers = new Array(headerCount)\r\n    .fill()\r\n    .map((_, i) => headerView.getUint32(4 * i, false));\r\n\r\n  // Get file type: image or label\r\n  let type, dataLength;\r\n  if (headers[0] === 2049) {\r\n    type = \"label\";\r\n    dataLength = 1;\r\n    headerCount = 2;\r\n  } else if (headers[0] === 2051) {\r\n    type = \"image\";\r\n    dataLength = headers[2] * headers[3];\r\n  } else {\r\n    throw new Error(\"Unknown file type \" + headers[0]);\r\n  }\r\n\r\n  // Create array of data only, headers removed\r\n  let data = new Uint8Array(buffer, headerCount * 4);\r\n\r\n  // Image, create array of subarrays of 28 * 28 = 784\r\n  if (type === \"image\") {\r\n    let dataArr = [];\r\n    for (let i = 0; i < headers[1]; i++) {\r\n      dataArr.push(data.subarray(dataLength * i, dataLength * (i + 1)));\r\n    }\r\n    console.log(\"Loaded file:\", file);\r\n    return dataArr;\r\n  }\r\n\r\n  // Label, just return data straight away\r\n  console.log(\"Loaded file:\", file);\r\n  return data;\r\n}\r\n\r\nexport default loadMNIST;\r\n","class Matrix {\r\n  /**\r\n   * Creates an empty matrix of all zeros or from the given Matrix.\r\n   * @param {number} rows The number of rows\r\n   * @param {number} cols The number of columns\r\n   * @param {Matrix} matrix A Matrix to copy\r\n   */\r\n  constructor(rows, cols, matrix) {\r\n    if (matrix) {\r\n      // Deep copy\r\n      this.rows = matrix.rows;\r\n      this.cols = matrix.cols;\r\n      this.data = [];\r\n      for (let i = 0; i < this.rows; i++) {\r\n        this.data.push([]);\r\n        for (let j = 0; j < this.cols; j++) {\r\n          this.data[i].push(matrix.data[i][j]);\r\n        }\r\n      }\r\n    } else {\r\n      this.rows = rows;\r\n      this.cols = cols;\r\n      this.data = Array(rows)\r\n        .fill()\r\n        .map(() => Array(cols).fill(0));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Element-wise addition by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to add by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  add(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Add: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x + matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x + matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise addition into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the addition of the two given matrices\r\n   */\r\n  static add(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Add: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] + matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Element-wise subtraction by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to subtract by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  sub(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Subtract: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x - matrix.data[i][j]);\r\n    }\r\n    //Scaler\r\n    return this.map((x) => x - matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise subtraction into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the subtraction of the two given matrices\r\n   */\r\n  static sub(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Subtract: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] - matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Element-wise multiplication by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The scaler or Matrix to multiply by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  mul(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Multiply: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x * matrix.data[i][j]);\r\n    }\r\n    // Scaler\r\n    return this.map((x) => x * matrix);\r\n  }\r\n\r\n  /**\r\n   * Matrix multiplication into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the matrix multiplication of the two given matrices\r\n   */\r\n  static mul(matrix1, matrix2) {\r\n    if (matrix1.cols !== matrix2.rows) {\r\n      console.log(\r\n        \"Multiply: first matrix's columns must match second matrix's rows\"\r\n      );\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix2.cols).map((_, i, j) => {\r\n      let sum = 0;\r\n      for (let k = 0; k < matrix1.cols; k++) {\r\n        sum += matrix1.data[i][k] * matrix2.data[k][j];\r\n      }\r\n      return sum;\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Element-wise division by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to divide by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  div(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Division: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x / matrix.data[i][j]);\r\n    }\r\n    // Scaler\r\n    return this.map((x) => x / matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise division into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the division of the two given matrices\r\n   */\r\n  static div(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Division: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] / matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Transposes the Matrix.\r\n   * @param {Matrix} matrix The Matrix to transpose\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  static transpose(matrix) {\r\n    return new Matrix(matrix.cols, matrix.rows).map(\r\n      (_, i, j) => matrix.data[j][i]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Converts the array into a column vector.\r\n   * @param {Array} arr The array to convert to a vector\r\n   * @return {Matrix} The array as a column vector\r\n   */\r\n  static vectorFromArray(arr) {\r\n    return new Matrix(arr.length, 1).map((_, i) => arr[i]);\r\n  }\r\n\r\n  /**\r\n   * Converts the array into a Matrix of the given dimensions.\r\n   * @param {Array} arr The array to convert to a Matrix\r\n   * @param {number} rows The number of rows for the new Matrix\r\n   * @param {number} cols The number of columns for the new Matrix\r\n   * @return {Matrix} The array as a Matrix of the given dimension\r\n   */\r\n  static matrixFromArray(arr, rows, cols) {\r\n    return new Matrix(rows, cols).map((_, i, j) => arr[i * cols + j]);\r\n  }\r\n\r\n  /**\r\n   * Converts this Matrix to an array.\r\n   * @return {Array} This Matrix as an array\r\n   */\r\n  toArray() {\r\n    const arr = [];\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        arr.push(this.data[i][j]);\r\n      }\r\n    }\r\n    return arr;\r\n  }\r\n\r\n  /**\r\n   * Returns a copy of this Matrix.\r\n   * @return {Matrix} A copy of this Matrix\r\n   */\r\n  copy() {\r\n    return new Matrix(this.rows, this.cols).map((_, i, j) => this.data[i][j]);\r\n  }\r\n\r\n  /**\r\n   * Applies the function to the Matrix.\r\n   * @param {Function} func The function to apply to the Matrix\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  map(func) {\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        this.data[i][j] = func(this.data[i][j], i, j);\r\n      }\r\n    }\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Applies the function to the Matrix and returns a new Matrix.\r\n   * @param {Matrix} matrix The Matrix to apply the function to\r\n   * @param {Function} func The function to apply to the Matrix\r\n   * @return {Matrix} A new Matrix from applying the function to the Matrix\r\n   */\r\n  static map(matrix, func) {\r\n    return new Matrix(matrix.rows, matrix.cols).map((_, i, j) =>\r\n      func(matrix.data[i][j], i, j)\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Randomize [-1, 1].\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  randomize() {\r\n    return this.map(() => Math.random() * 2 - 1);\r\n  }\r\n\r\n  /**\r\n   * Box-Muller Transform for normal distribution, mean = 0, variance = 1.\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  randomizeNormal() {\r\n    return this.map(() => {\r\n      let u = 0;\r\n      let v = 0;\r\n      while (u === 0) u = Math.random();\r\n      while (v === 0) v = Math.random();\r\n      return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Prints the Matrix as a table.\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  print() {\r\n    console.table(this.data);\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Returns a region of this Matrix.\r\n   * @param {number} x The column offset\r\n   * @param {number} y The row offset\r\n   * @param {number} w The width of the region to extract\r\n   * @param {number} h The height of the region to extract\r\n   * @return {Matrix} The region of this Matrix\r\n   */\r\n  getRegion(x, y, w, h) {\r\n    const region = new Matrix(h, w);\r\n    for (let r = 0; r < h; r++) {\r\n      for (let c = 0; c < w; c++) {\r\n        region.data[r][c] = this.data[y + r][x + c];\r\n      }\r\n    }\r\n    return region;\r\n  }\r\n\r\n  /**\r\n   * Returns the max value and the corresponding row and column.\r\n   * @return {Array} The max value and the corresponding row and column.\r\n   */\r\n  max() {\r\n    let max = Number.NEGATIVE_INFINITY;\r\n    let maxR = -1;\r\n    let maxC = -1;\r\n    for (let r = 0; r < this.rows; r++) {\r\n      for (let c = 0; c < this.cols; c++) {\r\n        if (this.data[r][c] > max) {\r\n          max = this.data[r][c];\r\n          maxR = r;\r\n          maxC = c;\r\n        }\r\n      }\r\n    }\r\n    return [max, maxR, maxC];\r\n  }\r\n}\r\n\r\nexport default Matrix;\r\n","import Matrix from \"../matrix\";\r\n\r\n/**\r\n * The sigmoid activation function and derivative.\r\n */\r\nexport class SigmoidActivation {\r\n  /**\r\n   * Returns the matrix mapped with sigmoid.\r\n   * @param {Matrix} z The matrix to apply the sigmoid function to\r\n   * @return {Matrix} The matrix mapped with sigmoid\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => 1 / (1 + Math.exp(-z_i)));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with sigmoid derivative.\r\n   * @param {Matrix} z The matrix to apply the sigmoid derivative function to\r\n   * @return {Matrix} The matrix mapped with sigmoid derivative\r\n   */\r\n  static derivative(z) {\r\n    const sigmoid = SigmoidActivation.fn(z);\r\n    return sigmoid.mul(Matrix.map(sigmoid, (a_i) => 1 - a_i));\r\n  }\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class ReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with ReLU.\r\n   * @param {Matrix} z The matrix to apply the ReLu function to\r\n   * @return {Matrix} The matrix mapped with ReLu\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => Math.max(0, z_i));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with ReLU derivative\r\n   */\r\n  static derivative(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0));\r\n  }\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class LeakyReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLu function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLu\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? z_i : 0.01 * z_i));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLU derivative\r\n   */\r\n  static derivative(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0.01));\r\n  }\r\n}\r\n\r\n/**\r\n * The softmax activation function and derivative.\r\n */\r\nexport class SoftmaxActivation {\r\n  /**\r\n   * Returns the matrix mapped with softmax.\r\n   * @param {Matrix} z The matrix to apply the softmax function to\r\n   * @return {Matrix} The matrix mapped with softmax\r\n   */\r\n  static fn(z) {\r\n    let sum = 0;\r\n    for (let r = 0; r < z.rows; r++) {\r\n      sum += Math.exp(z.data[r][0]);\r\n    }\r\n    return Matrix.map(z, (z_i) => Math.exp(z_i) / sum);\r\n  }\r\n\r\n  /**\r\n   * Returns the softmax derivative of the given number.\r\n   * @param {Matrix} z The matrix to apply the softmax derivative function to\r\n   * @return {Matrix} The matrix mapped with softmax derivative\r\n   */\r\n  static derivative(z) {\r\n    const softmax = SoftmaxActivation.fn(z);\r\n    return softmax.mul(Matrix.map(softmax, (a_i) => 1 - a_i));\r\n  }\r\n}\r\n\r\n/**\r\n * The quadratic loss function and output layer error.\r\n */\r\nexport class QuadraticLoss {\r\n  /**\r\n   * Returns the loss = sum over all (0.5 * (a - y)^2).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const diffMatrix = Matrix.sub(a, y);\r\n    let loss = 0;\r\n    for (let r = 0; r < diffMatrix.rows; r++) {\r\n      for (let c = 0; c < diffMatrix.cols; c++) {\r\n        loss += 0.5 * diffMatrix.data[r][c] ** 2;\r\n      }\r\n    }\r\n    return loss;\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = (a - y) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.sub(a, y);\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n\r\nconst EPSILON = 10 ** -100;\r\n\r\n/**\r\n * The binary cross entropy loss function and output layer error.\r\n */\r\nexport class BinaryCrossEntropyLoss {\r\n  /**\r\n   * Returns the loss = sum over all -(y * ln(a) + (1 - y) * ln(1 - a)).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const yIsOne = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    const yIsZero = Matrix.mul(\r\n      Matrix.transpose(Matrix.map(y, (y_i) => 1 - y_i)),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 1, not doing log(0)\r\n        return Math.log(1 - a_i + EPSILON);\r\n      })\r\n    );\r\n    return -(yIsOne.data[0][0] + yIsZero.data[0][0]);\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = [(a - y) / (a * (1 - a))] hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error matrix\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.sub(a, y).div(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return a_i * (1 - a_i) + EPSILON;\r\n      })\r\n    );\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n\r\n/**\r\n * The cross entropy loss function and output layer error.\r\n */\r\nexport class CrossEntropyLoss {\r\n  /**\r\n   * Returns the loss = sum over all -y * ln(a).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const loss = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    return -loss.data[0][0];\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = (-y / a) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error matrix\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.map(y, (y_i) => -y_i).div(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return a_i + EPSILON;\r\n      })\r\n    );\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n","/**\r\n * Fisher-Yates shuffle.\r\n * @param {Array} arr The array to shuffle\r\n * @return {Array} The shuffled array\r\n */\r\nexport function shuffle(arr) {\r\n  for (let i = arr.length - 1; i > 0; i--) {\r\n    const randomIndex = Math.floor(Math.random() * (i + 1));\r\n    const temp = arr[i];\r\n    arr[i] = arr[randomIndex];\r\n    arr[randomIndex] = temp;\r\n  }\r\n  return arr;\r\n}\r\n","import Matrix from \"../matrix\";\r\nimport {\r\n  SigmoidActivation,\r\n  ReLUActivation,\r\n  LeakyReLUActivation,\r\n  SoftmaxActivation,\r\n  QuadraticLoss,\r\n  BinaryCrossEntropyLoss,\r\n  CrossEntropyLoss,\r\n} from \"./ffnn-helpers\";\r\nimport { shuffle } from \"../utils\";\r\n\r\nconst CHECK_GRADIENTS = false;\r\nconst LOG_MINI_BATCH_ACCURACY = false;\r\nconst LOG_MINI_BATCH_COST = false;\r\nconst OUTPUT_NETWORK = true;\r\n\r\nclass FFNN {\r\n  /**\r\n   * Creates a new FFNN with the givens layer sizes or loads a pretrained model.\r\n   * @param {Array} sizes An array of layer sizes\r\n   * @param {FFNN} ffnn Optional initial settings\r\n   */\r\n  constructor(sizes, ffnn) {\r\n    this.hiddenActivationFunction = ReLUActivation;\r\n    this.outputActivationFunction = SoftmaxActivation;\r\n    this.lossFunction = BinaryCrossEntropyLoss;\r\n\r\n    if (ffnn) {\r\n      // Deep copy\r\n      this.numLayers = ffnn.sizes.length;\r\n      this.sizes = [];\r\n      for (let size of ffnn.sizes) {\r\n        this.sizes.push(size);\r\n      }\r\n\r\n      // Copy bias vectors\r\n      this.biases = [];\r\n      for (let bias of ffnn.biases) {\r\n        this.biases.push(new Matrix(null, null, bias));\r\n      }\r\n\r\n      // Copy weight matrices\r\n      this.weights = [];\r\n      for (let weight of ffnn.weights) {\r\n        this.weights.push(new Matrix(null, null, weight));\r\n      }\r\n\r\n      // Save mean and std in case of standardization\r\n      if (ffnn.hasOwnProperty(\"trainMean\")) {\r\n        this.trainMean = new Matrix(null, null, ffnn.trainMean);\r\n        this.trainSTD = new Matrix(null, null, ffnn.trainSTD);\r\n      }\r\n    } else {\r\n      this.numLayers = sizes.length;\r\n      this.sizes = sizes;\r\n\r\n      // Create bias vectors\r\n      this.biases = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const bias = new Matrix(sizes[i], 1);\r\n\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          // He initialization, biases = 0\r\n          bias.map((b) => 0);\r\n        } else {\r\n          bias.randomizeNormal();\r\n        }\r\n\r\n        this.biases.push(bias);\r\n      }\r\n\r\n      // Create weight matrices\r\n      this.weights = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const weight = new Matrix(sizes[i], sizes[i - 1]);\r\n\r\n        // He initialization, weights random standard normal * sqrt(2 / # incoming connections)\r\n        weight.randomizeNormal();\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          weight.map((w) => w * Math.sqrt(2 / sizes[i - 1]));\r\n        }\r\n\r\n        this.weights.push(weight);\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Performs feedforward and returns the result as an array.\r\n   * @param {Matrix} input The input as a Matrix object (vector)\r\n   * @return {Array} The result as an array\r\n   */\r\n  predict(input) {\r\n    let output = input;\r\n\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wx + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, output);\r\n      z.add(bias);\r\n      output =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n    }\r\n\r\n    return output.toArray();\r\n  }\r\n\r\n  /**\r\n   * Performs stochastic gradient descent with the specified hyperparameters.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} miniBatchSize The size of the mini batches\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {Array} testDatas The optional test datas\r\n   */\r\n  stochasticGradientDescent(\r\n    trainDatas,\r\n    epochs,\r\n    miniBatchSize,\r\n    learningRate,\r\n    regularization,\r\n    testDatas = null\r\n  ) {\r\n    // Train datas = [trainData == [Matrix(input), Matrix(targetOutput)]]\r\n    const trainDataSize = trainDatas.length;\r\n\r\n    // Train for specified number of epochs\r\n    for (let i = 0; i < epochs; i++) {\r\n      // Shuffle the train datas every epoch\r\n      shuffle(trainDatas);\r\n\r\n      // Mini batches = [miniBatch == [trainData == [Matrix(input), Matrix(targetOutput)]]]\r\n      const miniBatches = [];\r\n      for (let j = 0; j < trainDataSize; j += miniBatchSize) {\r\n        // Mini batch = [trainData == [Matrix(input), Matrix(targetOutput)]]\r\n        const miniBatch = [];\r\n\r\n        // Train data = [Matrix(input), Matrix(targetOutput)]\r\n        for (let k = j; k < j + miniBatchSize; k++) {\r\n          miniBatch.push(trainDatas[k]);\r\n        }\r\n        miniBatches.push(miniBatch);\r\n      }\r\n\r\n      // Update each mini batch\r\n      for (let j = 0; j < miniBatches.length; j++) {\r\n        this.updateMiniBatch(\r\n          miniBatches[j],\r\n          learningRate,\r\n          regularization,\r\n          trainDataSize\r\n        );\r\n\r\n        // Accuracy on test set\r\n        if (LOG_MINI_BATCH_ACCURACY) {\r\n          const accuracy = this.accuracy(testDatas);\r\n          console.log(\r\n            \"Testing mini batch \" +\r\n              (j + 1) +\r\n              \"/\" +\r\n              miniBatches.length +\r\n              \": \" +\r\n              accuracy +\r\n              \"/\" +\r\n              testDatas.length +\r\n              \", \" +\r\n              (100 * accuracy) / testDatas.length +\r\n              \"%\"\r\n          );\r\n        } else {\r\n          // Only log this if not doing the more detailed accuracy logging\r\n          console.log(\r\n            \"Finished mini batch \" + (j + 1) + \"/\" + miniBatches.length\r\n          );\r\n        }\r\n\r\n        // Cost on train set\r\n        if (LOG_MINI_BATCH_COST) {\r\n          const trainCost = this.trainCost(trainDatas, regularization);\r\n          console.log(\r\n            \"Train cost: \" +\r\n              trainCost[0] +\r\n              \", \" +\r\n              trainCost[1] +\r\n              \"/\" +\r\n              trainDatas.length +\r\n              \", \" +\r\n              (100 * trainCost[1]) / trainDatas.length +\r\n              \"%\"\r\n          );\r\n        }\r\n      }\r\n\r\n      // Testing\r\n      if (testDatas !== null) {\r\n        const accuracy = this.accuracy(testDatas);\r\n        console.log(\r\n          \"Testing epoch \" +\r\n            (i + 1) +\r\n            \"/\" +\r\n            epochs +\r\n            \": \" +\r\n            accuracy +\r\n            \"/\" +\r\n            testDatas.length +\r\n            \", \" +\r\n            (100 * accuracy) / testDatas.length +\r\n            \"%\"\r\n        );\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Updates the mini batch by getting the gradient and then applying it.\r\n   * @param {Array} miniBatch The mini batch of train data\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {number} trainDataSize The size of the train data set\r\n   */\r\n  updateMiniBatch(miniBatch, learningRate, regularization, trainDataSize) {\r\n    // Cumulative gradients for mini batch\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Calculates the cumulative biases and weights gradients for all train data in the mini batch\r\n    for (let trainData of miniBatch) {\r\n      const input = trainData[0];\r\n      const targetOutput = trainData[1];\r\n      const gradientDelta = this.backprop(input, targetOutput);\r\n      const biasesGradientDelta = gradientDelta[0];\r\n      const weightsGradientDelta = gradientDelta[1];\r\n\r\n      // Do gradient checking\r\n      if (CHECK_GRADIENTS) {\r\n        const biasesCheck = this.gradientCheck(\r\n          biasesGradientDelta,\r\n          this.biases,\r\n          input,\r\n          targetOutput\r\n        );\r\n        console.log(\"Gradient check biases:\", biasesCheck);\r\n        const weightsCheck = this.gradientCheck(\r\n          weightsGradientDelta,\r\n          this.weights,\r\n          input,\r\n          targetOutput\r\n        );\r\n        console.log(\"Gradient check weights:\", weightsCheck);\r\n      }\r\n\r\n      // Add gradient delta to miniBatch\r\n      for (let i = 0; i < this.numLayers - 1; i++) {\r\n        biasesGradient[i].add(biasesGradientDelta[i]);\r\n        weightsGradient[i].add(weightsGradientDelta[i]);\r\n      }\r\n    }\r\n\r\n    // Apply the cumulative biases and weights gradients to the network's biases and weights\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const learningRateWithAvg = learningRate / miniBatch.length;\r\n\r\n      // Bias adjustment by gradient, no regularization\r\n      this.biases[i].sub(biasesGradient[i].mul(learningRateWithAvg));\r\n\r\n      // Weight regularization\r\n      this.weights[i].mul(1 - learningRate * (regularization / trainDataSize));\r\n\r\n      // Weight adjustment by gradient\r\n      this.weights[i].sub(weightsGradient[i].mul(learningRateWithAvg));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Performs backpropagation to calculate the gradient for one train data.\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} targetOutput The target output matrix\r\n   * @return {Array} The array consisting of the biasesGradient and weightsGradient for this one train data\r\n   */\r\n  backprop(input, targetOutput) {\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Feedforward, store zs and activations by layer\r\n    const zs = [];\r\n    const activations = [input];\r\n    this.forward(zs, activations);\r\n\r\n    // Output error = lossDerivativeWRTa hadamardProduct outputActivationFunctionDerivative(outputZ)\r\n    const outputError = this.lossFunction.outputError(\r\n      zs[zs.length - 1],\r\n      activations[activations.length - 1],\r\n      targetOutput,\r\n      this.outputActivationFunction\r\n    );\r\n\r\n    // Output biasesGradient is simply the output error\r\n    biasesGradient[biasesGradient.length - 1] = outputError;\r\n\r\n    // Output weightsGradient = outputError * beforeOutputActivationTranspose\r\n    weightsGradient[weightsGradient.length - 1] = Matrix.mul(\r\n      outputError,\r\n      Matrix.transpose(activations[activations.length - 2])\r\n    );\r\n\r\n    // Backpropagate error to hidden layers\r\n    let hiddenError = outputError;\r\n    for (let i = 2; i < this.numLayers; i++) {\r\n      // Hidden error = (nextWeightsTranspose * nextError which is last pass's hidden error) hadamardProduct hiddenActivationFunctionDerivative(z)\r\n      const nextWeightsTranspose = Matrix.transpose(\r\n        this.weights[this.weights.length - i + 1]\r\n      );\r\n      const hiddenActivationFunctionDerivative = this.hiddenActivationFunction.derivative(\r\n        zs[zs.length - i]\r\n      );\r\n      hiddenError = Matrix.mul(nextWeightsTranspose, hiddenError).mul(\r\n        hiddenActivationFunctionDerivative\r\n      );\r\n\r\n      // Hidden biasesGradient is simply the hidden error\r\n      biasesGradient[biasesGradient.length - i] = hiddenError;\r\n\r\n      // Hidden weightsGradient = hiddenError * beforeHiddenActivationsTranspose\r\n      weightsGradient[weightsGradient.length - i] = Matrix.mul(\r\n        hiddenError,\r\n        Matrix.transpose(activations[activations.length - i - 1])\r\n      );\r\n    }\r\n\r\n    return [biasesGradient, weightsGradient];\r\n  }\r\n\r\n  /**\r\n   * Feedforward, but also keeping record of the z's and activations per layer.\r\n   * @param {Array} zs The array to store the z records\r\n   * @param {Array} activations The array to store the activation records\r\n   */\r\n  forward(zs, activations) {\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wa + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, activations[i]);\r\n      z.add(bias);\r\n      zs.push(z);\r\n\r\n      const a =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n      activations.push(a);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Creates an empty gradient with the target array's shape.\r\n   * @param {Array} arr The target array\r\n   * @return {Array} The empty gradient array with in the shape of the target array\r\n   */\r\n  createEmptyGradient(arr) {\r\n    const gradient = [];\r\n    for (let targetMatrix of arr) {\r\n      const gradientMatrix = new Matrix(targetMatrix.rows, targetMatrix.cols);\r\n      gradient.push(gradientMatrix);\r\n    }\r\n    return gradient;\r\n  }\r\n\r\n  /**\r\n   * Returns a count of how many test cases were passed.\r\n   * @param {Array} testDatas The array of test datas\r\n   * @return {number} The number of test cases passed\r\n   */\r\n  accuracy(testDatas) {\r\n    let count = 0;\r\n\r\n    for (let testData of testDatas) {\r\n      const input = testData[0];\r\n      const outputArr = this.predict(input);\r\n      const targetOutputArr = testData[1].toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const targetOutputInteger = targetOutputArr.indexOf(\r\n        Math.max(...targetOutputArr)\r\n      );\r\n\r\n      // Count number correct\r\n      if (outputInteger === targetOutputInteger) {\r\n        count++;\r\n      }\r\n    }\r\n\r\n    return count;\r\n  }\r\n\r\n  /**\r\n   * Returns the train cost and correct count for the data set using the regularization parameter.\r\n   * @param {Array} datas The array of data to get the train cost for\r\n   * @param {number} regularization The regularization parameter\r\n   * @return {Array} The train cost and correct count\r\n   */\r\n  trainCost(datas, regularization) {\r\n    let cost = 0;\r\n    let count = 0;\r\n\r\n    // Add loss of each data point\r\n    for (let data of datas) {\r\n      const input = data[0];\r\n      const targetOutput = data[1];\r\n\r\n      const outputArr = this.predict(input);\r\n      const targetOutputArr = targetOutput.toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const targetOutputInteger = targetOutputArr.indexOf(\r\n        Math.max(...targetOutputArr)\r\n      );\r\n\r\n      // Count correct\r\n      if (outputInteger === targetOutputInteger) {\r\n        count++;\r\n      }\r\n\r\n      // Output cost\r\n      cost +=\r\n        this.lossFunction.fn(Matrix.vectorFromArray(outputArr), targetOutput) /\r\n        datas.length;\r\n\r\n      // Regularization cost\r\n      let squaredWeights = 0;\r\n      for (let weight of this.weights) {\r\n        for (let r = 0; r < weight.rows; r++) {\r\n          for (let c = 0; c < weight.cols; c++) {\r\n            squaredWeights += weight.data[r][c] ** 2;\r\n          }\r\n        }\r\n      }\r\n      cost += 0.5 * (regularization / datas.length) * squaredWeights;\r\n    }\r\n\r\n    return [cost, count];\r\n  }\r\n\r\n  /**\r\n   * Performs gradient checking technique, manually calculating the gradient using the limit definition the derivative and a small epsilon.\r\n   * @param {Array} gradient The gradient to check\r\n   * @param {Array} weightOrBias A reference to the neural network's biases or weights\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} targetOutput The targed output matrix\r\n   * @return {number} The euclidean norm ratio which should be less than 10^-7\r\n   */\r\n  gradientCheck(gradient, weightOrBias, input, targetOutput) {\r\n    const targetOutputArr = targetOutput.toArray();\r\n    const epsilon = 10 ** -7;\r\n    const gradApprox = this.createEmptyGradient(gradient);\r\n\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          // Save the original bias or weight value to restore it at the end\r\n          const original = weightOrBias[i].data[r][c];\r\n\r\n          // Calculate the loss with plus epsilon\r\n          weightOrBias[i].data[r][c] = original + epsilon;\r\n          const outputPlus = this.predict(input);\r\n          let lossPlus = 0;\r\n          for (let j = 0; j < outputPlus.length; j++) {\r\n            lossPlus += 0.5 * (targetOutputArr[j] - outputPlus[j]) ** 2;\r\n          }\r\n\r\n          // Calculate the loss with minus epsilon\r\n          weightOrBias[i].data[r][c] = original - epsilon;\r\n          const outputMinus = this.predict(input);\r\n          let lossMinus = 0;\r\n          for (let j = 0; j < outputMinus.length; j++) {\r\n            lossMinus += 0.5 * (targetOutputArr[j] - outputMinus[j]) ** 2;\r\n          }\r\n\r\n          // Limit definition of derivative\r\n          const gradApproxVal = (lossPlus - lossMinus) / (2 * epsilon);\r\n          gradApprox[i].data[r][c] = gradApproxVal;\r\n\r\n          // Restore the initial bias or weight value\r\n          weightOrBias[i].data[r][c] = original;\r\n        }\r\n      }\r\n    }\r\n\r\n    let paramSum = 0;\r\n    let paramApproxSum = 0;\r\n    let errorSum = 0;\r\n\r\n    // Sum all Euclidean components\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          const gradientVal = gradient[i].data[r][c];\r\n          const gradApproxVal = gradApprox[i].data[r][c];\r\n\r\n          paramSum += gradientVal ** 2;\r\n          paramApproxSum += gradApproxVal ** 2;\r\n          errorSum += (gradApproxVal - gradientVal) ** 2;\r\n        }\r\n      }\r\n    }\r\n\r\n    return (\r\n      Math.sqrt(errorSum) / (Math.sqrt(paramApproxSum) + Math.sqrt(paramSum))\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Automation for choosing the regularization parameter.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {Array} valDatas The array of validation datas\r\n   * @param {Array} testDatas The array of test datas\r\n   */\r\n  static chooseHypeparameters(trainDatas, valDatas, testDatas) {\r\n    const miniBatchOptions = [1, 10, 20, 50, 100];\r\n    const learningRateOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    const regularizationOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    let bestMiniBatch = 1;\r\n    let bestLearningRate = 0.01;\r\n    let bestRegularization = 0.01;\r\n    let bestAccuracy = 0;\r\n    let bestNetwork = null;\r\n\r\n    // Train a different model for each combination of options\r\n    for (let i = 0; i < miniBatchOptions.length; i++) {\r\n      for (let j = 0; j < learningRateOptions.length; j++) {\r\n        for (let k = 0; k < regularizationOptions.length; k++) {\r\n          const curMiniBatch = miniBatchOptions[i];\r\n          const curLearningRate = learningRateOptions[j];\r\n          const curRegularization = regularizationOptions[k];\r\n\r\n          // Train the network using the current settings\r\n          const curNetwork = new FFNN([784, 30, 10]);\r\n          curNetwork.stochasticGradientDescent(\r\n            trainDatas,\r\n            1,\r\n            curMiniBatch,\r\n            curLearningRate,\r\n            curRegularization\r\n          );\r\n\r\n          // Evaluate accuracy using validation set\r\n          const valAccuracy = curNetwork.accuracy(valDatas);\r\n\r\n          // Choose best neural network based on validation set\r\n          if (valAccuracy > bestAccuracy) {\r\n            bestMiniBatch = curMiniBatch;\r\n            bestLearningRate = curLearningRate;\r\n            bestRegularization = curRegularization;\r\n            bestAccuracy = valAccuracy;\r\n            bestNetwork = curNetwork;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    console.log(\"Best mini batch size: \" + bestMiniBatch);\r\n    console.log(\"Best learning rate: \" + bestLearningRate);\r\n    console.log(\"Best regularization: \" + bestRegularization);\r\n    console.log(\r\n      \"Best validation set: \" +\r\n        bestAccuracy +\r\n        \"/\" +\r\n        valDatas.length +\r\n        \", \" +\r\n        (100 * bestAccuracy) / valDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Test the generalization of the selected network on the test set\r\n    const generalizationAccuracy = bestNetwork.accuracy(testDatas);\r\n    console.log(\r\n      \"Best test set: \" +\r\n        generalizationAccuracy +\r\n        \"/\" +\r\n        testDatas.length +\r\n        \", \" +\r\n        (100 * generalizationAccuracy) / testDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Log the best neural network\r\n    console.log(\"Best network:\", JSON.stringify(bestNetwork));\r\n  }\r\n}\r\n\r\nexport default FFNN;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass Conv {\r\n  /**\r\n   * Create a Conv layer with the given settings or loads a pretrained one.\r\n   * @param {number} numFilters The number of filters\r\n   * @param {number} filterSize The filter size, square only\r\n   * @param {Conv} conv The pretrained Conv\r\n   */\r\n  constructor(numFilters, filterSize = 3, conv = null) {\r\n    if (conv !== null) {\r\n      this.numFilters = conv.numFilters;\r\n      this.filterSize = conv.filterSize;\r\n      this.filters = [];\r\n\r\n      for (let filter of conv.filters) {\r\n        this.filters.push(new Matrix(null, null, filter));\r\n      }\r\n    } else {\r\n      this.numFilters = numFilters;\r\n      this.filterSize = filterSize;\r\n      this.filters = [];\r\n\r\n      for (let i = 0; i < numFilters; i++) {\r\n        this.filters.push(\r\n          new Matrix(filterSize, filterSize)\r\n            .randomizeNormal()\r\n            .div(filterSize ** 2)\r\n        );\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generator method for iterating over the image.\r\n   * @param {Matrix} image The image to iterate over\r\n   * @return {Array} The image region as a 2D Matrix and the coordinates of the region\r\n   */\r\n  *iterateRegions(image) {\r\n    const h = image.rows;\r\n    const w = image.cols;\r\n    const f = this.filterSize;\r\n\r\n    for (let y = 0; y < h - f + 1; y++) {\r\n      for (let x = 0; x < w - f + 1; x++) {\r\n        yield [image.getRegion(x, y, f, f), y, x];\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward implementation assuming a very simple CNN architecture (single channel).\r\n   * @param {Matrix} input The input image\r\n   * @return {Array} An array of images processed by the filters\r\n   */\r\n  forward(input) {\r\n    this.lastInput = input;\r\n\r\n    const h = input.rows;\r\n    const w = input.cols;\r\n    const f = this.filterSize;\r\n\r\n    const outputs = [];\r\n\r\n    // For each filter\r\n    for (let filter of this.filters) {\r\n      const output = new Matrix(h - f + 1, w - f + 1);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(input)) {\r\n        // Apply the filter to the region\r\n        for (let r = 0; r < f; r++) {\r\n          for (let c = 0; c < f; c++) {\r\n            output.data[y][x] += region.data[r][c] * filter.data[r][c];\r\n          }\r\n        }\r\n      }\r\n\r\n      outputs.push(output);\r\n    }\r\n\r\n    return outputs;\r\n  }\r\n\r\n  /**\r\n   * Backpropagation assuming only a single channel.\r\n   * @param {Array} dLdOut Array of loss gradients w.r.t. the conv layer's outputs\r\n   * @param {number} learningRate The learning rate\r\n   */\r\n  backprop(dLdOut, learningRate) {\r\n    const dLdFilters = [];\r\n\r\n    // For each filter\r\n    for (let i = 0; i < this.filters.length; i++) {\r\n      const filter = this.filters[i];\r\n      const dLdFilter = new Matrix(filter.rows, filter.cols);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(this.lastInput)) {\r\n        // Accumulate filter gradient\r\n        dLdFilter.add(region.mul(dLdOut[i].data[y][x]));\r\n      }\r\n      dLdFilters.push(dLdFilter);\r\n    }\r\n\r\n    // Update filters\r\n    for (let i = 0; i < this.filters.length; i++) {\r\n      const filter = this.filters[i];\r\n      const dLdFilter = dLdFilters[i];\r\n\r\n      filter.sub(dLdFilter.mul(learningRate));\r\n    }\r\n  }\r\n}\r\n\r\nexport default Conv;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass MaxPool {\r\n  /**\r\n   * Creates a max pool with the given size or loads the pool size from the given pool.\r\n   * @param {number} poolSize The pool size, square only, stride same as size\r\n   * @param {MaxPool} pool The preset pool, only containing size information\r\n   */\r\n  constructor(poolSize = 2, pool = null) {\r\n    if (pool !== null) {\r\n      this.poolSize = pool.poolSize;\r\n    } else {\r\n      this.poolSize = poolSize;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generator method for iterating over the image.\r\n   * @param {Matrix} image The image to iterate over\r\n   * @return {Array} The image region as a 2D Matrix and the coordinates of the region\r\n   */\r\n  *iterateRegions(image) {\r\n    const h = image.rows;\r\n    const w = image.cols;\r\n    const s = this.poolSize;\r\n\r\n    const newH = Math.floor(h / s);\r\n    const newW = Math.floor(w / s);\r\n\r\n    for (let y = 0; y < newH; y++) {\r\n      for (let x = 0; x < newW; x++) {\r\n        yield [image.getRegion(x * s, y * s, s, s), y, x];\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on the max pool.\r\n   * @param {Array} input The array of input images passed through a conv layer\r\n   * @return {Array} An array of images processed by the max pool\r\n   */\r\n  forward(input) {\r\n    this.lastInput = input;\r\n\r\n    const h = input[0].rows;\r\n    const w = input[0].cols;\r\n    const s = this.poolSize;\r\n\r\n    const newH = Math.floor(h / s);\r\n    const newW = Math.floor(w / s);\r\n\r\n    const outputs = [];\r\n\r\n    // For each channel\r\n    for (let channel of input) {\r\n      const output = new Matrix(newH, newW);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(channel)) {\r\n        // Apply the pool to the region\r\n        const [max, _, __] = region.max();\r\n        output.data[y][x] = max;\r\n      }\r\n\r\n      outputs.push(output);\r\n    }\r\n\r\n    return outputs;\r\n  }\r\n\r\n  /**\r\n   * Backpropagation on the max pool.\r\n   * @param {Array} dLdOut Array of loss gradients w.r.t. the pool layer's outputs\r\n   * @return {Array} Array of loss gradients w.r.t. the pool layer's inputs\r\n   */\r\n  backprop(dLdOut) {\r\n    const dLdInputs = [];\r\n\r\n    // For each channel\r\n    for (let i = 0; i < this.lastInput.length; i++) {\r\n      const channel = this.lastInput[i];\r\n      const dLdInput = new Matrix(channel.rows, channel.cols);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(channel)) {\r\n        // Apply the pool to the region\r\n        const [max, _, __] = region.max();\r\n\r\n        // Find all pixels matching the max value and replace with corresponding dLdOut\r\n        for (let r = 0; r < region.rows; r++) {\r\n          for (let c = 0; c < region.cols; c++) {\r\n            if (region.data[r][c] === max) {\r\n              dLdInput.data[y * this.poolSize + r][x * this.poolSize + c] =\r\n                dLdOut[i].data[y][x];\r\n            }\r\n          }\r\n        }\r\n      }\r\n\r\n      dLdInputs.push(dLdInput);\r\n    }\r\n\r\n    return dLdInputs;\r\n  }\r\n}\r\n\r\nexport default MaxPool;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass Softmax {\r\n  /**\r\n   * Creates a new softmax layer or loads the pretrained layer.\r\n   * @param {number} inputLen The input layer size\r\n   * @param {number} nodes The output layer size\r\n   * @param {Softmax} softmax The pretrained softmax layer\r\n   */\r\n  constructor(inputLen, nodes, softmax = null) {\r\n    if (softmax !== null) {\r\n      this.weights = new Matrix(null, null, softmax.weights);\r\n      this.biases = new Matrix(null, null, softmax.biases);\r\n    } else {\r\n      this.weights = new Matrix(inputLen, nodes)\r\n        .randomizeNormal()\r\n        .div(inputLen);\r\n      this.biases = new Matrix(1, nodes);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on the softmax layer.\r\n   * @param {Array} input The array of input images passed through a max pool layer\r\n   * @return {Matrix} A row vector of final output probabilities\r\n   */\r\n  forward(input) {\r\n    this.lastInputShape = [input.length, input[0].rows, input[0].cols];\r\n\r\n    // Flattened row vector\r\n    const flattened = new Matrix(\r\n      1,\r\n      input[0].rows * input[0].cols * input.length\r\n    );\r\n    let flattenedCol = 0;\r\n\r\n    // Flatten\r\n    for (let channel of input) {\r\n      for (let r = 0; r < channel.rows; r++) {\r\n        for (let c = 0; c < channel.cols; c++) {\r\n          flattened.data[0][flattenedCol] = channel.data[r][c];\r\n          flattenedCol++;\r\n        }\r\n      }\r\n    }\r\n    this.lastInput = flattened;\r\n\r\n    // Product sum and bias\r\n    const z = Matrix.mul(flattened, this.weights).add(this.biases);\r\n    this.lastZ = z;\r\n\r\n    // Softmax function\r\n    const exp = Matrix.map(z, Math.exp);\r\n    let sum = 0;\r\n    for (let c = 0; c < exp.cols; c++) {\r\n      sum += exp.data[0][c];\r\n    }\r\n    return exp.div(sum);\r\n  }\r\n\r\n  /**\r\n   * Backpropagation on the softmax layer.\r\n   * @param {Matrix} dLdOut Row vector of loss gradients w.r.t. the softmax layer's outputs\r\n   * @param {number} learningRate The learning rate\r\n   * @return {Array} Array of loss gradients w.r.t. the softmax layer's inputs\r\n   */\r\n  backprop(dLdOut, learningRate) {\r\n    // Find correct label index\r\n    let correctI = 0;\r\n    for (let i = 0; i < dLdOut.cols; i++) {\r\n      if (dLdOut.data[0][i] !== 0) {\r\n        correctI = i;\r\n        break;\r\n      }\r\n    }\r\n    const gradient = dLdOut.data[0][correctI];\r\n\r\n    // e^z\r\n    const zExp = Matrix.map(this.lastZ, Math.exp);\r\n    const zExpCorrect = zExp.data[0][correctI];\r\n\r\n    // Sum of all e^z\r\n    let S = 0;\r\n    for (let c = 0; c < zExp.cols; c++) {\r\n      S += zExp.data[0][c];\r\n    }\r\n\r\n    /* Gradients of output w.r.t z\r\n          = -zExpCorrect * zExp / (S ** 2), for wrong label\r\n          = zExpCorrect * (S - zExpCorrect) / (S ** 2), for correct label\r\n      */\r\n    const dOutdZ = zExp.mul(-zExpCorrect / S ** 2);\r\n    dOutdZ.data[0][correctI] = (zExpCorrect * (S - zExpCorrect)) / S ** 2;\r\n\r\n    // Gradients of z w.r.t. weights/biases/input, dZdB = 1, so can ignore\r\n    const dZdW = this.lastInput;\r\n    const dZdInputs = this.weights;\r\n\r\n    // Gradients of loss w.r.t. z\r\n    const dLdZ = dOutdZ.mul(gradient);\r\n\r\n    // Gradients of loss w.r.t. weights/biases/input\r\n    const dLdW = Matrix.mul(Matrix.transpose(dZdW), dLdZ);\r\n    const dLdB = dLdZ;\r\n    const dLdInputs = Matrix.mul(dLdZ, Matrix.transpose(dZdInputs));\r\n\r\n    // Update weights and biases\r\n    this.weights.sub(dLdW.mul(learningRate));\r\n    this.biases.sub(dLdB.mul(learningRate));\r\n\r\n    // Reshape to original input shape\r\n    const channels = this.lastInputShape[0];\r\n    const rows = this.lastInputShape[1];\r\n    const cols = this.lastInputShape[2];\r\n    let index = 0;\r\n    const dLdInputsReshaped = [];\r\n\r\n    for (let i = 0; i < channels; i++) {\r\n      const dLdInputChannel = new Matrix(rows, cols);\r\n\r\n      for (let r = 0; r < rows; r++) {\r\n        for (let c = 0; c < cols; c++) {\r\n          dLdInputChannel.data[r][c] = dLdInputs.data[0][index];\r\n          index++;\r\n        }\r\n      }\r\n\r\n      dLdInputsReshaped.push(dLdInputChannel);\r\n    }\r\n\r\n    return dLdInputsReshaped;\r\n  }\r\n}\r\n\r\nexport default Softmax;\r\n","import Matrix from \"../matrix\";\r\nimport Conv from \"./conv\";\r\nimport MaxPool from \"./maxpool\";\r\nimport Softmax from \"./softmax\";\r\nimport { shuffle } from \"../utils\";\r\n\r\nconst OUTPUT_NETWORK = true;\r\n\r\nclass CNN {\r\n  /**\r\n   * Creates a new simple CNN or loads a pretrained model.\r\n   * @param {CNN} cnn The pretrained CNN model\r\n   */\r\n  constructor(cnn = null) {\r\n    if (cnn !== null) {\r\n      this.conv = new Conv(null, null, cnn.conv);\r\n      this.pool = new MaxPool(null, cnn.pool);\r\n      this.softmax = new Softmax(null, null, cnn.softmax);\r\n    } else {\r\n      this.conv = new Conv(8); // 28x28x1 -> 26x26x8\r\n      this.pool = new MaxPool(); // 26x26x8 -> 13x13x8\r\n      this.softmax = new Softmax(13 * 13 * 8, 10); // 13x13x8 -> 10\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Passes the image through the CNN.\r\n   * @param {Matrix} image The image as a 2D matrix\r\n   * @return {Array} The result as an array of probabilities\r\n   */\r\n  predict(image) {\r\n    // Out is a row vector of probabilities\r\n    let out = this.conv.forward(image); // 28x28x1 -> 26x26x8\r\n    out = this.pool.forward(out); // 26x26x8 -> 13x13x8\r\n    out = this.softmax.forward(out); // 13x13x8 -> 10\r\n    return out.toArray();\r\n  }\r\n\r\n  /**\r\n   * Trains the CNN.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} learningRate The learning rate\r\n   * @param {Array} testDatas The optional array of test datas\r\n   */\r\n  train(trainDatas, epochs, learningRate, testDatas = null) {\r\n    for (let epoch = 0; epoch < epochs; epoch++) {\r\n      shuffle(trainDatas);\r\n\r\n      let loss = 0;\r\n      let numCorrect = 0;\r\n\r\n      for (let i = 0; i < trainDatas.length; i++) {\r\n        const trainData = trainDatas[i];\r\n        const image = trainData[0];\r\n        const label = trainData[1];\r\n\r\n        // Label is a column vector\r\n        const [_, labelNum, __] = label.max();\r\n\r\n        // Forward, out is a row vector\r\n        const [out, l, acc] = this.forward(image, label);\r\n\r\n        // Save loss and number correct for printing\r\n        loss += l;\r\n        numCorrect += acc;\r\n\r\n        // Initial gradient = dL/dOut = d(-ln(Out))/dOut = -1/Out\r\n        let gradient = new Matrix(1, 10);\r\n        gradient.data[0][labelNum] = -1 / out.data[0][labelNum];\r\n\r\n        // Backprop\r\n        gradient = this.softmax.backprop(gradient, learningRate);\r\n        gradient = this.pool.backprop(gradient);\r\n        this.conv.backprop(gradient, learningRate);\r\n\r\n        if (i % 100 === 99) {\r\n          console.log(\r\n            \"Training: \" +\r\n              (i + 1) +\r\n              \"/\" +\r\n              trainDatas.length +\r\n              \" | Average Loss: \" +\r\n              loss / 100 +\r\n              \" | Accuracy: \" +\r\n              numCorrect +\r\n              \"/100\"\r\n          );\r\n          loss = 0;\r\n          numCorrect = 0;\r\n        }\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n\r\n    if (testDatas !== null) {\r\n      this.test(testDatas);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on one image-label pair.\r\n   * @param {Matrix} image The image to feedforward\r\n   * @param {Matrix} label The correct label as a one-hot column vector\r\n   * @return {Array} The output probabilities as a 1x10 Matrix, the loss, and whether the CNN predicted correctly\r\n   */\r\n  forward(image, label) {\r\n    // Out is a row vector of probabilities\r\n    let out = this.conv.forward(image); // 28x28x1 -> 26x26x8\r\n    out = this.pool.forward(out); // 26x26x8 -> 13x13x8\r\n    out = this.softmax.forward(out); // 13x13x8 -> 10\r\n\r\n    // Label is a column vector\r\n    const [_, labelNum, __] = label.max();\r\n    const [___, ____, outMax] = out.max();\r\n\r\n    // Calculate cross entropy loss and accuracy\r\n    const loss = -Math.log(out.data[0][labelNum]);\r\n    const acc = outMax === labelNum ? 1 : 0;\r\n\r\n    return [out, loss, acc];\r\n  }\r\n\r\n  /**\r\n   * Prints the average test loss and accuracy of the CNN on the test set.\r\n   * @param {Array} testDatas The array of test datas\r\n   */\r\n  test(testDatas) {\r\n    let loss = 0;\r\n    let numCorrect = 0;\r\n\r\n    // Calculate loss and number correct for all test samples\r\n    for (let testData of testDatas) {\r\n      const image = testData[0];\r\n      const label = testData[1];\r\n\r\n      const [_, l, acc] = this.forward(image, label);\r\n      loss += l;\r\n      numCorrect += acc;\r\n    }\r\n\r\n    // Print the loss and accuracy\r\n    const numTests = testDatas.length;\r\n    console.log(\"Test loss:\", loss / numTests);\r\n    console.log(\r\n      \"Test accuracy: \" +\r\n        numCorrect +\r\n        \"/\" +\r\n        numTests +\r\n        \", \" +\r\n        (100 * numCorrect) / numTests +\r\n        \"%\"\r\n    );\r\n  }\r\n}\r\n\r\nexport default CNN;\r\n","import React, { Component } from \"react\";\nimport Title from \"./components/title\";\nimport Description from \"./components/description\";\nimport Button from \"./components/button\";\nimport Canvas from \"./components/canvas\";\nimport GithubCorner from \"react-github-corner\";\nimport loadMNIST from \"./logic/mnist\";\nimport mnistSamples from \"./data/mnist-samples.json\";\nimport ffnnModel from \"./data/ffnn-model.json\";\nimport cnnModel from \"./data/cnn-model.json\";\nimport Matrix from \"./logic/matrix\";\nimport FFNN from \"./logic/ffnn/ffnn\";\nimport CNN from \"./logic/cnn/cnn\";\n\nconst TRAIN_FFNN = false;\nconst TRAIN_CNN = false;\nconst NEW_FFNN = false;\nconst NEW_CNN = false;\nconst USE_STANDARDIZATION = false;\n\nconst LOAD_TRAIN = false;\nconst LOAD_VAL = false;\nconst LOAD_TEST = false;\n\nconst OUTPUT_FFNN_ACCURACY = false;\nconst OUTPUT_CNN_ACCURACY = false;\nconst OUTPUT_MNIST = false;\n\nconst NUM_TRAIN = 50000;\nconst NUM_VAL = 10000;\nconst NUM_TEST = 10000;\nconst EPSILON = 10 ** -100;\n\nconst NUM_MNIST_SAMPLES = 5;\n\nclass App extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      ffnnOutputArr: [],\n      cnnOutputArr: [],\n      ffnnPred: \"\",\n      cnnPred: \"\",\n    };\n\n    // For training\n    if (TRAIN_FFNN || TRAIN_CNN) {\n      // Do everything after loading\n      loadMNIST((data) => {\n        this.mnist = data;\n        console.log(\"All files loaded\");\n\n        if (OUTPUT_MNIST) {\n          console.log(this.mnist);\n        }\n\n        // Format and normalize data\n        this.formatData();\n        this.normalizeData();\n        if (USE_STANDARDIZATION) {\n          this.standardizeData();\n        }\n\n        // FFNN\n        if (TRAIN_FFNN) {\n          console.log(\"Starting FFNN training\");\n\n          // Create new or load model\n          if (NEW_FFNN) {\n            this.ffnn = new FFNN([784, 30, 10]);\n          } else {\n            this.ffnn = new FFNN(null, ffnnModel);\n\n            if (OUTPUT_FFNN_ACCURACY) {\n              const accuracy = this.ffnn.accuracy(this.ffnnTestDatas);\n              console.log(\n                \"Accuracy: \" +\n                  accuracy +\n                  \"/\" +\n                  this.ffnnTestDatas.length +\n                  \", \" +\n                  (100 * accuracy) / this.ffnnTestDatas.length +\n                  \"%\"\n              );\n            }\n          }\n\n          // Remember to use much smaller learning rate when using ReLU\n          this.ffnn.stochasticGradientDescent(\n            this.ffnnTrainDatas,\n            1,\n            10,\n            0.03,\n            1.0,\n            this.ffnnTestDatas\n          );\n        }\n\n        // CNN\n        if (TRAIN_CNN) {\n          console.log(\"Starting CNN training\");\n\n          // Create new or load model\n          if (NEW_CNN) {\n            this.cnn = new CNN();\n          } else {\n            this.cnn = new CNN(cnnModel);\n\n            if (OUTPUT_CNN_ACCURACY) {\n              this.cnn.test(this.cnnTestDatas);\n            }\n          }\n\n          this.cnn.train(this.cnnTrainDatas, 1, 0.005, this.cnnTestDatas);\n        }\n      });\n    } else {\n      // No training, load both models\n      this.ffnn = new FFNN(null, ffnnModel);\n      this.cnn = new CNN(cnnModel);\n    }\n\n    this.canvasRef = React.createRef();\n  }\n\n  componentDidMount() {\n    // this.saveSamples();\n    this.showSamples();\n  }\n\n  /**\n   * Outputs JSON of MNIST samples.\n   */\n  saveSamples() {\n    const samples = [];\n\n    // For each digit\n    for (let i = 0; i < 10; i++) {\n      const sampleImages = [];\n\n      // Find digit samples from test set\n      for (let j = 0; j < this.mnist.testImages.length; j++) {\n        if (this.mnist.testLabels[j] === i) {\n          sampleImages.push(Array.from(this.mnist.testImages[j]));\n\n          // Found desired number of samples\n          if (sampleImages.length === NUM_MNIST_SAMPLES) {\n            break;\n          }\n        }\n      }\n\n      samples.push(sampleImages);\n    }\n\n    console.log(JSON.stringify(samples));\n  }\n\n  /**\n   * Shows MNISt samples.\n   */\n  showSamples() {\n    // For each digit\n    for (let i = 0; i < 10; i++) {\n      // For the desired number of samples\n      for (let j = 0; j < NUM_MNIST_SAMPLES; j++) {\n        // Retrieve canvas and context\n        const canvas = document.getElementById(`canvas-${i}-${j}`);\n        const ctx = canvas.getContext(\"2d\");\n\n        for (let y = 0; y < 28; y++) {\n          for (let x = 0; x < 28; x++) {\n            // Create single pixel block and retrieve saved pixel\n            const block = ctx.createImageData(1, 1);\n            const newVal = 255 * mnistSamples[i][j][y * 28 + x];\n\n            // Assign loaded pixel value\n            block.data[0] = newVal;\n            block.data[1] = newVal;\n            block.data[2] = newVal;\n            block.data[3] = 255;\n\n            // Draw to canvas\n            ctx.putImageData(block, x, y);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Formats data to suitable format to pass to FFNN and CNN.\n   */\n  formatData() {\n    if (LOAD_TRAIN) {\n      console.log(\"Formatting train data\");\n      if (TRAIN_FFNN) {\n        this.ffnnTrainDatas = this.loadDatas(\n          this.mnist.trainImages.slice(0, NUM_TRAIN),\n          this.mnist.trainLabels.slice(0, NUM_TRAIN),\n          true\n        );\n      }\n      if (TRAIN_CNN) {\n        this.cnnTrainDatas = this.loadDatas(\n          this.mnist.trainImages.slice(0, NUM_TRAIN),\n          this.mnist.trainLabels.slice(0, NUM_TRAIN),\n          false\n        );\n      }\n    }\n\n    if (LOAD_VAL) {\n      console.log(\"Formatting validation data\");\n      if (TRAIN_FFNN) {\n        this.ffnnValDatas = this.loadDatas(\n          this.mnist.trainImages.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\n          this.mnist.trainLabels.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\n          true\n        );\n      }\n      if (TRAIN_CNN) {\n        this.cnnValDatas = this.loadDatas(\n          this.mnist.trainImages.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\n          this.mnist.trainLabels.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\n          false\n        );\n      }\n    }\n\n    if (LOAD_TEST) {\n      console.log(\"Formatting test data\");\n      if (TRAIN_FFNN) {\n        this.ffnnTestDatas = this.loadDatas(\n          this.mnist.testImages.slice(0, NUM_TEST),\n          this.mnist.testLabels.slice(0, NUM_TEST),\n          true\n        );\n      }\n      if (TRAIN_CNN) {\n        this.cnnTestDatas = this.loadDatas(\n          this.mnist.testImages.slice(0, NUM_TEST),\n          this.mnist.testLabels.slice(0, NUM_TEST),\n          false\n        );\n      }\n    }\n  }\n\n  /**\n   * Loads data into image-label pairs.\n   * @param {Array} images Array of images\n   * @param {Array} labels Array of labels\n   * @param {boolean} isFFNN Whether to load the data for FFNN or CNN\n   * @return {Array} Array of image-label pairs\n   */\n  loadDatas(images, labels, isFFNN) {\n    const datas = [];\n\n    for (let i = 0; i < images.length; i++) {\n      const inputArr = images[i];\n      const targetInt = labels[i];\n      const targetArr = [];\n\n      for (let j = 0; j < 10; j++) {\n        if (targetInt === j) {\n          targetArr.push(1);\n        } else {\n          targetArr.push(0);\n        }\n      }\n\n      datas.push([\n        isFFNN\n          ? Matrix.vectorFromArray(inputArr)\n          : Matrix.matrixFromArray(inputArr, 28, 28),\n        Matrix.vectorFromArray(targetArr),\n      ]);\n    }\n\n    return datas;\n  }\n\n  /**\n   * Normalizes all data.\n   */\n  normalizeData() {\n    // Normalize train images\n    if (LOAD_TRAIN) {\n      console.log(\"Normalizing train data\");\n      if (TRAIN_FFNN) {\n        for (let trainData of this.ffnnTrainDatas) {\n          trainData[0].div(255);\n        }\n      }\n      if (TRAIN_CNN) {\n        for (let trainData of this.cnnTrainDatas) {\n          trainData[0].div(255);\n        }\n      }\n    }\n\n    // Normalize validation images\n    if (LOAD_VAL) {\n      console.log(\"Normalizing validation data\");\n      if (TRAIN_FFNN) {\n        for (let valData of this.ffnnValDatas) {\n          valData[0].div(255);\n        }\n      }\n      if (TRAIN_CNN) {\n        for (let valData of this.cnnValDatas) {\n          valData[0].div(255);\n        }\n      }\n    }\n\n    // Normalize test images\n    if (LOAD_TEST) {\n      console.log(\"Normalizing test data\");\n      if (TRAIN_FFNN) {\n        for (let testData of this.ffnnTestDatas) {\n          testData[0].div(255);\n        }\n      }\n      if (TRAIN_CNN) {\n        for (let testData of this.cnnTestDatas) {\n          testData[0].div(255);\n        }\n      }\n    }\n  }\n\n  /**\n   * Standardizes all data.\n   */\n  standardizeData() {\n    // Neural network does NOT have predefined train mean and STD, calculate them and use that to standardize everything\n    if (!this.ffnn.hasOwnProperty(\"trainMean\")) {\n      const mean = new Matrix(784, 1); // mean = sum(pixels) / numTrain\n      const std = new Matrix(784, 1); // std = sqrt(sum((pixels - mean)^2) / numTrain)\n\n      // Calculate sum(pixels)\n      console.log(\"Calculating train data mean\");\n      for (let trainData of this.ffnnTrainDatas) {\n        mean.add(trainData[0]);\n      }\n\n      // Divide by total number of train datas\n      mean.map((x) => x / this.ffnnTrainDatas.length);\n\n      // Calculate sum((pixels - mean)^2)\n      console.log(\"Calculating train data standard deviation\");\n      for (let trainData of this.ffnnTrainDatas) {\n        std.add(Matrix.sub(trainData[0], mean).map((x) => x ** 2));\n      }\n\n      // Divide by total number of train datas and square root\n      std.map((x) => Math.sqrt(x / this.ffnnTrainDatas.length));\n\n      // Save to neural network\n      this.ffnn.trainMean = mean;\n      this.ffnn.trainSTD = std;\n    }\n\n    // Retrieve mean and std from neural network\n    const mean = this.ffnn.trainMean;\n    const std = this.ffnn.trainSTD;\n\n    // Standardize train images, add small epsilon so never divide by zero\n    if (LOAD_TRAIN) {\n      console.log(\"Standardizing train data\");\n      for (let i = 0; i < this.ffnnTrainDatas.length; i++) {\n        this.ffnnTrainDatas[i][0]\n          .sub(mean)\n          .div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n\n    // Standardize validation images, add small epsilon so never divide by zero\n    if (LOAD_VAL) {\n      console.log(\"Standardizing validation data\");\n      for (let i = 0; i < this.ffnnValDatas.length; i++) {\n        this.ffnnValDatas[i][0]\n          .sub(mean)\n          .div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n\n    // Standardize test images, add small epsilon so never divide by zero\n    if (LOAD_TEST) {\n      console.log(\"Standardizing test data\");\n      for (let i = 0; i < this.ffnnTestDatas.length; i++) {\n        this.ffnnTestDatas[i][0]\n          .sub(mean)\n          .div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n  }\n\n  /**\n   * Makes predictions on the canvas input using FFNN and CNN and sets component state.\n   */\n  handlePredict = () => {\n    if (this.ffnn !== undefined && this.cnn !== undefined) {\n      const inputArr = this.canvasRef.current.predict();\n      const ffnnInput = Matrix.vectorFromArray(inputArr);\n      const cnnInput = Matrix.matrixFromArray(inputArr, 28, 28);\n\n      if (USE_STANDARDIZATION) {\n        ffnnInput\n          .sub(this.ffnn.trainMean)\n          .div(Matrix.map(this.ffnn.trainSTD, (x) => x + EPSILON));\n      }\n\n      const ffnnOutputArr = this.ffnn.predict(ffnnInput);\n      const ffnnPred = ffnnOutputArr.indexOf(Math.max(...ffnnOutputArr));\n\n      const cnnOutputArr = this.cnn.predict(cnnInput);\n      const cnnPred = cnnOutputArr.indexOf(Math.max(...cnnOutputArr));\n\n      // Update state about prediction and displayed probabilities\n      this.setState({\n        ffnnOutputArr,\n        cnnOutputArr,\n        ffnnPred,\n        cnnPred,\n      });\n    }\n  };\n\n  /**\n   * Clears the canvas and resets component state.\n   */\n  handleClear = () => {\n    this.canvasRef.current.erase();\n\n    this.setState({\n      ffnnOutputArr: [],\n      cnnOutputArr: [],\n      ffnnPred: \"\",\n      cnnPred: \"\",\n    });\n  };\n\n  render() {\n    const sampleImages = [];\n    for (let i = 0; i < 10; i++) {\n      const cols = [];\n\n      for (let j = 0; j < NUM_MNIST_SAMPLES; j++) {\n        const col = (\n          <div className=\"col-auto\" key={`col-${i}-${j}`}>\n            <canvas\n              id={`canvas-${i}-${j}`}\n              width=\"28\"\n              height=\"28\"\n              style={{\n                border: \"2px solid aquamarine\",\n                borderRadius: \"5px\",\n                backgroundColor: \"white\",\n              }}\n            ></canvas>\n          </div>\n        );\n        cols.push(col);\n      }\n\n      const row = (\n        <div className=\"row justify-content-center\" key={`row-${i}`}>\n          {cols}\n        </div>\n      );\n      sampleImages.push(row);\n    }\n\n    const ffnnProbs = [];\n    for (let i = 0; i < 10; i++) {\n      const prob = (\n        <div className=\"row\" key={\"fnn\" + i}>\n          <div className=\"col text-right\">\n            <h5>{i}:</h5>\n          </div>\n          <div className=\"col text-left\">\n            <h5>\n              {this.state.ffnnOutputArr.length > 0\n                ? (this.state.ffnnOutputArr[i] * 100).toFixed(1) + \"%\"\n                : \"\"}\n            </h5>\n          </div>\n        </div>\n      );\n      ffnnProbs.push(prob);\n    }\n    const cnnProbs = [];\n    for (let i = 0; i < 10; i++) {\n      const prob = (\n        <div className=\"row\" key={\"cnn\" + i}>\n          <div className=\"col text-right\">\n            <h5>{i}:</h5>\n          </div>\n          <div className=\"col text-left\">\n            <h5>\n              {this.state.cnnOutputArr.length > 0\n                ? (this.state.cnnOutputArr[i] * 100).toFixed(1) + \"%\"\n                : \"\"}\n            </h5>\n          </div>\n        </div>\n      );\n      cnnProbs.push(prob);\n    }\n\n    return (\n      <div className=\"App container text-center pt-5\">\n        <div className=\"row\">\n          <div className=\"col\">\n            <Title text=\"Digit Recognizer\" />\n          </div>\n        </div>\n        <div className=\"row\">\n          <div className=\"col\">\n            <Description\n              text={\n                \"Digit recognition with feedforward (FFNN) and convolutional (CNN) neural networks.\"\n              }\n            />\n          </div>\n        </div>\n        <div className=\"row pt-3\">\n          <div className=\"col\">\n            <h3>MNIST Samples:</h3>\n          </div>\n        </div>\n        {sampleImages}\n        <div className=\"row justify-content-center pt-5\">\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Predict\" onClick={this.handlePredict} />\n          </div>\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Clear\" onClick={this.handleClear} />\n          </div>\n        </div>\n        <div className=\"row pt-3\">\n          <div className=\"col\">\n            <Canvas ref={this.canvasRef} />\n          </div>\n        </div>\n        <div className=\"row\">\n          <div className=\"col\">\n            <canvas\n              id=\"canvas28\"\n              width=\"28\"\n              height=\"28\"\n              style={{\n                border: \"2px solid aquamarine\",\n                borderRadius: \"5px\",\n                backgroundColor: \"white\",\n              }}\n            ></canvas>\n          </div>\n        </div>\n        <div className=\"row justify-content-center pb-5\">\n          <div className=\"col-6 col-md-4 col-lg-3\">\n            <div className=\"row\">\n              <div className=\"col text-right\">\n                <h4 className=\"font-weight-bold\">FFNN:</h4>\n              </div>\n              <div className=\"col text-left\">\n                <h4 className=\"font-weight-bold\">{this.state.ffnnPred}</h4>\n              </div>\n            </div>\n            {ffnnProbs}\n          </div>\n          <div className=\"col-6 col-md-4 col-lg-3\">\n            <div className=\"row font-weight-bold\">\n              <div className=\"col text-right\">\n                <h4 className=\"font-weight-bold\">CNN:</h4>\n              </div>\n              <div className=\"col text-left\">\n                <h4 className=\"font-weight-bold\">{this.state.cnnPred}</h4>\n              </div>\n            </div>\n            {cnnProbs}\n          </div>\n        </div>\n        <GithubCorner\n          href=\"https://github.com/ryantran2165/digit-recognizer\"\n          bannerColor=\"#222\"\n          octoColor=\"#7fffd4\"\n          target=\"_blank\"\n        />\n      </div>\n    );\n  }\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.0/8 are considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl, {\n    headers: { 'Service-Worker': 'script' }\n  })\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport App from \"./App\";\nimport * as serviceWorker from \"./serviceWorker\";\nimport \"bootstrap/dist/css/bootstrap.css\";\nimport \"./index.scss\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}