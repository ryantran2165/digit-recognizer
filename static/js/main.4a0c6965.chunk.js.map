{"version":3,"sources":["components/button.js","components/canvas.js","logic/mnist.js","logic/matrix.js","logic/ffnn/ffnn-helpers.js","logic/utils.js","logic/ffnn/ffnn.js","logic/cnn/conv.js","logic/cnn/maxpool.js","logic/cnn/softmax.js","logic/cnn/cnn.js","App.js","serviceWorker.js","index.js"],"names":["Button","value","onClick","className","type","e","target","blur","Canvas","findxy","res","isTouch","currX","touches","clientX","canvas","getBoundingClientRect","left","currY","clientY","top","ctx","beginPath","lineWidth","arc","LINE_WIDTH","Math","PI","stroke","closePath","fill","paths","push","paintFlag","prevX","prevY","currPath","length","draw","x1","y1","x2","y2","strokeStyle","lineCap","lineJoin","moveTo","lineTo","erase","clearRect","width","height","ctx28","canvas28","imageDataToGrayscale","imgData","grayscaleImg","y","x","offset","data","getBoundingRect","img","threshold","rows","columns","minX","minY","maxX","maxY","centerImage","meanX","meanY","sumPixels","pixel","transX","round","transY","predict","getImageData","boundingRect","trans","canvasCopy","document","createElement","copyCtx","getContext","brW","brH","scaling","translate","scale","p","i","nnInput","Array","mean","v","h","block","newVal","putImageData","this","getElementById","addEventListener","body","preventDefault","passive","id","toString","style","border","borderRadius","backgroundColor","Component","loadMNIST","Matrix","cols","matrix","j","map","console","log","arr","_","func","random","u","sqrt","cos","table","w","region","r","c","max","Number","NEGATIVE_INFINITY","maxR","maxC","matrix1","matrix2","sum","k","ReLUActivation","z","z_i","SoftmaxActivation","exp","softmax","fn","mul","a_i","EPSILON","BinaryCrossEntropyLoss","a","yIsOne","transpose","yIsZero","y_i","outputActivationFunction","sub","div","derivative","shuffle","randomIndex","floor","temp","FFNN","sizes","ffnn","hiddenActivationFunction","lossFunction","numLayers","size","biases","bias","weights","weight","hasOwnProperty","trainMean","trainSTD","b","randomizeNormal","input","output","add","toArray","trainDatas","epochs","miniBatchSize","learningRate","regularization","testDatas","trainDataSize","miniBatches","miniBatch","updateMiniBatch","accuracy","JSON","stringify","biasesGradient","createEmptyGradient","weightsGradient","trainData","targetOutput","gradientDelta","backprop","biasesGradientDelta","weightsGradientDelta","learningRateWithAvg","zs","activations","forward","outputError","hiddenError","nextWeightsTranspose","hiddenActivationFunctionDerivative","gradient","targetMatrix","gradientMatrix","count","testData","outputArr","targetOutputArr","indexOf","datas","cost","vectorFromArray","squaredWeights","weightOrBias","epsilon","gradApprox","original","outputPlus","lossPlus","outputMinus","lossMinus","gradApproxVal","paramSum","paramApproxSum","errorSum","gradientVal","valDatas","miniBatchOptions","learningRateOptions","regularizationOptions","bestMiniBatch","bestLearningRate","bestRegularization","bestAccuracy","bestNetwork","curMiniBatch","curLearningRate","curRegularization","curNetwork","stochasticGradientDescent","valAccuracy","generalizationAccuracy","Conv","numFilters","filterSize","conv","filters","filter","image","f","getRegion","lastInput","outputs","iterateRegions","dLdOut","dLdFilters","dLdFilter","MaxPool","poolSize","pool","s","newH","newW","channel","dLdInputs","dLdInput","Softmax","inputLen","nodes","lastInputShape","flattened","flattenedCol","lastZ","correctI","zExp","zExpCorrect","S","dOutdZ","dZdW","dZdInputs","dLdZ","dLdW","dLdB","channels","index","dLdInputsReshaped","dLdInputChannel","CNN","cnn","out","epoch","loss","numCorrect","label","labelNum","l","acc","test","outMax","numTests","App","props","handlePredict","undefined","inputArr","canvasRef","current","ffnnInput","cnnInput","matrixFromArray","ffnnOutputArr","ffnnPred","cnnOutputArr","cnnPred","setState","handleClear","state","ffnnModel","cnnModel","React","createRef","showSamples","samples","sampleImages","mnist","testImages","testLabels","from","createImageData","mnistSamples","images","labels","isFFNN","targetInt","targetArr","std","ffnnTrainDatas","col","key","row","ffnnProbs","prob","toFixed","cnnProbs","ref","href","bannerColor","octoColor","Boolean","window","location","hostname","match","ReactDOM","render","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"u+85BA0BeA,EAvBA,SAAC,GAAwB,IAAtBC,EAAqB,EAArBA,MAAOC,EAAc,EAAdA,QAOvB,OACE,4BACEC,UAAU,yBACVC,KAAK,SACLF,QAVkB,SAACG,GAErBA,EAAEC,OAAOC,OACTL,MASGD,IC8XQO,E,4MAjSbC,OAAS,SAACC,EAAKL,EAAGM,GA+BhB,GA9BY,SAARD,IAEF,EAAKE,OACFD,EAAUN,EAAEQ,QAAQ,GAAGC,QAAUT,EAAES,SACpC,EAAKC,OAAOC,wBAAwBC,KACtC,EAAKC,OACFP,EAAUN,EAAEQ,QAAQ,GAAGM,QAAUd,EAAEc,SACpC,EAAKJ,OAAOC,wBAAwBI,IAGtC,EAAKC,IAAIC,YACT,EAAKD,IAAIE,UAAY,EACrB,EAAKF,IAAIG,IAAI,EAAKZ,MAAO,EAAKM,MAAOO,GAAgB,EAAG,EAAIC,KAAKC,IACjE,EAAKN,IAAIO,SACT,EAAKP,IAAIQ,YACT,EAAKR,IAAIS,OAGT,EAAKC,MAAMC,KAAK,CAAC,CAAC,EAAKpB,OAAQ,CAAC,EAAKM,SAGrC,EAAKe,WAAY,GAIP,OAARvB,GAAwB,QAARA,IAClB,EAAKuB,WAAY,GAIP,SAARvB,GAAkB,EAAKuB,UAAW,CAEpC,EAAKC,MAAQ,EAAKtB,MAClB,EAAKuB,MAAQ,EAAKjB,MAGlB,EAAKN,OACFD,EAAUN,EAAEQ,QAAQ,GAAGC,QAAUT,EAAES,SACpC,EAAKC,OAAOC,wBAAwBC,KACtC,EAAKC,OACFP,EAAUN,EAAEQ,QAAQ,GAAGM,QAAUd,EAAEc,SACpC,EAAKJ,OAAOC,wBAAwBI,IAGtC,IAAMgB,EAAW,EAAKL,MAAM,EAAKA,MAAMM,OAAS,GAChDD,EAAS,GAAGJ,KAAK,EAAKpB,OACtBwB,EAAS,GAAGJ,KAAK,EAAKd,OACtB,EAAKa,MAAM,EAAKA,MAAMM,OAAS,GAAKD,EAGpC,EAAKE,KACH,EAAKjB,IA3JM,GA6JX,EAAKa,MACL,EAAKC,MACL,EAAKvB,MACL,EAAKM,S,EAMXoB,KAAO,SAACjB,EAAKE,EAAWgB,EAAIC,EAAIC,EAAIC,GAClCrB,EAAIC,YACJD,EAAIsB,YAvKM,QAwKVtB,EAAIE,UAAYA,EAChBF,EAAIuB,QAAU,QACdvB,EAAIwB,SAAW,QACfxB,EAAIyB,OAAOP,EAAIC,GACfnB,EAAI0B,OAAON,EAAIC,GACfrB,EAAIO,SACJP,EAAIQ,a,EAINmB,MAAQ,WACN,EAAK3B,IAAI4B,UAAU,EAAG,EAAG,EAAKlC,OAAOmC,MAAO,EAAKnC,OAAOoC,QACxD,EAAKpB,MAAQ,GAEb,EAAKqB,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,S,EAGhEG,qBAAuB,SAACC,GAItB,IAFA,IAAMC,EAAe,GAEZC,EAAI,EAAGA,EAAIF,EAAQJ,OAAQM,IAAK,CAEvCD,EAAaC,GAAK,GAElB,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAQL,MAAOQ,IAAK,CAEtC,IAAMC,EAAa,EAAJF,EAAQF,EAAQL,MAAQ,EAAIQ,EAM7B,IAHAH,EAAQK,KAAKD,EAAS,KAIlCJ,EAAQK,KAAKD,GAAU,KAIzBH,EAAaC,GAAGC,GAAKH,EAAQK,KAAKD,GAAU,KAKhD,OAAOH,G,EAGTK,gBAAkB,SAACC,EAAKC,GAQtB,IAPA,IAAMC,EAAOF,EAAIzB,OACX4B,EAAUH,EAAI,GAAGzB,OACnB6B,EAAOD,EACPE,EAAOH,EACPI,GAAQ,EACRC,GAAQ,EAEHZ,EAAI,EAAGA,EAAIO,EAAMP,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIO,EAASP,IAEvBI,EAAIL,GAAGC,GAAKK,IACVG,EAAOR,IAAGQ,EAAOR,GACjBU,EAAOV,IAAGU,EAAOV,GACjBS,EAAOV,IAAGU,EAAOV,GACjBY,EAAOZ,IAAGY,EAAOZ,IAK3B,MAAO,CAAEU,KAAMA,EAAMD,KAAMA,EAAMG,KAAMA,EAAMD,KAAMA,I,EAGrDE,YAAc,SAACR,GAQb,IAPA,IAAME,EAAOF,EAAIzB,OACX4B,EAAUH,EAAI,GAAGzB,OACnBkC,EAAQ,EACRC,EAAQ,EACRC,EAAY,EAGPhB,EAAI,EAAGA,EAAIO,EAAMP,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIO,EAASP,IAAK,CAChC,IAAIgB,EAAQ,EAAIZ,EAAIL,GAAGC,GACvBa,GAASb,EAAIgB,EACbF,GAASf,EAAIiB,EACbD,GAAaC,EASjB,OANAH,GAASE,EACTD,GAASC,EAKF,CAAEE,OAHAjD,KAAKkD,MAAMX,EAAU,EAAIM,GAGbM,OAFZnD,KAAKkD,MAAMZ,EAAO,EAAIQ,K,EAKjCM,QAAU,WAER,IAAIvB,EAAU,EAAKlC,IAAI0D,aAAa,EAAG,EA7Q7B,IACC,KA6QPvB,EAAe,EAAKF,qBAAqBC,GAGvCyB,EAAe,EAAKnB,gBAAgBL,EA9QnB,KAgRjByB,EAAQ,EAAKX,YAAYd,GAGzB0B,EAAaC,SAASC,cAAc,UAC1CF,EAAWhC,MAAQK,EAAQL,MAC3BgC,EAAW/B,OAASI,EAAQJ,OAC5B,IAAMkC,EAAUH,EAAWI,WAAW,MAGhCC,EAAMP,EAAaZ,KAAOY,EAAad,KAAO,EAC9CsB,EAAMR,EAAaX,KAAOW,EAAab,KAAO,EAC9CsB,EA5RS,KA4ReF,EAAMC,EAAMD,EAAMC,GAGhDH,EAAQK,UAAU,EAAK3E,OAAOmC,MAAQ,EAAG,EAAKnC,OAAOoC,OAAS,GAC9DkC,EAAQM,MAAMF,EAASA,GACvBJ,EAAQK,WAAW,EAAK3E,OAAOmC,MAAQ,GAAI,EAAKnC,OAAOoC,OAAS,GAGhEkC,EAAQK,UAAUT,EAAMN,OAAQM,EAAMJ,QAIpC,IAAK,IAAIe,EAAI,EAAGA,EAAI,EAAK7D,MAAMM,OAAQuD,IACrC,IAAK,IAAIC,EAAI,EAAGA,EAAI,EAAK9D,MAAM6D,GAAG,GAAGvD,OAAS,EAAGwD,IAAK,CACpD,IAAMtD,EAAK,EAAKR,MAAM6D,GAAG,GAAGC,GACtBrD,EAAK,EAAKT,MAAM6D,GAAG,GAAGC,GACtBpD,EAAK,EAAKV,MAAM6D,GAAG,GAAGC,EAAI,GAC1BnD,EAAK,EAAKX,MAAM6D,GAAG,GAAGC,EAAI,GAChC,EAAKvD,KAAK+C,EA5SD,GA4SuBI,EAASlD,EAAIC,EAAIC,EAAIC,GAQ3Da,EAAU8B,EAAQN,aAAa,EAAG,EAxTxB,IACC,KAwTXvB,EAAe,EAAKF,qBAAqBC,GAMzC,IAHA,IAAMuC,EAAU,IAAIC,MAAM,KAGjBtC,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAE3B,IADA,IAAIsC,EAAO,EACFC,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IACtBF,GAAQxC,EAAiB,GAAJC,EAASwC,GAAO,GAAJvC,EAASwC,GAK9CJ,EAAY,GAAJrC,EAASC,GAAK,EAAIsC,EAAO,IAMrC,EAAK5C,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,QAE9D,IAAK,IAAIM,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMyC,EAAQ,EAAK/C,MAAM2B,aAAarB,EAAGD,EAAG,EAAG,GACzC2C,EAAS,IAAMN,EAAY,GAAJrC,EAASC,GAEtCyC,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAK,IAEhB,EAAKR,MAAMiD,aAAaF,EAAOzC,EAAGD,GA8BtC,OAAOqC,G,kEA9WY,IAAD,OAClBQ,KAAKvF,OAASoE,SAASoB,eAAe,eACtCD,KAAKjF,IAAMiF,KAAKvF,OAAOuE,WAAW,MAClCgB,KAAKjD,SAAW8B,SAASoB,eAAe,YACxCD,KAAKlD,MAAQkD,KAAKjD,SAASiC,WAAW,MAGtCgB,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAEFiG,KAAKvF,OAAOyF,iBACV,WACA,SAACnG,GACC,EAAKI,OAAO,KAAMJ,GAAG,MAEvB,GAEFiG,KAAKvF,OAAOyF,iBACV,YACA,SAACnG,GACC,EAAKI,OAAO,MAAOJ,GAAG,MAExB,GAEFiG,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAIFiG,KAAKvF,OAAOyF,iBACV,cACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAEFiG,KAAKvF,OAAOyF,iBACV,YACA,SAACnG,GACC,EAAKI,OAAO,KAAMJ,GAAG,MAEvB,GAEFiG,KAAKvF,OAAOyF,iBACV,aACA,SAACnG,GACC,EAAKI,OAAO,OAAQJ,GAAG,MAEzB,GAIF8E,SAASsB,KAAKD,iBACZ,cACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAEbxB,SAASsB,KAAKD,iBACZ,YACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAEbxB,SAASsB,KAAKD,iBACZ,aACA,SAACnG,GACKA,EAAEC,SAAW,EAAKS,QACpBV,EAAEqG,mBAGN,CAAEC,SAAS,IAGbL,KAAKpE,MAAQ,EACboE,KAAK1F,MAAQ,EACb0F,KAAKnE,MAAQ,EACbmE,KAAKpF,MAAQ,EACboF,KAAKvE,MAAQ,GACbuE,KAAKrE,WAAY,I,+BAqRjB,OACE,4BACE2E,GAAG,cACH1D,MAhYM,KAgYO2D,WACb1D,OAhYO,KAgYQ0D,WACfC,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,e,GA3XNC,a,uCCgENC,I,wBCiPAC,E,WAtTb,WAAYpD,EAAMqD,EAAMC,GACtB,GAD+B,oBAC3BA,EAAQ,CAEVhB,KAAKtC,KAAOsD,EAAOtD,KACnBsC,KAAKe,KAAOC,EAAOD,KACnBf,KAAK1C,KAAO,GACZ,IAAK,IAAIiC,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAAK,CAClCS,KAAK1C,KAAK5B,KAAK,IACf,IAAK,IAAIuF,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BjB,KAAK1C,KAAKiC,GAAG7D,KAAKsF,EAAO1D,KAAKiC,GAAG0B,UAIrCjB,KAAKtC,KAAOA,EACZsC,KAAKe,KAAOA,EACZf,KAAK1C,KAAOmC,MAAM/B,GACflC,OACA0F,KAAI,kBAAMzB,MAAMsB,GAAMvF,KAAK,M,gDAS9BwF,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDI,QAAQC,IAAI,sCAGPpB,KAAKkB,KAAI,SAAC9D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAE3CjB,KAAKkB,KAAI,SAAC9D,GAAD,OAAOA,EAAI4D,O,0BAwBzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDI,QAAQC,IAAI,2CAIPpB,KAAKkB,KAAI,SAAC9D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAKkB,KAAI,SAAC9D,GAAD,OAAOA,EAAI4D,O,0BAwBzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDI,QAAQC,IAAI,2CAIPpB,KAAKkB,KAAI,SAAC9D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAKkB,KAAI,SAAC9D,GAAD,OAAOA,EAAI4D,O,0BA8BzBA,GACF,OAAIA,aAAkBF,EAChBd,KAAKtC,OAASsD,EAAOtD,MAAQsC,KAAKe,OAASC,EAAOD,UACpDI,QAAQC,IAAI,2CAIPpB,KAAKkB,KAAI,SAAC9D,EAAGmC,EAAG0B,GAAP,OAAa7D,EAAI4D,EAAO1D,KAAKiC,GAAG0B,MAG3CjB,KAAKkB,KAAI,SAAC9D,GAAD,OAAOA,EAAI4D,O,gCAwD3B,IADA,IAAMK,EAAM,GACH9B,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAC7B,IAAK,IAAI0B,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BI,EAAI3F,KAAKsE,KAAK1C,KAAKiC,GAAG0B,IAG1B,OAAOI,I,6BAOD,IAAD,OACL,OAAO,IAAIP,EAAOd,KAAKtC,KAAMsC,KAAKe,MAAMG,KAAI,SAACI,EAAG/B,EAAG0B,GAAP,OAAa,EAAK3D,KAAKiC,GAAG0B,Q,0BAQpEM,GACF,IAAK,IAAIhC,EAAI,EAAGA,EAAIS,KAAKtC,KAAM6B,IAC7B,IAAK,IAAI0B,EAAI,EAAGA,EAAIjB,KAAKe,KAAME,IAC7BjB,KAAK1C,KAAKiC,GAAG0B,GAAKM,EAAKvB,KAAK1C,KAAKiC,GAAG0B,GAAI1B,EAAG0B,GAG/C,OAAOjB,O,kCAoBP,OAAOA,KAAKkB,KAAI,kBAAsB,EAAhB9F,KAAKoG,SAAe,O,wCAQ1C,OAAOxB,KAAKkB,KAAI,WAGd,IAFA,IAAIO,EAAI,EACJ9B,EAAI,EACK,IAAN8B,GAASA,EAAIrG,KAAKoG,SACzB,KAAa,IAAN7B,GAASA,EAAIvE,KAAKoG,SACzB,OAAOpG,KAAKsG,MAAM,EAAMtG,KAAKgG,IAAIK,IAAMrG,KAAKuG,IAAI,EAAMvG,KAAKC,GAAKsE,Q,8BAUlE,OADAwB,QAAQS,MAAM5B,KAAK1C,MACZ0C,O,gCAWC5C,EAAGD,EAAG0E,EAAGjC,GAEjB,IADA,IAAMkC,EAAS,IAAIhB,EAAOlB,EAAGiC,GACpBE,EAAI,EAAGA,EAAInC,EAAGmC,IACrB,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAGG,IACrBF,EAAOxE,KAAKyE,GAAGC,GAAKhC,KAAK1C,KAAKH,EAAI4E,GAAG3E,EAAI4E,GAG7C,OAAOF,I,4BAWP,IAHA,IAAIG,EAAMC,OAAOC,kBACbC,GAAQ,EACRC,GAAQ,EACHN,EAAI,EAAGA,EAAI/B,KAAKtC,KAAMqE,IAC7B,IAAK,IAAIC,EAAI,EAAGA,EAAIhC,KAAKe,KAAMiB,IACzBhC,KAAK1C,KAAKyE,GAAGC,GAAKC,IACpBA,EAAMjC,KAAK1C,KAAKyE,GAAGC,GACnBI,EAAOL,EACPM,EAAOL,GAIb,MAAO,CAACC,EAAKG,EAAMC,M,2BAvQVC,EAASC,GAClB,GAAID,EAAQ5E,OAAS6E,EAAQ7E,MAAQ4E,EAAQvB,OAASwB,EAAQxB,KAI9D,OAAO,IAAID,EAAOwB,EAAQ5E,KAAM4E,EAAQvB,MAAMG,KAC5C,SAACI,EAAG/B,EAAG0B,GAAP,OAAaqB,EAAQhF,KAAKiC,GAAG0B,GAAKsB,EAAQjF,KAAKiC,GAAG0B,MAJlDE,QAAQC,IAAI,wC,0BAgCLkB,EAASC,GAClB,GAAID,EAAQ5E,OAAS6E,EAAQ7E,MAAQ4E,EAAQvB,OAASwB,EAAQxB,KAI9D,OAAO,IAAID,EAAOwB,EAAQ5E,KAAM4E,EAAQvB,MAAMG,KAC5C,SAACI,EAAG/B,EAAG0B,GAAP,OAAaqB,EAAQhF,KAAKiC,GAAG0B,GAAKsB,EAAQjF,KAAKiC,GAAG0B,MAJlDE,QAAQC,IAAI,6C,0BAgCLkB,EAASC,GAClB,GAAID,EAAQvB,OAASwB,EAAQ7E,KAM7B,OAAO,IAAIoD,EAAOwB,EAAQ5E,KAAM6E,EAAQxB,MAAMG,KAAI,SAACI,EAAG/B,EAAG0B,GAEvD,IADA,IAAIuB,EAAM,EACDC,EAAI,EAAGA,EAAIH,EAAQvB,KAAM0B,IAChCD,GAAOF,EAAQhF,KAAKiC,GAAGkD,GAAKF,EAAQjF,KAAKmF,GAAGxB,GAE9C,OAAOuB,KAVPrB,QAAQC,IACN,sE,0BAqCKkB,EAASC,GAClB,GAAID,EAAQ5E,OAAS6E,EAAQ7E,MAAQ4E,EAAQvB,OAASwB,EAAQxB,KAI9D,OAAO,IAAID,EAAOwB,EAAQ5E,KAAM4E,EAAQvB,MAAMG,KAC5C,SAACI,EAAG/B,EAAG0B,GAAP,OAAaqB,EAAQhF,KAAKiC,GAAG0B,GAAKsB,EAAQjF,KAAKiC,GAAG0B,MAJlDE,QAAQC,IAAI,6C,gCAaCJ,GACf,OAAO,IAAIF,EAAOE,EAAOD,KAAMC,EAAOtD,MAAMwD,KAC1C,SAACI,EAAG/B,EAAG0B,GAAP,OAAaD,EAAO1D,KAAK2D,GAAG1B,Q,sCAST8B,GACrB,OAAO,IAAIP,EAAOO,EAAItF,OAAQ,GAAGmF,KAAI,SAACI,EAAG/B,GAAJ,OAAU8B,EAAI9B,Q,sCAU9B8B,EAAK3D,EAAMqD,GAChC,OAAO,IAAID,EAAOpD,EAAMqD,GAAMG,KAAI,SAACI,EAAG/B,EAAG0B,GAAP,OAAaI,EAAI9B,EAAIwB,EAAOE,Q,0BA6CrDD,EAAQO,GACjB,OAAO,IAAIT,EAAOE,EAAOtD,KAAMsD,EAAOD,MAAMG,KAAI,SAACI,EAAG/B,EAAG0B,GAAP,OAC9CM,EAAKP,EAAO1D,KAAKiC,GAAG0B,GAAI1B,EAAG0B,U,KCtNpByB,EAAb,gGAMYC,GACR,OAAO7B,EAAOI,IAAIyB,GAAG,SAACC,GAAD,OAASxH,KAAK6G,IAAI,EAAGW,QAP9C,iCAeoBD,GAChB,OAAO7B,EAAOI,IAAIyB,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,SAhBjD,KA8CaC,EAAb,gGAMYF,GAER,IADA,IAAIH,EAAM,EACDT,EAAI,EAAGA,EAAIY,EAAEjF,KAAMqE,IAC1BS,GAAOpH,KAAK0H,IAAIH,EAAErF,KAAKyE,GAAG,IAE5B,OAAOjB,EAAOI,IAAIyB,GAAG,SAACC,GAAD,OAASxH,KAAK0H,IAAIF,GAAOJ,OAXlD,iCAmBoBG,GAChB,IAAMI,EAAUF,EAAkBG,GAAGL,GACrC,OAAOI,EAAQE,IAAInC,EAAOI,IAAI6B,GAAS,SAACG,GAAD,OAAS,EAAIA,UArBxD,KA4DMC,EAAO,SAAG,IAAO,KAKVC,EAAb,gGAOYC,EAAGlG,GACX,IAAMmG,EAASxC,EAAOmC,IACpBnC,EAAOyC,UAAUpG,GACjB2D,EAAOI,IAAImC,GAAG,SAACH,GAEb,OAAO9H,KAAKgG,IAAI8B,EAAMC,OAGpBK,EAAU1C,EAAOmC,IACrBnC,EAAOyC,UAAUzC,EAAOI,IAAI/D,GAAG,SAACsG,GAAD,OAAS,EAAIA,MAC5C3C,EAAOI,IAAImC,GAAG,SAACH,GAEb,OAAO9H,KAAKgG,IAAI,EAAI8B,EAAMC,OAG9B,QAASG,EAAOhG,KAAK,GAAG,GAAKkG,EAAQlG,KAAK,GAAG,MAtBjD,kCAiCqBqF,EAAGU,EAAGlG,EAAGuG,GAO1B,OAN2B5C,EAAO6C,IAAIN,EAAGlG,GAAGyG,IAC1C9C,EAAOI,IAAImC,GAAG,SAACH,GAEb,OAAOA,GAAO,EAAIA,GAAOC,MAGHF,IAAIS,EAAyBG,WAAWlB,QAxCtE,KCvIO,SAASmB,EAAQzC,GACtB,IAAK,IAAI9B,EAAI8B,EAAItF,OAAS,EAAGwD,EAAI,EAAGA,IAAK,CACvC,IAAMwE,EAAc3I,KAAK4I,MAAM5I,KAAKoG,UAAYjC,EAAI,IAC9C0E,EAAO5C,EAAI9B,GACjB8B,EAAI9B,GAAK8B,EAAI0C,GACb1C,EAAI0C,GAAeE,EAErB,OAAO5C,ECAT,IA2kBe6C,E,WAhkBb,WAAYC,EAAOC,GAAO,IAAD,OAKvB,GALuB,oBACvBpE,KAAKqE,yBAA2B3B,EAChC1C,KAAK0D,yBAA2Bb,EAChC7C,KAAKsE,aAAelB,EAEhBgB,EAAM,CAERpE,KAAKuE,UAAYH,EAAKD,MAAMpI,OAC5BiE,KAAKmE,MAAQ,GAHL,oBAISC,EAAKD,OAJd,IAIR,2BAA6B,CAAC,IAArBK,EAAoB,QAC3BxE,KAAKmE,MAAMzI,KAAK8I,IALV,8BASRxE,KAAKyE,OAAS,GATN,oBAUSL,EAAKK,QAVd,IAUR,2BAA8B,CAAC,IAAtBC,EAAqB,QAC5B1E,KAAKyE,OAAO/I,KAAK,IAAIoF,EAAO,KAAM,KAAM4D,KAXlC,8BAeR1E,KAAK2E,QAAU,GAfP,oBAgBWP,EAAKO,SAhBhB,IAgBR,2BAAiC,CAAC,IAAzBC,EAAwB,QAC/B5E,KAAK2E,QAAQjJ,KAAK,IAAIoF,EAAO,KAAM,KAAM8D,KAjBnC,8BAqBJR,EAAKS,eAAe,eACtB7E,KAAK8E,UAAY,IAAIhE,EAAO,KAAM,KAAMsD,EAAKU,WAC7C9E,KAAK+E,SAAW,IAAIjE,EAAO,KAAM,KAAMsD,EAAKW,eAEzC,CACL/E,KAAKuE,UAAYJ,EAAMpI,OACvBiE,KAAKmE,MAAQA,EAGbnE,KAAKyE,OAAS,GACd,IAAK,IAAIlF,EAAI,EAAGA,EAAI4E,EAAMpI,OAAQwD,IAAK,CACrC,IAAMmF,EAAO,IAAI5D,EAAOqD,EAAM5E,GAAI,GAE9BS,KAAKqE,2BAA6B3B,EAEpCgC,EAAKxD,KAAI,SAAC8D,GAAD,OAAO,KAEhBN,EAAKO,kBAGPjF,KAAKyE,OAAO/I,KAAKgJ,GAInB1E,KAAK2E,QAAU,GACf,IArBK,eAqBIpF,GACP,IAAMqF,EAAS,IAAI9D,EAAOqD,EAAM5E,GAAI4E,EAAM5E,EAAI,IAG9CqF,EAAOK,kBACH,EAAKZ,2BAA6B3B,GACpCkC,EAAO1D,KAAI,SAACW,GAAD,OAAOA,EAAIzG,KAAKsG,KAAK,EAAIyC,EAAM5E,EAAI,OAGhD,EAAKoF,QAAQjJ,KAAKkJ,IATXrF,EAAI,EAAGA,EAAI4E,EAAMpI,OAAQwD,IAAM,EAA/BA,I,oDAmBL2F,GAGN,IAFA,IAAIC,EAASD,EAEJ3F,EAAI,EAAGA,EAAIS,KAAKuE,UAAY,EAAGhF,IAAK,CAC3C,IAAMmF,EAAO1E,KAAKyE,OAAOlF,GACnBqF,EAAS5E,KAAK2E,QAAQpF,GAGtBoD,EAAI7B,EAAOmC,IAAI2B,EAAQO,GAC7BxC,EAAEyC,IAAIV,GACNS,EACE5F,IAAMS,KAAKuE,UAAY,EACnBvE,KAAK0D,yBAAyBV,GAAGL,GACjC3C,KAAKqE,yBAAyBrB,GAAGL,GAGzC,OAAOwC,EAAOE,Y,gDAadC,EACAC,EACAC,EACAC,EACAC,GAOA,IALC,IADDC,EACA,uDADY,KAGNC,EAAgBN,EAAWvJ,OAGxBwD,EAAI,EAAGA,EAAIgG,EAAQhG,IAAK,CAE/BuE,EAAQwB,GAIR,IADA,IAAMO,EAAc,GACX5E,EAAI,EAAGA,EAAI2E,EAAe3E,GAAKuE,EAAe,CAKrD,IAHA,IAAMM,EAAY,GAGTrD,EAAIxB,EAAGwB,EAAIxB,EAAIuE,EAAe/C,IACrCqD,EAAUpK,KAAK4J,EAAW7C,IAE5BoD,EAAYnK,KAAKoK,GAInB,IAAK,IAAI7E,EAAI,EAAGA,EAAI4E,EAAY9J,OAAQkF,IAAK,CAC3CjB,KAAK+F,gBACHF,EAAY5E,GACZwE,EACAC,EACAE,GAqBAzE,QAAQC,IACN,wBAA0BH,EAAI,GAAK,IAAM4E,EAAY9J,QAsB3D,GAAkB,OAAd4J,EAAoB,CACtB,IAAMK,EAAWhG,KAAKgG,SAASL,GAC/BxE,QAAQC,IACN,kBACG7B,EAAI,GACL,IACAgG,EACA,KACAS,EACA,IACAL,EAAU5J,OACV,KACC,IAAMiK,EAAYL,EAAU5J,OAC7B,KAKJoF,QAAQC,IAAI6E,KAAKC,UAAUlG,U,sCAYjB8F,EAAWL,EAAcC,EAAgBE,GAEvD,IAFsE,EAEhEO,EAAiBnG,KAAKoG,oBAAoBpG,KAAKyE,QAC/C4B,EAAkBrG,KAAKoG,oBAAoBpG,KAAK2E,SAHgB,cAMhDmB,GANgD,IAMtE,2BA0BE,IA1BgC,IAAzBQ,EAAwB,QACzBpB,EAAQoB,EAAU,GAClBC,EAAeD,EAAU,GACzBE,EAAgBxG,KAAKyG,SAASvB,EAAOqB,GACrCG,EAAsBF,EAAc,GACpCG,EAAuBH,EAAc,GAqBlCjH,EAAI,EAAGA,EAAIS,KAAKuE,UAAY,EAAGhF,IACtC4G,EAAe5G,GAAG6F,IAAIsB,EAAoBnH,IAC1C8G,EAAgB9G,GAAG6F,IAAIuB,EAAqBpH,IAlCsB,8BAuCtE,IAAK,IAAIA,EAAI,EAAGA,EAAIS,KAAKuE,UAAY,EAAGhF,IAAK,CAC3C,IAAMqH,EAAsBnB,EAAeK,EAAU/J,OAGrDiE,KAAKyE,OAAOlF,GAAGoE,IAAIwC,EAAe5G,GAAG0D,IAAI2D,IAGzC5G,KAAK2E,QAAQpF,GAAG0D,IAAI,EAAIwC,GAAgBC,EAAiBE,IAGzD5F,KAAK2E,QAAQpF,GAAGoE,IAAI0C,EAAgB9G,GAAG0D,IAAI2D,O,+BAUtC1B,EAAOqB,GACd,IAAMJ,EAAiBnG,KAAKoG,oBAAoBpG,KAAKyE,QAC/C4B,EAAkBrG,KAAKoG,oBAAoBpG,KAAK2E,SAGhDkC,EAAK,GACLC,EAAc,CAAC5B,GACrBlF,KAAK+G,QAAQF,EAAIC,GAGjB,IAAME,EAAchH,KAAKsE,aAAa0C,YACpCH,EAAGA,EAAG9K,OAAS,GACf+K,EAAYA,EAAY/K,OAAS,GACjCwK,EACAvG,KAAK0D,0BAIPyC,EAAeA,EAAepK,OAAS,GAAKiL,EAG5CX,EAAgBA,EAAgBtK,OAAS,GAAK+E,EAAOmC,IACnD+D,EACAlG,EAAOyC,UAAUuD,EAAYA,EAAY/K,OAAS,KAKpD,IADA,IAAIkL,EAAcD,EACTzH,EAAI,EAAGA,EAAIS,KAAKuE,UAAWhF,IAAK,CAEvC,IAAM2H,EAAuBpG,EAAOyC,UAClCvD,KAAK2E,QAAQ3E,KAAK2E,QAAQ5I,OAASwD,EAAI,IAEnC4H,EAAqCnH,KAAKqE,yBAAyBR,WACvEgD,EAAGA,EAAG9K,OAASwD,IAEjB0H,EAAcnG,EAAOmC,IAAIiE,EAAsBD,GAAahE,IAC1DkE,GAIFhB,EAAeA,EAAepK,OAASwD,GAAK0H,EAG5CZ,EAAgBA,EAAgBtK,OAASwD,GAAKuB,EAAOmC,IACnDgE,EACAnG,EAAOyC,UAAUuD,EAAYA,EAAY/K,OAASwD,EAAI,KAI1D,MAAO,CAAC4G,EAAgBE,K,8BAQlBQ,EAAIC,GACV,IAAK,IAAIvH,EAAI,EAAGA,EAAIS,KAAKuE,UAAY,EAAGhF,IAAK,CAC3C,IAAMmF,EAAO1E,KAAKyE,OAAOlF,GACnBqF,EAAS5E,KAAK2E,QAAQpF,GAGtBoD,EAAI7B,EAAOmC,IAAI2B,EAAQkC,EAAYvH,IACzCoD,EAAEyC,IAAIV,GACNmC,EAAGnL,KAAKiH,GAER,IAAMU,EACJ9D,IAAMS,KAAKuE,UAAY,EACnBvE,KAAK0D,yBAAyBV,GAAGL,GACjC3C,KAAKqE,yBAAyBrB,GAAGL,GACvCmE,EAAYpL,KAAK2H,M,0CASDhC,GAClB,IADuB,EACjB+F,EAAW,GADM,cAEE/F,GAFF,IAEvB,2BAA8B,CAAC,IAAtBgG,EAAqB,QACtBC,EAAiB,IAAIxG,EAAOuG,EAAa3J,KAAM2J,EAAatG,MAClEqG,EAAS1L,KAAK4L,IAJO,8BAMvB,OAAOF,I,+BAQAzB,GACP,IADkB,EACd4B,EAAQ,EADM,cAGG5B,GAHH,IAGlB,2BAAgC,CAAC,IAAxB6B,EAAuB,QACxBtC,EAAQsC,EAAS,GACjBC,EAAYzH,KAAKxB,QAAQ0G,GACzBwC,EAAkBF,EAAS,GAAGnC,UACdoC,EAAUE,QAAQvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQqM,OACxBC,EAAgBC,QAC1CvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQsM,MAKZH,KAdc,8BAkBlB,OAAOA,I,gCASCK,EAAOlC,GACf,IAD+B,EAC3BmC,EAAO,EACPN,EAAQ,EAFmB,cAKdK,GALc,IAK/B,2BAAwB,CAAC,IAAhBtK,EAAe,QAChB4H,EAAQ5H,EAAK,GACbiJ,EAAejJ,EAAK,GAEpBmK,EAAYzH,KAAKxB,QAAQ0G,GACzBwC,EAAkBnB,EAAalB,UACfoC,EAAUE,QAAQvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQqM,OACxBC,EAAgBC,QAC1CvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQsM,MAKZH,IAIFM,GACE7H,KAAKsE,aAAatB,GAAGlC,EAAOgH,gBAAgBL,GAAYlB,GACxDqB,EAAM7L,OAGR,IAtBsB,EAsBlBgM,EAAiB,EAtBC,cAuBH/H,KAAK2E,SAvBF,IAuBtB,2BACE,IADgC,IAAzBC,EAAwB,QACtB7C,EAAI,EAAGA,EAAI6C,EAAOlH,KAAMqE,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI4C,EAAO7D,KAAMiB,IAC/B+F,GAAc,SAAInD,EAAOtH,KAAKyE,GAAGC,GAAM,GA1BvB,8BA8BtB6F,GAAenC,EAAiBkC,EAAM7L,OAA9B,GAAwCgM,GAnCnB,8BAsC/B,MAAO,CAACF,EAAMN,K,oCAWFH,EAAUY,EAAc9C,EAAOqB,GAK3C,IAJA,IAAMmB,EAAkBnB,EAAalB,UAC/B4C,EAAO,SAAG,IAAO,GACjBC,EAAalI,KAAKoG,oBAAoBgB,GAEnC7H,EAAI,EAAGA,EAAI2I,EAAWnM,OAAQwD,IACrC,IAAK,IAAIwC,EAAI,EAAGA,EAAImG,EAAW3I,GAAG7B,KAAMqE,IACtC,IAAK,IAAIC,EAAI,EAAGA,EAAIkG,EAAW3I,GAAGwB,KAAMiB,IAAK,CAE3C,IAAMmG,EAAWH,EAAazI,GAAGjC,KAAKyE,GAAGC,GAGzCgG,EAAazI,GAAGjC,KAAKyE,GAAGC,GAAKmG,EAAWF,EAGxC,IAFA,IAAMG,EAAapI,KAAKxB,QAAQ0G,GAC5BmD,EAAW,EACNpH,EAAI,EAAGA,EAAImH,EAAWrM,OAAQkF,IACrCoH,GAAY,YAAOX,EAAgBzG,GAAKmH,EAAWnH,GAAO,GAI5D+G,EAAazI,GAAGjC,KAAKyE,GAAGC,GAAKmG,EAAWF,EAGxC,IAFA,IAAMK,EAActI,KAAKxB,QAAQ0G,GAC7BqD,EAAY,EACPtH,EAAI,EAAGA,EAAIqH,EAAYvM,OAAQkF,IACtCsH,GAAa,YAAOb,EAAgBzG,GAAKqH,EAAYrH,GAAO,GAI9D,IAAMuH,GAAiBH,EAAWE,IAAc,EAAIN,GACpDC,EAAW3I,GAAGjC,KAAKyE,GAAGC,GAAKwG,EAG3BR,EAAazI,GAAGjC,KAAKyE,GAAGC,GAAKmG,EAUnC,IALA,IAAIM,EAAW,EACXC,EAAiB,EACjBC,EAAW,EAGNpJ,EAAI,EAAGA,EAAI2I,EAAWnM,OAAQwD,IACrC,IAAK,IAAIwC,EAAI,EAAGA,EAAImG,EAAW3I,GAAG7B,KAAMqE,IACtC,IAAK,IAAIC,EAAI,EAAGA,EAAIkG,EAAW3I,GAAGwB,KAAMiB,IAAK,CAC3C,IAAM4G,EAAcxB,EAAS7H,GAAGjC,KAAKyE,GAAGC,GAClCwG,EAAgBN,EAAW3I,GAAGjC,KAAKyE,GAAGC,GAE5CyG,GAAQ,SAAIG,EAAe,GAC3BF,GAAc,SAAIF,EAAiB,GACnCG,GAAQ,SAAKH,EAAgBI,EAAgB,GAKnD,OACExN,KAAKsG,KAAKiH,IAAavN,KAAKsG,KAAKgH,GAAkBtN,KAAKsG,KAAK+G,O,4CAUrCnD,EAAYuD,EAAUlD,GAWhD,IAVA,IAAMmD,EAAmB,CAAC,EAAG,GAAI,GAAI,GAAI,KACnCC,EAAsB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACnDC,EAAwB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACvDC,EAAgB,EAChBC,EAAmB,IACnBC,EAAqB,IACrBC,EAAe,EACfC,EAAc,KAGT9J,EAAI,EAAGA,EAAIuJ,EAAiB/M,OAAQwD,IAC3C,IAAK,IAAI0B,EAAI,EAAGA,EAAI8H,EAAoBhN,OAAQkF,IAC9C,IAAK,IAAIwB,EAAI,EAAGA,EAAIuG,EAAsBjN,OAAQ0G,IAAK,CACrD,IAAM6G,EAAeR,EAAiBvJ,GAChCgK,EAAkBR,EAAoB9H,GACtCuI,EAAoBR,EAAsBvG,GAG1CgH,EAAa,IAAIvF,EAAK,CAAC,IAAK,GAAI,KACtCuF,EAAWC,0BACTpE,EACA,EACAgE,EACAC,EACAC,GAIF,IAAMG,EAAcF,EAAWzD,SAAS6C,GAGpCc,EAAcP,IAChBH,EAAgBK,EAChBJ,EAAmBK,EACnBJ,EAAqBK,EACrBJ,EAAeO,EACfN,EAAcI,GAMtBtI,QAAQC,IAAI,yBAA2B6H,GACvC9H,QAAQC,IAAI,uBAAyB8H,GACrC/H,QAAQC,IAAI,wBAA0B+H,GACtChI,QAAQC,IACN,wBACEgI,EACA,IACAP,EAAS9M,OACT,KACC,IAAMqN,EAAgBP,EAAS9M,OAChC,KAIJ,IAAM6N,EAAyBP,EAAYrD,SAASL,GACpDxE,QAAQC,IACN,kBACEwI,EACA,IACAjE,EAAU5J,OACV,KACC,IAAM6N,EAA0BjE,EAAU5J,OAC3C,KAIJoF,QAAQC,IAAI,gBAAiB6E,KAAKC,UAAUmD,Q,YChejCQ,E,WA1Gb,WAAYC,GAA0C,IAA9BC,EAA6B,uDAAhB,EAAGC,EAAa,uDAAN,KAC7C,GADmD,oBACtC,OAATA,EAAe,CACjBhK,KAAK8J,WAAaE,EAAKF,WACvB9J,KAAK+J,WAAaC,EAAKD,WACvB/J,KAAKiK,QAAU,GAHE,oBAKED,EAAKC,SALP,IAKjB,2BAAiC,CAAC,IAAzBC,EAAwB,QAC/BlK,KAAKiK,QAAQvO,KAAK,IAAIoF,EAAO,KAAM,KAAMoJ,KAN1B,mCAQZ,CACLlK,KAAK8J,WAAaA,EAClB9J,KAAK+J,WAAaA,EAClB/J,KAAKiK,QAAU,GAEf,IAAK,IAAI1K,EAAI,EAAGA,EAAIuK,EAAYvK,IAC9BS,KAAKiK,QAAQvO,KACX,IAAIoF,EAAOiJ,EAAYA,GACpB9E,kBACArB,IAFH,SAEOmG,EAAc,M,uEAWbI,G,+EACRvK,EAAIuK,EAAMzM,KACVmE,EAAIsI,EAAMpJ,KACVqJ,EAAIpK,KAAK+J,WAEN5M,EAAI,E,YAAGA,EAAIyC,EAAIwK,EAAI,G,iBACjBhN,EAAI,E,YAAGA,EAAIyE,EAAIuI,EAAI,G,iBAC1B,O,SAAM,CAACD,EAAME,UAAUjN,EAAGD,EAAGiN,EAAGA,GAAIjN,EAAGC,G,OADVA,I,uBADFD,I,8FAYzB+H,GACNlF,KAAKsK,UAAYpF,EAEjB,IAHa,EAGPtF,EAAIsF,EAAMxH,KACVmE,EAAIqD,EAAMnE,KACVqJ,EAAIpK,KAAK+J,WAETQ,EAAU,GAPH,cAUMvK,KAAKiK,SAVX,IAUb,2BAAiC,CAAC,IAAD,EAAxBC,EAAwB,QACzB/E,EAAS,IAAIrE,EAAOlB,EAAIwK,EAAI,EAAGvI,EAAIuI,EAAI,GADd,cAIJpK,KAAKwK,eAAetF,IAJhB,IAI/B,2BAEE,IAFsD,IAAD,yBAA7CpD,EAA6C,KAArC3E,EAAqC,KAAlCC,EAAkC,KAE5C2E,EAAI,EAAGA,EAAIqI,EAAGrI,IACrB,IAAK,IAAIC,EAAI,EAAGA,EAAIoI,EAAGpI,IACrBmD,EAAO7H,KAAKH,GAAGC,IAAM0E,EAAOxE,KAAKyE,GAAGC,GAAKkI,EAAO5M,KAAKyE,GAAGC,GAR/B,8BAa/BuI,EAAQ7O,KAAKyJ,IAvBF,8BA0Bb,OAAOoF,I,+BAQAE,EAAQhF,GAIf,IAHA,IAAMiF,EAAa,GAGVnL,EAAI,EAAGA,EAAIS,KAAKiK,QAAQlO,OAAQwD,IAAK,CAC5C,IAD4C,EACtC2K,EAASlK,KAAKiK,QAAQ1K,GACtBoL,EAAY,IAAI7J,EAAOoJ,EAAOxM,KAAMwM,EAAOnJ,MAFL,cAKjBf,KAAKwK,eAAexK,KAAKsK,YALR,IAK5C,2BAAgE,CAAC,IAAD,yBAAtDxI,EAAsD,KAA9C3E,EAA8C,KAA3CC,EAA2C,KAE9DuN,EAAUvF,IAAItD,EAAOmB,IAAIwH,EAAOlL,GAAGjC,KAAKH,GAAGC,MAPD,8BAS5CsN,EAAWhP,KAAKiP,GAIlB,IAAK,IAAIpL,EAAI,EAAGA,EAAIS,KAAKiK,QAAQlO,OAAQwD,IAAK,CAC5C,IAAM2K,EAASlK,KAAKiK,QAAQ1K,GACtBoL,EAAYD,EAAWnL,GAE7B2K,EAAOvG,IAAIgH,EAAU1H,IAAIwC,S,KCJhBmF,E,WAlGb,aAAwC,IAA5BC,EAA2B,uDAAhB,EAAGC,EAAa,uDAAN,KAAM,oBAEnC9K,KAAK6K,SADM,OAATC,EACcA,EAAKD,SAELA,E,uEASJV,G,mFACRvK,EAAIuK,EAAMzM,KACVmE,EAAIsI,EAAMpJ,KACVgK,EAAI/K,KAAK6K,SAETG,EAAO5P,KAAK4I,MAAMpE,EAAImL,GACtBE,EAAO7P,KAAK4I,MAAMnC,EAAIkJ,GAEnB5N,EAAI,E,YAAGA,EAAI6N,G,iBACT5N,EAAI,E,YAAGA,EAAI6N,G,iBAClB,O,UAAM,CAACd,EAAME,UAAUjN,EAAI2N,EAAG5N,EAAI4N,EAAGA,EAAGA,GAAI5N,EAAGC,G,QADvBA,I,uBADFD,I,8FAYpB+H,GACNlF,KAAKsK,UAAYpF,EAEjB,IAHa,EAGPtF,EAAIsF,EAAM,GAAGxH,KACbmE,EAAIqD,EAAM,GAAGnE,KACbgK,EAAI/K,KAAK6K,SAETG,EAAO5P,KAAK4I,MAAMpE,EAAImL,GACtBE,EAAO7P,KAAK4I,MAAMnC,EAAIkJ,GAEtBR,EAAU,GAVH,cAaOrF,GAbP,IAab,2BAA2B,CAAC,IAAD,EAAlBgG,EAAkB,QACnB/F,EAAS,IAAIrE,EAAOkK,EAAMC,GADP,cAIEjL,KAAKwK,eAAeU,IAJtB,IAIzB,2BAAyD,CAAC,IAAD,yBAA/CpJ,EAA+C,KAAvC3E,EAAuC,KAApCC,EAAoC,OAElC0E,EAAOG,MAF2B,mBAEhDA,EAFgD,eAGvDkD,EAAO7H,KAAKH,GAAGC,GAAK6E,GAPG,8BAUzBsI,EAAQ7O,KAAKyJ,IAvBF,8BA0Bb,OAAOoF,I,+BAQAE,GAIP,IAHA,IAAMU,EAAY,GAGT5L,EAAI,EAAGA,EAAIS,KAAKsK,UAAUvO,OAAQwD,IAAK,CAC9C,IAD8C,EACxC2L,EAAUlL,KAAKsK,UAAU/K,GACzB6L,EAAW,IAAItK,EAAOoK,EAAQxN,KAAMwN,EAAQnK,MAFJ,cAKnBf,KAAKwK,eAAeU,IALD,IAK9C,2BAKE,IALwD,IAAD,yBAA/CpJ,EAA+C,KAAvC3E,EAAuC,KAApCC,EAAoC,OAElC0E,EAAOG,MAF2B,mBAEhDA,EAFgD,KAK9CF,GAL8C,UAK1C,GAAGA,EAAID,EAAOpE,KAAMqE,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAOf,KAAMiB,IAC3BF,EAAOxE,KAAKyE,GAAGC,KAAOC,IACxBmJ,EAAS9N,KAAKH,EAAI6C,KAAK6K,SAAW9I,GAAG3E,EAAI4C,KAAK6K,SAAW7I,GACvDyI,EAAOlL,GAAGjC,KAAKH,GAAGC,IAdkB,8BAoB9C+N,EAAUzP,KAAK0P,GAGjB,OAAOD,M,KCgCIE,E,WA7Hb,WAAYC,EAAUC,GAAwB,IAAjBxI,EAAgB,uDAAN,KAAM,oBAC3B,OAAZA,GACF/C,KAAK2E,QAAU,IAAI7D,EAAO,KAAM,KAAMiC,EAAQ4B,SAC9C3E,KAAKyE,OAAS,IAAI3D,EAAO,KAAM,KAAMiC,EAAQ0B,UAE7CzE,KAAK2E,QAAU,IAAI7D,EAAOwK,EAAUC,GACjCtG,kBACArB,IAAI0H,GACPtL,KAAKyE,OAAS,IAAI3D,EAAO,EAAGyK,I,oDASxBrG,GACNlF,KAAKwL,eAAiB,CAACtG,EAAMnJ,OAAQmJ,EAAM,GAAGxH,KAAMwH,EAAM,GAAGnE,MAG7D,IAJa,EAIP0K,EAAY,IAAI3K,EACpB,EACAoE,EAAM,GAAGxH,KAAOwH,EAAM,GAAGnE,KAAOmE,EAAMnJ,QAEpC2P,EAAe,EARN,cAWOxG,GAXP,IAWb,2BACE,IAD0B,IAAnBgG,EAAkB,QAChBnJ,EAAI,EAAGA,EAAImJ,EAAQxN,KAAMqE,IAChC,IAAK,IAAIC,EAAI,EAAGA,EAAIkJ,EAAQnK,KAAMiB,IAChCyJ,EAAUnO,KAAK,GAAGoO,GAAgBR,EAAQ5N,KAAKyE,GAAGC,GAClD0J,IAfO,8BAmBb1L,KAAKsK,UAAYmB,EAGjB,IAAM9I,EAAI7B,EAAOmC,IAAIwI,EAAWzL,KAAK2E,SAASS,IAAIpF,KAAKyE,QACvDzE,KAAK2L,MAAQhJ,EAKb,IAFA,IAAMG,EAAMhC,EAAOI,IAAIyB,EAAGvH,KAAK0H,KAC3BN,EAAM,EACDR,EAAI,EAAGA,EAAIc,EAAI/B,KAAMiB,IAC5BQ,GAAOM,EAAIxF,KAAK,GAAG0E,GAErB,OAAOc,EAAIc,IAAIpB,K,+BASRiI,EAAQhF,GAGf,IADA,IAAImG,EAAW,EACNrM,EAAI,EAAGA,EAAIkL,EAAO1J,KAAMxB,IAC/B,GAA0B,IAAtBkL,EAAOnN,KAAK,GAAGiC,GAAU,CAC3BqM,EAAWrM,EACX,MAWJ,IARA,IAAM6H,EAAWqD,EAAOnN,KAAK,GAAGsO,GAG1BC,EAAO/K,EAAOI,IAAIlB,KAAK2L,MAAOvQ,KAAK0H,KACnCgJ,EAAcD,EAAKvO,KAAK,GAAGsO,GAG7BG,EAAI,EACC/J,EAAI,EAAGA,EAAI6J,EAAK9K,KAAMiB,IAC7B+J,GAAKF,EAAKvO,KAAK,GAAG0E,GAOpB,IAAMgK,EAASH,EAAK5I,KAAK6I,EAAD,SAAeC,EAAK,IAC5CC,EAAO1O,KAAK,GAAGsO,GAAaE,GAAeC,EAAID,GAApB,SAAoCC,EAAK,GAGpE,IAAME,EAAOjM,KAAKsK,UACZ4B,EAAYlM,KAAK2E,QAGjBwH,EAAOH,EAAO/I,IAAImE,GAGlBgF,EAAOtL,EAAOmC,IAAInC,EAAOyC,UAAU0I,GAAOE,GAC1CE,EAAOF,EACPhB,EAAYrK,EAAOmC,IAAIkJ,EAAMrL,EAAOyC,UAAU2I,IAGpDlM,KAAK2E,QAAQhB,IAAIyI,EAAKnJ,IAAIwC,IAC1BzF,KAAKyE,OAAOd,IAAI0I,EAAKpJ,IAAIwC,IASzB,IANA,IAAM6G,EAAWtM,KAAKwL,eAAe,GAC/B9N,EAAOsC,KAAKwL,eAAe,GAC3BzK,EAAOf,KAAKwL,eAAe,GAC7Be,EAAQ,EACNC,EAAoB,GAEjBjN,EAAI,EAAGA,EAAI+M,EAAU/M,IAAK,CAGjC,IAFA,IAAMkN,EAAkB,IAAI3L,EAAOpD,EAAMqD,GAEhCgB,EAAI,EAAGA,EAAIrE,EAAMqE,IACxB,IAAK,IAAIC,EAAI,EAAGA,EAAIjB,EAAMiB,IACxByK,EAAgBnP,KAAKyE,GAAGC,GAAKmJ,EAAU7N,KAAK,GAAGiP,GAC/CA,IAIJC,EAAkB9Q,KAAK+Q,GAGzB,OAAOD,M,KC6BIE,E,WAlJb,aAAyB,IAAbC,EAAY,uDAAN,KAAM,oBACV,OAARA,GACF3M,KAAKgK,KAAO,IAAIH,EAAK,KAAM,KAAM8C,EAAI3C,MACrChK,KAAK8K,KAAO,IAAIF,EAAQ,KAAM+B,EAAI7B,MAClC9K,KAAK+C,QAAU,IAAIsI,EAAQ,KAAM,KAAMsB,EAAI5J,WAE3C/C,KAAKgK,KAAO,IAAIH,EAAK,GACrB7J,KAAK8K,KAAO,IAAIF,EAChB5K,KAAK+C,QAAU,IAAIsI,EAAQ,KAAa,K,oDASpClB,GAEN,IAAIyC,EAAM5M,KAAKgK,KAAKjD,QAAQoD,GAG5B,OAFAyC,EAAM5M,KAAK8K,KAAK/D,QAAQ6F,IACxBA,EAAM5M,KAAK+C,QAAQgE,QAAQ6F,IAChBvH,Y,4BAUPC,EAAYC,EAAQE,GACxB,IADyD,IAAnBE,EAAkB,uDAAN,KACzCkH,EAAQ,EAAGA,EAAQtH,EAAQsH,IAAS,CAC3C/I,EAAQwB,GAKR,IAHA,IAAIwH,EAAO,EACPC,EAAa,EAERxN,EAAI,EAAGA,EAAI+F,EAAWvJ,OAAQwD,IAAK,CAC1C,IAAM+G,EAAYhB,EAAW/F,GACvB4K,EAAQ7D,EAAU,GAClB0G,EAAQ1G,EAAU,GAHkB,EAMhB0G,EAAM/K,MANU,mBAMhCgL,GANgC,mBASpBjN,KAAK+G,QAAQoD,EAAO6C,IATA,mBASnCJ,EATmC,KAS9BM,EAT8B,KAS3BC,EAT2B,KAY1CL,GAAQI,EACRH,GAAcI,EAGd,IAAI/F,EAAW,IAAItG,EAAO,EAAG,IAC7BsG,EAAS9J,KAAK,GAAG2P,IAAa,EAAIL,EAAItP,KAAK,GAAG2P,GAG9C7F,EAAWpH,KAAK+C,QAAQ0D,SAASW,EAAU3B,GAC3C2B,EAAWpH,KAAK8K,KAAKrE,SAASW,GAC9BpH,KAAKgK,KAAKvD,SAASW,EAAU3B,GAEzBlG,EAAI,MAAQ,KACd4B,QAAQC,IACN,cACG7B,EAAI,GACL,IACA+F,EAAWvJ,OACX,oBACA+Q,EAAO,IACP,gBACAC,EACA,QAEJD,EAAO,EACPC,EAAa,GAKf5L,QAAQC,IAAI6E,KAAKC,UAAUlG,OAIb,OAAd2F,GACF3F,KAAKoN,KAAKzH,K,8BAUNwE,EAAO6C,GAEb,IAAIJ,EAAM5M,KAAKgK,KAAKjD,QAAQoD,GAC5ByC,EAAM5M,KAAK8K,KAAK/D,QAAQ6F,GACxBA,EAAM5M,KAAK+C,QAAQgE,QAAQ6F,GAJP,MAOMI,EAAM/K,MAPZ,mBAOVgL,GAPU,mBAQQL,EAAI3K,OARZ,mBAQFoL,GARE,gBAcpB,MAAO,CAACT,GAHMxR,KAAKgG,IAAIwL,EAAItP,KAAK,GAAG2P,IACvBI,IAAWJ,EAAW,EAAI,K,2BASnCtH,GACH,IADc,EACVmH,EAAO,EACPC,EAAa,EAFH,cAKOpH,GALP,IAKd,2BAAgC,CAAC,IAAxB6B,EAAuB,QACxB2C,EAAQ3C,EAAS,GACjBwF,EAAQxF,EAAS,GAFO,EAIVxH,KAAK+G,QAAQoD,EAAO6C,GAJV,mBAIpBE,GAJoB,WAIjBC,EAJiB,KAK9BL,GAAQI,EACRH,GAAcI,GAXF,8BAed,IAAMG,EAAW3H,EAAU5J,OAC3BoF,QAAQC,IAAI,aAAc0L,EAAOQ,GACjCnM,QAAQC,IACN,kBACE2L,EACA,IACAO,EACA,KACC,IAAMP,EAAcO,EACrB,S,KC6aOC,GA1iBF,SAAG,IAAO,K,kDAKrB,WAAYC,GAAQ,IAAD,8BACjB,cAAMA,IA8WRC,cAAgB,WACd,QAAkBC,IAAd,EAAKtJ,WAAmCsJ,IAAb,EAAKf,IAAmB,CACrD,IAAMgB,EAAW,EAAKC,UAAUC,QAAQrP,UAClCsP,EAAYhN,EAAOgH,gBAAgB6F,GACnCI,EAAWjN,EAAOkN,gBAAgBL,EAAU,GAAI,IArYhC,EA6YtB,IAAMM,EAAgB,EAAK7J,KAAK5F,QAAQsP,GAClCI,EAAWD,EAActG,QAAQvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQ6S,KAE7CE,EAAe,EAAKxB,IAAInO,QAAQuP,GAChCK,EAAUD,EAAaxG,QAAQvM,KAAK6G,IAAL,MAAA7G,KAAI,YAAQ+S,KAGjD,EAAKE,SAAS,CACZJ,gBACAE,eACAD,WACAE,cAtYa,EA8YnBE,YAAc,WACZ,EAAKV,UAAUC,QAAQnR,QAEvB,EAAK2R,SAAS,CACZJ,cAAe,GACfE,aAAc,GACdD,SAAU,GACVE,QAAS,MAnZX,EAAKG,MAAQ,CACXN,cAAe,GACfE,aAAc,GACdD,SAAU,GACVE,QAAS,IA4ET,EAAKhK,KAAO,IAAIF,EAAK,KAAMsK,GAC3B,EAAK7B,IAAM,IAAID,EAAI+B,GAGrB,EAAKb,UAAYc,IAAMC,YAtFN,E,gEA2FjB3O,KAAK4O,gB,oCAUL,IAHA,IAAMC,EAAU,GAGPtP,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAI3B,IAHA,IAAMuP,EAAe,GAGZ7N,EAAI,EAAGA,EAAIjB,KAAK+O,MAAMC,WAAWjT,SACpCiE,KAAK+O,MAAME,WAAWhO,KAAO1B,IAC/BuP,EAAapT,KAAK+D,MAAMyP,KAAKlP,KAAK+O,MAAMC,WAAW/N,KA9GnC,IAiHZ6N,EAAa/S,SAL6BkF,KAWlD4N,EAAQnT,KAAKoT,GAGf3N,QAAQC,IAAI6E,KAAKC,UAAU2I,M,oCAQ3B,IAAK,IAAItP,EAAI,EAAGA,EAAI,GAAIA,IAEtB,IAAK,IAAI0B,EAAI,EAAGA,EApII,EAoImBA,IAKrC,IAHA,IACMlG,EADS8D,SAASoB,eAAT,iBAAkCV,EAAlC,YAAuC0B,IACnCjC,WAAW,MAErB7B,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAE3B,IAAMyC,EAAQ9E,EAAIoU,gBAAgB,EAAG,GAC/BrP,EAAS,IAAMsP,EAAa7P,GAAG0B,GAAO,GAAJ9D,EAASC,GAGjDyC,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAKwC,EAChBD,EAAMvC,KAAK,GAAK,IAGhBvC,EAAIgF,aAAaF,EAAOzC,EAAGD,M,sEAyE3BkS,EAAQC,EAAQC,GAGxB,IAFA,IAAM3H,EAAQ,GAELrI,EAAI,EAAGA,EAAI8P,EAAOtT,OAAQwD,IAAK,CAKtC,IAJA,IAAMoO,EAAW0B,EAAO9P,GAClBiQ,EAAYF,EAAO/P,GACnBkQ,EAAY,GAETxO,EAAI,EAAGA,EAAI,GAAIA,IAClBuO,IAAcvO,EAChBwO,EAAU/T,KAAK,GAEf+T,EAAU/T,KAAK,GAInBkM,EAAMlM,KAAK,CACT6T,EACIzO,EAAOgH,gBAAgB6F,GACvB7M,EAAOkN,gBAAgBL,EAAU,GAAI,IACzC7M,EAAOgH,gBAAgB2H,KAI3B,OAAO7H,I,iFAwDU,IAAD,OAEhB,IAAK5H,KAAKoE,KAAKS,eAAe,aAAc,CAC1C,IAAMnF,EAAO,IAAIoB,EAAO,IAAK,GACvB4O,EAAM,IAAI5O,EAAO,IAAK,GAG5BK,QAAQC,IAAI,+BAL8B,oBAMpBpB,KAAK2P,gBANe,IAM1C,2BAA2C,CAAC,IAAnCrJ,EAAkC,QACzC5G,EAAK0F,IAAIkB,EAAU,KAPqB,8BAW1C5G,EAAKwB,KAAI,SAAC9D,GAAD,OAAOA,EAAI,EAAKuS,eAAe5T,UAGxCoF,QAAQC,IAAI,6CAd8B,oBAepBpB,KAAK2P,gBAfe,IAe1C,2BAA2C,CAAC,IAAnCrJ,EAAkC,QACzCoJ,EAAItK,IAAItE,EAAO6C,IAAI2C,EAAU,GAAI5G,GAAMwB,KAAI,SAAC9D,GAAD,gBAAOA,EAAK,QAhBf,8BAoB1CsS,EAAIxO,KAAI,SAAC9D,GAAD,OAAOhC,KAAKsG,KAAKtE,EAAI,EAAKuS,eAAe5T,WAGjDiE,KAAKoE,KAAKU,UAAYpF,EACtBM,KAAKoE,KAAKW,SAAW2K,EAIV1P,KAAKoE,KAAKU,UACX9E,KAAKoE,KAAKW,W,+BAgFtB,IADA,IAAM+J,EAAe,GACZvP,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAG3B,IAFA,IAAMwB,EAAO,GAEJE,EAAI,EAAGA,EAjaI,EAiamBA,IAAK,CAC1C,IAAM2O,EACJ,yBAAK/V,UAAU,WAAWgW,IAAG,cAAStQ,EAAT,YAAc0B,IACzC,4BACEX,GAAE,iBAAYf,EAAZ,YAAiB0B,GACnBrE,MAAM,KACNC,OAAO,KACP2D,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,YAKzBI,EAAKrF,KAAKkU,GAGZ,IAAME,EACJ,yBAAKjW,UAAU,6BAA6BgW,IAAG,cAAStQ,IACrDwB,GAGL+N,EAAapT,KAAKoU,GAIpB,IADA,IAAMC,EAAY,GACTxQ,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMyQ,EACJ,yBAAKnW,UAAU,MAAMgW,IAAK,MAAQtQ,GAChC,yBAAK1F,UAAU,kBACb,4BAAK0F,EAAL,MAEF,yBAAK1F,UAAU,iBACb,4BACGmG,KAAKuO,MAAMN,cAAclS,OAAS,GACA,IAA9BiE,KAAKuO,MAAMN,cAAc1O,IAAU0Q,QAAQ,GAAK,IACjD,MAKZF,EAAUrU,KAAKsU,GAGjB,IADA,IAAME,EAAW,GACR3Q,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMyQ,EACJ,yBAAKnW,UAAU,MAAMgW,IAAK,MAAQtQ,GAChC,yBAAK1F,UAAU,kBACb,4BAAK0F,EAAL,MAEF,yBAAK1F,UAAU,iBACb,4BACGmG,KAAKuO,MAAMJ,aAAapS,OAAS,GACA,IAA7BiE,KAAKuO,MAAMJ,aAAa5O,IAAU0Q,QAAQ,GAAK,IAChD,MAKZC,EAASxU,KAAKsU,GAGhB,OACE,yBAAKnW,UAAU,kCACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,OACb,wBAAIA,UAAU,oBAAd,oBACA,8IAGE,6BAHF,8EAOA,wBAAIA,UAAU,QAAd,kBACCiV,EACD,yBAAKjV,UAAU,mCACb,yBAAKA,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,UAAUC,QAASoG,KAAKyN,iBAExC,yBAAK5T,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,QAAQC,QAASoG,KAAKsO,gBAGxC,yBAAKzU,UAAU,QACb,kBAAC,EAAD,CAAQsW,IAAKnQ,KAAK4N,aAEpB,4BACEtN,GAAG,WACH1D,MAAM,KACNC,OAAO,KACP2D,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,WAGrB,yBAAK9G,UAAU,8BACb,yBAAKA,UAAU,2BACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,kBACb,wBAAIA,UAAU,oBAAd,UAEF,yBAAKA,UAAU,iBACb,wBAAIA,UAAU,oBAAoBmG,KAAKuO,MAAML,YAGhD6B,GAEH,yBAAKlW,UAAU,2BACb,yBAAKA,UAAU,wBACb,yBAAKA,UAAU,kBACb,wBAAIA,UAAU,oBAAd,SAEF,yBAAKA,UAAU,iBACb,wBAAIA,UAAU,oBAAoBmG,KAAKuO,MAAMH,WAGhD8B,MAKT,kBAAC,IAAD,CACEE,KAAK,mDACLC,YAAY,OACZC,UAAU,UACVtW,OAAO,gB,GA/hBC4G,cCrBE2P,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASC,MACvB,2D,YCXNC,IAASC,OAAO,kBAAC,EAAD,MAAShS,SAASoB,eAAe,SD4H3C,kBAAmB6Q,WACrBA,UAAUC,cAAcC,MAAMC,MAAK,SAAAC,GACjCA,EAAaC,kB","file":"static/js/main.4a0c6965.chunk.js","sourcesContent":["import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Button = ({ value, onClick }) => {\r\n  const handleOnClick = (e) => {\r\n    // Remove focus from button\r\n    e.target.blur();\r\n    onClick();\r\n  };\r\n\r\n  return (\r\n    <button\r\n      className=\"btn btn-primary btn-lg\"\r\n      type=\"button\"\r\n      onClick={handleOnClick}\r\n    >\r\n      {value}\r\n    </button>\r\n  );\r\n};\r\n\r\nButton.propTypes = {\r\n  value: PropTypes.string,\r\n  onClick: PropTypes.func,\r\n};\r\n\r\nexport default Button;\r\n","import React, { Component } from \"react\";\r\n\r\nconst WIDTH = 280;\r\nconst HEIGHT = 280;\r\nconst SCALE_SIZE = 190;\r\nconst BOUNDING_THRESHOLD = 0.01;\r\nconst LINE_WIDTH = 20;\r\nconst COLOR = \"black\";\r\nconst SCALE_PATH = true;\r\n\r\nconst DEBUG = false;\r\n\r\nclass Canvas extends Component {\r\n  componentDidMount() {\r\n    this.canvas = document.getElementById(\"main-canvas\");\r\n    this.ctx = this.canvas.getContext(\"2d\");\r\n    this.canvas28 = document.getElementById(\"canvas28\");\r\n    this.ctx28 = this.canvas28.getContext(\"2d\");\r\n\r\n    // Mouse\r\n    this.canvas.addEventListener(\r\n      \"mousedown\",\r\n      (e) => {\r\n        this.findxy(\"down\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseup\",\r\n      (e) => {\r\n        this.findxy(\"up\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseout\",\r\n      (e) => {\r\n        this.findxy(\"out\", e, false);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mousemove\",\r\n      (e) => {\r\n        this.findxy(\"move\", e, false);\r\n      },\r\n      false\r\n    );\r\n\r\n    // Touchscreen\r\n    this.canvas.addEventListener(\r\n      \"touchstart\",\r\n      (e) => {\r\n        this.findxy(\"down\", e, true);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"touchend\",\r\n      (e) => {\r\n        this.findxy(\"up\", e, true);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"touchmove\",\r\n      (e) => {\r\n        this.findxy(\"move\", e, true);\r\n      },\r\n      false\r\n    );\r\n\r\n    // Prevent scrolling while drawing on touchscreen\r\n    document.body.addEventListener(\r\n      \"touchstart\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n    document.body.addEventListener(\r\n      \"touchend\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n    document.body.addEventListener(\r\n      \"touchmove\",\r\n      (e) => {\r\n        if (e.target === this.canvas) {\r\n          e.preventDefault();\r\n        }\r\n      },\r\n      { passive: false }\r\n    );\r\n\r\n    this.prevX = 0;\r\n    this.currX = 0;\r\n    this.prevY = 0;\r\n    this.currY = 0;\r\n    this.paths = [];\r\n    this.paintFlag = false;\r\n  }\r\n\r\n  findxy = (res, e, isTouch) => {\r\n    if (res === \"down\") {\r\n      // Get touch down point\r\n      this.currX =\r\n        (isTouch ? e.touches[0].clientX : e.clientX) -\r\n        this.canvas.getBoundingClientRect().left;\r\n      this.currY =\r\n        (isTouch ? e.touches[0].clientY : e.clientY) -\r\n        this.canvas.getBoundingClientRect().top;\r\n\r\n      // Draw circle\r\n      this.ctx.beginPath();\r\n      this.ctx.lineWidth = 1;\r\n      this.ctx.arc(this.currX, this.currY, LINE_WIDTH / 2, 0, 2 * Math.PI);\r\n      this.ctx.stroke();\r\n      this.ctx.closePath();\r\n      this.ctx.fill();\r\n\r\n      // Add start of new path\r\n      this.paths.push([[this.currX], [this.currY]]);\r\n\r\n      // Activate paint flag\r\n      this.paintFlag = true;\r\n    }\r\n\r\n    // Deactivate paint flag on touch up or mouse off canvas\r\n    if (res === \"up\" || res === \"out\") {\r\n      this.paintFlag = false;\r\n    }\r\n\r\n    // If moving and paint flag activated, draw!\r\n    if (res === \"move\" && this.paintFlag) {\r\n      // Save previous point\r\n      this.prevX = this.currX;\r\n      this.prevY = this.currY;\r\n\r\n      // Get new point\r\n      this.currX =\r\n        (isTouch ? e.touches[0].clientX : e.clientX) -\r\n        this.canvas.getBoundingClientRect().left;\r\n      this.currY =\r\n        (isTouch ? e.touches[0].clientY : e.clientY) -\r\n        this.canvas.getBoundingClientRect().top;\r\n\r\n      // Add point to last path\r\n      const currPath = this.paths[this.paths.length - 1];\r\n      currPath[0].push(this.currX);\r\n      currPath[1].push(this.currY);\r\n      this.paths[this.paths.length - 1] = currPath;\r\n\r\n      // Draw line between new point and previous point\r\n      this.draw(\r\n        this.ctx,\r\n        LINE_WIDTH,\r\n        this.prevX,\r\n        this.prevY,\r\n        this.currX,\r\n        this.currY\r\n      );\r\n    }\r\n  };\r\n\r\n  // Draw line between 2 points\r\n  draw = (ctx, lineWidth, x1, y1, x2, y2) => {\r\n    ctx.beginPath();\r\n    ctx.strokeStyle = COLOR;\r\n    ctx.lineWidth = lineWidth;\r\n    ctx.lineCap = \"round\";\r\n    ctx.lineJoin = \"round\";\r\n    ctx.moveTo(x1, y1);\r\n    ctx.lineTo(x2, y2);\r\n    ctx.stroke();\r\n    ctx.closePath();\r\n  };\r\n\r\n  // Erase canvas and clear paths\r\n  erase = () => {\r\n    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n    this.paths = [];\r\n\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n  };\r\n\r\n  imageDataToGrayscale = (imgData) => {\r\n    // 2D array\r\n    const grayscaleImg = [];\r\n\r\n    for (let y = 0; y < imgData.height; y++) {\r\n      // Row number y\r\n      grayscaleImg[y] = [];\r\n\r\n      for (let x = 0; x < imgData.width; x++) {\r\n        // Each pixel has four values, RGBA\r\n        const offset = y * 4 * imgData.width + 4 * x;\r\n\r\n        // Alpha === 0 means no drawing\r\n        const alpha = imgData.data[offset + 3];\r\n\r\n        // No drawing, set value to white\r\n        if (alpha === 0) {\r\n          imgData.data[offset] = 255;\r\n        }\r\n\r\n        // Take only RED value since grayscale and scale to [0, 1]\r\n        grayscaleImg[y][x] = imgData.data[offset] / 255;\r\n        // grayscaleImg[y][x] = imgData.data[offset];\r\n      }\r\n    }\r\n\r\n    return grayscaleImg;\r\n  };\r\n\r\n  getBoundingRect = (img, threshold) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let minX = columns;\r\n    let minY = rows;\r\n    let maxX = -1;\r\n    let maxY = -1;\r\n\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        // Black === 0, so must be lower than some darkness threshold to be considered significant\r\n        if (img[y][x] < threshold) {\r\n          if (minX > x) minX = x;\r\n          if (maxX < x) maxX = x;\r\n          if (minY > y) minY = y;\r\n          if (maxY < y) maxY = y;\r\n        }\r\n      }\r\n    }\r\n\r\n    return { minY: minY, minX: minX, maxY: maxY, maxX: maxX };\r\n  };\r\n\r\n  centerImage = (img) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let meanX = 0;\r\n    let meanY = 0;\r\n    let sumPixels = 0;\r\n\r\n    // Center of mass, weighted by color intensity\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        let pixel = 1 - img[y][x];\r\n        meanX += x * pixel;\r\n        meanY += y * pixel;\r\n        sumPixels += pixel;\r\n      }\r\n    }\r\n    meanX /= sumPixels;\r\n    meanY /= sumPixels;\r\n\r\n    let dx = Math.round(columns / 2 - meanX);\r\n    let dy = Math.round(rows / 2 - meanY);\r\n\r\n    return { transX: dx, transY: dy };\r\n  };\r\n\r\n  predict = () => {\r\n    // Get image and convert to grayscale\r\n    let imgData = this.ctx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    let grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Get bounding rectangle and center of mass translation amount\r\n    const boundingRect = this.getBoundingRect(grayscaleImg, BOUNDING_THRESHOLD);\r\n    // const boundingRect = this.getBoundingRect(grayscaleImg, 25);\r\n    const trans = this.centerImage(grayscaleImg);\r\n\r\n    // Create hidden copy of canvas context\r\n    const canvasCopy = document.createElement(\"canvas\");\r\n    canvasCopy.width = imgData.width;\r\n    canvasCopy.height = imgData.height;\r\n    const copyCtx = canvasCopy.getContext(\"2d\");\r\n\r\n    // Scale largest dimension to SCALE_SIZE\r\n    const brW = boundingRect.maxX - boundingRect.minX + 1;\r\n    const brH = boundingRect.maxY - boundingRect.minY + 1;\r\n    const scaling = SCALE_SIZE / (brW > brH ? brW : brH);\r\n\r\n    // Scale\r\n    copyCtx.translate(this.canvas.width / 2, this.canvas.height / 2);\r\n    copyCtx.scale(scaling, scaling);\r\n    copyCtx.translate(-this.canvas.width / 2, -this.canvas.height / 2);\r\n\r\n    // Center on canvas over center of mass\r\n    copyCtx.translate(trans.transX, trans.transY);\r\n\r\n    if (SCALE_PATH) {\r\n      // Scale path line width\r\n      for (let p = 0; p < this.paths.length; p++) {\r\n        for (let i = 0; i < this.paths[p][0].length - 1; i++) {\r\n          const x1 = this.paths[p][0][i];\r\n          const y1 = this.paths[p][1][i];\r\n          const x2 = this.paths[p][0][i + 1];\r\n          const y2 = this.paths[p][1][i + 1];\r\n          this.draw(copyCtx, LINE_WIDTH / scaling, x1, y1, x2, y2);\r\n        }\r\n      }\r\n    } else {\r\n      copyCtx.drawImage(this.ctx.canvas, 0, 0);\r\n    }\r\n\r\n    // Get scaled and translated image and convert to grayscale\r\n    imgData = copyCtx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Final input array for neural net\r\n    const nnInput = new Array(784);\r\n\r\n    // Convert to 28x28\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        let mean = 0;\r\n        for (let v = 0; v < 10; v++) {\r\n          for (let h = 0; h < 10; h++) {\r\n            mean += grayscaleImg[y * 10 + v][x * 10 + h];\r\n          }\r\n        }\r\n\r\n        // Average and invert color\r\n        nnInput[y * 28 + x] = 1 - mean / 100;\r\n        // nnInput[y + 28 * x] = 255 - mean / 100;\r\n      }\r\n    }\r\n\r\n    // Draw to 28x28 canvas\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        const block = this.ctx28.getImageData(x, y, 1, 1);\r\n        const newVal = 255 * nnInput[y * 28 + x];\r\n\r\n        block.data[0] = newVal;\r\n        block.data[1] = newVal;\r\n        block.data[2] = newVal;\r\n        block.data[3] = 255;\r\n\r\n        this.ctx28.putImageData(block, x, y);\r\n      }\r\n    }\r\n\r\n    // Draw neural network input back to canvas\r\n    if (DEBUG) {\r\n      // Clear canvas\r\n      this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n\r\n      for (let y = 0; y < 28; y++) {\r\n        for (let x = 0; x < 28; x++) {\r\n          // Blocks of 10\r\n          const block = this.ctx.getImageData(x * 10, y * 10, 10, 10);\r\n          const newVal = 255 * nnInput[y * 28 + x];\r\n          // const newVal = nnInput[y + 28 * x];\r\n\r\n          // R=G=B since grayscale, A=255 for full opacity\r\n          for (let i = 0; i < 4 * 10 * 10; i += 4) {\r\n            block.data[i] = newVal;\r\n            block.data[i + 1] = newVal;\r\n            block.data[i + 2] = newVal;\r\n            block.data[i + 3] = 255;\r\n          }\r\n\r\n          // Paint new data to canvas\r\n          this.ctx.putImageData(block, x * 10, y * 10);\r\n        }\r\n      }\r\n    }\r\n\r\n    return nnInput;\r\n  };\r\n\r\n  render() {\r\n    return (\r\n      <canvas\r\n        id=\"main-canvas\"\r\n        width={WIDTH.toString()}\r\n        height={HEIGHT.toString()}\r\n        style={{\r\n          border: \"5px solid aquamarine\",\r\n          borderRadius: \"5px\",\r\n          backgroundColor: \"white\",\r\n        }}\r\n      ></canvas>\r\n    );\r\n  }\r\n}\r\n\r\nexport default Canvas;\r\n","/**\r\n * Loads the MNIST data.\r\n * @param {function} callback The callback function to be called when loading is finished\r\n * @return {Promise} The resolved promise\r\n */\r\nfunction loadMNIST(callback) {\r\n  let mnist = {};\r\n  let files = {\r\n    trainImages: \"./train-images.idx3-ubyte\",\r\n    trainLabels: \"./train-labels.idx1-ubyte\",\r\n    testImages: \"./t10k-images.idx3-ubyte\",\r\n    testLabels: \"./t10k-labels.idx1-ubyte\",\r\n  };\r\n\r\n  // Load all files\r\n  return Promise.all(\r\n    Object.keys(files).map(async (file) => {\r\n      mnist[file] = await loadFile(files[file]);\r\n    })\r\n  ).then(() => callback(mnist));\r\n}\r\n\r\n/**\r\n * Parses the MNIST file into an array of data.\r\n * @param {string} file The filename\r\n * @return {Array} The MNIST data\r\n */\r\nasync function loadFile(file) {\r\n  // Fetch file response\r\n  let response = await fetch(file);\r\n\r\n  // Get 8-bit/1-byte array\r\n  let buffer = await response.arrayBuffer();\r\n\r\n  // Default header count is 4 for images, change to 2 for labels later\r\n  let headerCount = 4;\r\n\r\n  // Can't access data straight from ArrayBuffer, extract headers using DataView\r\n  let headerView = new DataView(buffer, 0, 4 * headerCount);\r\n\r\n  // Create Array of 32-bit/4-byte headers\r\n  let headers = new Array(headerCount)\r\n    .fill()\r\n    .map((_, i) => headerView.getUint32(4 * i, false));\r\n\r\n  // Get file type: image or label\r\n  let type, dataLength;\r\n  if (headers[0] === 2049) {\r\n    type = \"label\";\r\n    dataLength = 1;\r\n    headerCount = 2;\r\n  } else if (headers[0] === 2051) {\r\n    type = \"image\";\r\n    dataLength = headers[2] * headers[3];\r\n  } else {\r\n    throw new Error(\"Unknown file type \" + headers[0]);\r\n  }\r\n\r\n  // Create array of data only, headers removed\r\n  let data = new Uint8Array(buffer, headerCount * 4);\r\n\r\n  // Image, create array of subarrays of 28 * 28 = 784\r\n  if (type === \"image\") {\r\n    let dataArr = [];\r\n    for (let i = 0; i < headers[1]; i++) {\r\n      dataArr.push(data.subarray(dataLength * i, dataLength * (i + 1)));\r\n    }\r\n    console.log(\"Loaded file:\", file);\r\n    return dataArr;\r\n  }\r\n\r\n  // Label, just return data straight away\r\n  console.log(\"Loaded file:\", file);\r\n  return data;\r\n}\r\n\r\nexport default loadMNIST;\r\n","class Matrix {\r\n  /**\r\n   * Creates an empty matrix of all zeros or from the given Matrix.\r\n   * @param {number} rows The number of rows\r\n   * @param {number} cols The number of columns\r\n   * @param {Matrix} matrix A Matrix to copy\r\n   */\r\n  constructor(rows, cols, matrix) {\r\n    if (matrix) {\r\n      // Deep copy\r\n      this.rows = matrix.rows;\r\n      this.cols = matrix.cols;\r\n      this.data = [];\r\n      for (let i = 0; i < this.rows; i++) {\r\n        this.data.push([]);\r\n        for (let j = 0; j < this.cols; j++) {\r\n          this.data[i].push(matrix.data[i][j]);\r\n        }\r\n      }\r\n    } else {\r\n      this.rows = rows;\r\n      this.cols = cols;\r\n      this.data = Array(rows)\r\n        .fill()\r\n        .map(() => Array(cols).fill(0));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Element-wise addition by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to add by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  add(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Add: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x + matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x + matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise addition into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the addition of the two given matrices\r\n   */\r\n  static add(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Add: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] + matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Element-wise subtraction by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to subtract by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  sub(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Subtract: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x - matrix.data[i][j]);\r\n    }\r\n    //Scaler\r\n    return this.map((x) => x - matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise subtraction into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the subtraction of the two given matrices\r\n   */\r\n  static sub(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Subtract: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] - matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Element-wise multiplication by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The scaler or Matrix to multiply by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  mul(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Multiply: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x * matrix.data[i][j]);\r\n    }\r\n    // Scaler\r\n    return this.map((x) => x * matrix);\r\n  }\r\n\r\n  /**\r\n   * Matrix multiplication into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the matrix multiplication of the two given matrices\r\n   */\r\n  static mul(matrix1, matrix2) {\r\n    if (matrix1.cols !== matrix2.rows) {\r\n      console.log(\r\n        \"Multiply: first matrix's columns must match second matrix's rows\"\r\n      );\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix2.cols).map((_, i, j) => {\r\n      let sum = 0;\r\n      for (let k = 0; k < matrix1.cols; k++) {\r\n        sum += matrix1.data[i][k] * matrix2.data[k][j];\r\n      }\r\n      return sum;\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Element-wise division by a Matrix or scaler.\r\n   * @param {(Matrix | number)} matrix The Matrix or scaler to divide by\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  div(matrix) {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Division: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      // Matrix\r\n      return this.map((x, i, j) => x / matrix.data[i][j]);\r\n    }\r\n    // Scaler\r\n    return this.map((x) => x / matrix);\r\n  }\r\n\r\n  /**\r\n   * Element-wise division into a new Matrix.\r\n   * @param {Matrix} matrix1 The first Matrix\r\n   * @param {Matrix} matrix2 The second Matrix\r\n   * @return {Matrix} A new Matrix from the division of the two given matrices\r\n   */\r\n  static div(matrix1, matrix2) {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Division: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] / matrix2.data[i][j]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Transposes the Matrix.\r\n   * @param {Matrix} matrix The Matrix to transpose\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  static transpose(matrix) {\r\n    return new Matrix(matrix.cols, matrix.rows).map(\r\n      (_, i, j) => matrix.data[j][i]\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Converts the array into a column vector.\r\n   * @param {Array} arr The array to convert to a vector\r\n   * @return {Matrix} The array as a column vector\r\n   */\r\n  static vectorFromArray(arr) {\r\n    return new Matrix(arr.length, 1).map((_, i) => arr[i]);\r\n  }\r\n\r\n  /**\r\n   * Converts the array into a Matrix of the given dimensions.\r\n   * @param {Array} arr The array to convert to a Matrix\r\n   * @param {number} rows The number of rows for the new Matrix\r\n   * @param {number} cols The number of columns for the new Matrix\r\n   * @return {Matrix} The array as a Matrix of the given dimension\r\n   */\r\n  static matrixFromArray(arr, rows, cols) {\r\n    return new Matrix(rows, cols).map((_, i, j) => arr[i * cols + j]);\r\n  }\r\n\r\n  /**\r\n   * Converts this Matrix to an array.\r\n   * @return {Array} This Matrix as an array\r\n   */\r\n  toArray() {\r\n    const arr = [];\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        arr.push(this.data[i][j]);\r\n      }\r\n    }\r\n    return arr;\r\n  }\r\n\r\n  /**\r\n   * Returns a copy of this Matrix.\r\n   * @return {Matrix} A copy of this Matrix\r\n   */\r\n  copy() {\r\n    return new Matrix(this.rows, this.cols).map((_, i, j) => this.data[i][j]);\r\n  }\r\n\r\n  /**\r\n   * Applies the function to the Matrix.\r\n   * @param {Function} func The function to apply to the Matrix\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  map(func) {\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        this.data[i][j] = func(this.data[i][j], i, j);\r\n      }\r\n    }\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Applies the function to the Matrix and returns a new Matrix.\r\n   * @param {Matrix} matrix The Matrix to apply the function to\r\n   * @param {Function} func The function to apply to the Matrix\r\n   * @return {Matrix} A new Matrix from applying the function to the Matrix\r\n   */\r\n  static map(matrix, func) {\r\n    return new Matrix(matrix.rows, matrix.cols).map((_, i, j) =>\r\n      func(matrix.data[i][j], i, j)\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Randomize [-1, 1].\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  randomize() {\r\n    return this.map(() => Math.random() * 2 - 1);\r\n  }\r\n\r\n  /**\r\n   * Box-Muller Transform for normal distribution, mean = 0, variance = 1.\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  randomizeNormal() {\r\n    return this.map(() => {\r\n      let u = 0;\r\n      let v = 0;\r\n      while (u === 0) u = Math.random();\r\n      while (v === 0) v = Math.random();\r\n      return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Prints the Matrix as a table.\r\n   * @return {Matrix} The Matrix for chaining\r\n   */\r\n  print() {\r\n    console.table(this.data);\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Returns a region of this Matrix.\r\n   * @param {number} x The column offset\r\n   * @param {number} y The row offset\r\n   * @param {number} w The width of the region to extract\r\n   * @param {number} h The height of the region to extract\r\n   * @return {Matrix} The region of this Matrix\r\n   */\r\n  getRegion(x, y, w, h) {\r\n    const region = new Matrix(h, w);\r\n    for (let r = 0; r < h; r++) {\r\n      for (let c = 0; c < w; c++) {\r\n        region.data[r][c] = this.data[y + r][x + c];\r\n      }\r\n    }\r\n    return region;\r\n  }\r\n\r\n  /**\r\n   * Returns the max value and the corresponding row and column.\r\n   * @return {Array} The max value and the corresponding row and column.\r\n   */\r\n  max() {\r\n    let max = Number.NEGATIVE_INFINITY;\r\n    let maxR = -1;\r\n    let maxC = -1;\r\n    for (let r = 0; r < this.rows; r++) {\r\n      for (let c = 0; c < this.cols; c++) {\r\n        if (this.data[r][c] > max) {\r\n          max = this.data[r][c];\r\n          maxR = r;\r\n          maxC = c;\r\n        }\r\n      }\r\n    }\r\n    return [max, maxR, maxC];\r\n  }\r\n}\r\n\r\nexport default Matrix;\r\n","import Matrix from \"../matrix\";\r\n\r\n/**\r\n * The sigmoid activation function and derivative.\r\n */\r\nexport class SigmoidActivation {\r\n  /**\r\n   * Returns the matrix mapped with sigmoid.\r\n   * @param {Matrix} z The matrix to apply the sigmoid function to\r\n   * @return {Matrix} The matrix mapped with sigmoid\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => 1 / (1 + Math.exp(-z_i)));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with sigmoid derivative.\r\n   * @param {Matrix} z The matrix to apply the sigmoid derivative function to\r\n   * @return {Matrix} The matrix mapped with sigmoid derivative\r\n   */\r\n  static derivative(z) {\r\n    const sigmoid = SigmoidActivation.fn(z);\r\n    return sigmoid.mul(Matrix.map(sigmoid, (a_i) => 1 - a_i));\r\n  }\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class ReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with ReLU.\r\n   * @param {Matrix} z The matrix to apply the ReLu function to\r\n   * @return {Matrix} The matrix mapped with ReLu\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => Math.max(0, z_i));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with ReLU derivative\r\n   */\r\n  static derivative(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0));\r\n  }\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class LeakyReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLu function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLu\r\n   */\r\n  static fn(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? z_i : 0.01 * z_i));\r\n  }\r\n\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLU derivative\r\n   */\r\n  static derivative(z) {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0.01));\r\n  }\r\n}\r\n\r\n/**\r\n * The softmax activation function and derivative.\r\n */\r\nexport class SoftmaxActivation {\r\n  /**\r\n   * Returns the matrix mapped with softmax.\r\n   * @param {Matrix} z The matrix to apply the softmax function to\r\n   * @return {Matrix} The matrix mapped with softmax\r\n   */\r\n  static fn(z) {\r\n    let sum = 0;\r\n    for (let r = 0; r < z.rows; r++) {\r\n      sum += Math.exp(z.data[r][0]);\r\n    }\r\n    return Matrix.map(z, (z_i) => Math.exp(z_i) / sum);\r\n  }\r\n\r\n  /**\r\n   * Returns the softmax derivative of the given number.\r\n   * @param {Matrix} z The matrix to apply the softmax derivative function to\r\n   * @return {Matrix} The matrix mapped with softmax derivative\r\n   */\r\n  static derivative(z) {\r\n    const softmax = SoftmaxActivation.fn(z);\r\n    return softmax.mul(Matrix.map(softmax, (a_i) => 1 - a_i));\r\n  }\r\n}\r\n\r\n/**\r\n * The quadratic loss function and output layer error.\r\n */\r\nexport class QuadraticLoss {\r\n  /**\r\n   * Returns the loss = sum over all (0.5 * (a - y)^2).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const diffMatrix = Matrix.sub(a, y);\r\n    let loss = 0;\r\n    for (let r = 0; r < diffMatrix.rows; r++) {\r\n      for (let c = 0; c < diffMatrix.cols; c++) {\r\n        loss += 0.5 * diffMatrix.data[r][c] ** 2;\r\n      }\r\n    }\r\n    return loss;\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = (a - y) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.sub(a, y);\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n\r\nconst EPSILON = 10 ** -100;\r\n\r\n/**\r\n * The binary cross entropy loss function and output layer error.\r\n */\r\nexport class BinaryCrossEntropyLoss {\r\n  /**\r\n   * Returns the loss = sum over all -(y * ln(a) + (1 - y) * ln(1 - a)).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const yIsOne = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    const yIsZero = Matrix.mul(\r\n      Matrix.transpose(Matrix.map(y, (y_i) => 1 - y_i)),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 1, not doing log(0)\r\n        return Math.log(1 - a_i + EPSILON);\r\n      })\r\n    );\r\n    return -(yIsOne.data[0][0] + yIsZero.data[0][0]);\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = [(a - y) / (a * (1 - a))] hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error matrix\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.sub(a, y).div(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return a_i * (1 - a_i) + EPSILON;\r\n      })\r\n    );\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n\r\n/**\r\n * The cross entropy loss function and output layer error.\r\n */\r\nexport class CrossEntropyLoss {\r\n  /**\r\n   * Returns the loss = sum over all -y * ln(a).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The loss\r\n   */\r\n  static fn(a, y) {\r\n    const loss = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    return -loss.data[0][0];\r\n  }\r\n\r\n  /**\r\n   * Returns the output error = (-y / a) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error matrix\r\n   */\r\n  static outputError(z, a, y, outputActivationFunction) {\r\n    const lossDerivativeWRTa = Matrix.map(y, (y_i) => -y_i).div(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return a_i + EPSILON;\r\n      })\r\n    );\r\n    return lossDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  }\r\n}\r\n","/**\r\n * Fisher-Yates shuffle.\r\n * @param {Array} arr The array to shuffle\r\n * @return {Array} The shuffled array\r\n */\r\nexport function shuffle(arr) {\r\n  for (let i = arr.length - 1; i > 0; i--) {\r\n    const randomIndex = Math.floor(Math.random() * (i + 1));\r\n    const temp = arr[i];\r\n    arr[i] = arr[randomIndex];\r\n    arr[randomIndex] = temp;\r\n  }\r\n  return arr;\r\n}\r\n","import Matrix from \"../matrix\";\r\nimport {\r\n  SigmoidActivation,\r\n  ReLUActivation,\r\n  LeakyReLUActivation,\r\n  SoftmaxActivation,\r\n  QuadraticLoss,\r\n  BinaryCrossEntropyLoss,\r\n  CrossEntropyLoss,\r\n} from \"./ffnn-helpers\";\r\nimport { shuffle } from \"../utils\";\r\n\r\nconst CHECK_GRADIENTS = false;\r\nconst LOG_MINI_BATCH_ACCURACY = false;\r\nconst LOG_MINI_BATCH_COST = false;\r\nconst OUTPUT_NETWORK = true;\r\n\r\nclass FFNN {\r\n  /**\r\n   * Creates a new FFNN with the givens layer sizes or loads a pretrained model.\r\n   * @param {Array} sizes An array of layer sizes\r\n   * @param {FFNN} ffnn Optional initial settings\r\n   */\r\n  constructor(sizes, ffnn) {\r\n    this.hiddenActivationFunction = ReLUActivation;\r\n    this.outputActivationFunction = SoftmaxActivation;\r\n    this.lossFunction = BinaryCrossEntropyLoss;\r\n\r\n    if (ffnn) {\r\n      // Deep copy\r\n      this.numLayers = ffnn.sizes.length;\r\n      this.sizes = [];\r\n      for (let size of ffnn.sizes) {\r\n        this.sizes.push(size);\r\n      }\r\n\r\n      // Copy bias vectors\r\n      this.biases = [];\r\n      for (let bias of ffnn.biases) {\r\n        this.biases.push(new Matrix(null, null, bias));\r\n      }\r\n\r\n      // Copy weight matrices\r\n      this.weights = [];\r\n      for (let weight of ffnn.weights) {\r\n        this.weights.push(new Matrix(null, null, weight));\r\n      }\r\n\r\n      // Save mean and std in case of standardization\r\n      if (ffnn.hasOwnProperty(\"trainMean\")) {\r\n        this.trainMean = new Matrix(null, null, ffnn.trainMean);\r\n        this.trainSTD = new Matrix(null, null, ffnn.trainSTD);\r\n      }\r\n    } else {\r\n      this.numLayers = sizes.length;\r\n      this.sizes = sizes;\r\n\r\n      // Create bias vectors\r\n      this.biases = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const bias = new Matrix(sizes[i], 1);\r\n\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          // He initialization, biases = 0\r\n          bias.map((b) => 0);\r\n        } else {\r\n          bias.randomizeNormal();\r\n        }\r\n\r\n        this.biases.push(bias);\r\n      }\r\n\r\n      // Create weight matrices\r\n      this.weights = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const weight = new Matrix(sizes[i], sizes[i - 1]);\r\n\r\n        // He initialization, weights random standard normal * sqrt(2 / # incoming connections)\r\n        weight.randomizeNormal();\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          weight.map((w) => w * Math.sqrt(2 / sizes[i - 1]));\r\n        }\r\n\r\n        this.weights.push(weight);\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Performs feedforward and returns the result as an array.\r\n   * @param {Matrix} input The input as a Matrix object (vector)\r\n   * @return {Array} The result as an array\r\n   */\r\n  predict(input) {\r\n    let output = input;\r\n\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wx + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, output);\r\n      z.add(bias);\r\n      output =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n    }\r\n\r\n    return output.toArray();\r\n  }\r\n\r\n  /**\r\n   * Performs stochastic gradient descent with the specified hyperparameters.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} miniBatchSize The size of the mini batches\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {Array} testDatas The optional test datas\r\n   */\r\n  stochasticGradientDescent(\r\n    trainDatas,\r\n    epochs,\r\n    miniBatchSize,\r\n    learningRate,\r\n    regularization,\r\n    testDatas = null\r\n  ) {\r\n    // Train datas = [trainData == [Matrix(input), Matrix(targetOutput)]]\r\n    const trainDataSize = trainDatas.length;\r\n\r\n    // Train for specified number of epochs\r\n    for (let i = 0; i < epochs; i++) {\r\n      // Shuffle the train datas every epoch\r\n      shuffle(trainDatas);\r\n\r\n      // Mini batches = [miniBatch == [trainData == [Matrix(input), Matrix(targetOutput)]]]\r\n      const miniBatches = [];\r\n      for (let j = 0; j < trainDataSize; j += miniBatchSize) {\r\n        // Mini batch = [trainData == [Matrix(input), Matrix(targetOutput)]]\r\n        const miniBatch = [];\r\n\r\n        // Train data = [Matrix(input), Matrix(targetOutput)]\r\n        for (let k = j; k < j + miniBatchSize; k++) {\r\n          miniBatch.push(trainDatas[k]);\r\n        }\r\n        miniBatches.push(miniBatch);\r\n      }\r\n\r\n      // Update each mini batch\r\n      for (let j = 0; j < miniBatches.length; j++) {\r\n        this.updateMiniBatch(\r\n          miniBatches[j],\r\n          learningRate,\r\n          regularization,\r\n          trainDataSize\r\n        );\r\n\r\n        // Accuracy on test set\r\n        if (LOG_MINI_BATCH_ACCURACY) {\r\n          const accuracy = this.accuracy(testDatas);\r\n          console.log(\r\n            \"Testing mini batch \" +\r\n              (j + 1) +\r\n              \"/\" +\r\n              miniBatches.length +\r\n              \": \" +\r\n              accuracy +\r\n              \"/\" +\r\n              testDatas.length +\r\n              \", \" +\r\n              (100 * accuracy) / testDatas.length +\r\n              \"%\"\r\n          );\r\n        } else {\r\n          // Only log this if not doing the more detailed accuracy logging\r\n          console.log(\r\n            \"Finished mini batch \" + (j + 1) + \"/\" + miniBatches.length\r\n          );\r\n        }\r\n\r\n        // Cost on train set\r\n        if (LOG_MINI_BATCH_COST) {\r\n          const trainCost = this.trainCost(trainDatas, regularization);\r\n          console.log(\r\n            \"Train cost: \" +\r\n              trainCost[0] +\r\n              \", \" +\r\n              trainCost[1] +\r\n              \"/\" +\r\n              trainDatas.length +\r\n              \", \" +\r\n              (100 * trainCost[1]) / trainDatas.length +\r\n              \"%\"\r\n          );\r\n        }\r\n      }\r\n\r\n      // Testing\r\n      if (testDatas !== null) {\r\n        const accuracy = this.accuracy(testDatas);\r\n        console.log(\r\n          \"Testing epoch \" +\r\n            (i + 1) +\r\n            \"/\" +\r\n            epochs +\r\n            \": \" +\r\n            accuracy +\r\n            \"/\" +\r\n            testDatas.length +\r\n            \", \" +\r\n            (100 * accuracy) / testDatas.length +\r\n            \"%\"\r\n        );\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Updates the mini batch by getting the gradient and then applying it.\r\n   * @param {Array} miniBatch The mini batch of train data\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {number} trainDataSize The size of the train data set\r\n   */\r\n  updateMiniBatch(miniBatch, learningRate, regularization, trainDataSize) {\r\n    // Cumulative gradients for mini batch\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Calculates the cumulative biases and weights gradients for all train data in the mini batch\r\n    for (let trainData of miniBatch) {\r\n      const input = trainData[0];\r\n      const targetOutput = trainData[1];\r\n      const gradientDelta = this.backprop(input, targetOutput);\r\n      const biasesGradientDelta = gradientDelta[0];\r\n      const weightsGradientDelta = gradientDelta[1];\r\n\r\n      // Do gradient checking\r\n      if (CHECK_GRADIENTS) {\r\n        const biasesCheck = this.gradientCheck(\r\n          biasesGradientDelta,\r\n          this.biases,\r\n          input,\r\n          targetOutput\r\n        );\r\n        console.log(\"Gradient check biases:\", biasesCheck);\r\n        const weightsCheck = this.gradientCheck(\r\n          weightsGradientDelta,\r\n          this.weights,\r\n          input,\r\n          targetOutput\r\n        );\r\n        console.log(\"Gradient check weights:\", weightsCheck);\r\n      }\r\n\r\n      // Add gradient delta to miniBatch\r\n      for (let i = 0; i < this.numLayers - 1; i++) {\r\n        biasesGradient[i].add(biasesGradientDelta[i]);\r\n        weightsGradient[i].add(weightsGradientDelta[i]);\r\n      }\r\n    }\r\n\r\n    // Apply the cumulative biases and weights gradients to the network's biases and weights\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const learningRateWithAvg = learningRate / miniBatch.length;\r\n\r\n      // Bias adjustment by gradient, no regularization\r\n      this.biases[i].sub(biasesGradient[i].mul(learningRateWithAvg));\r\n\r\n      // Weight regularization\r\n      this.weights[i].mul(1 - learningRate * (regularization / trainDataSize));\r\n\r\n      // Weight adjustment by gradient\r\n      this.weights[i].sub(weightsGradient[i].mul(learningRateWithAvg));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Performs backpropagation to calculate the gradient for one train data.\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} targetOutput The target output matrix\r\n   * @return {Array} The array consisting of the biasesGradient and weightsGradient for this one train data\r\n   */\r\n  backprop(input, targetOutput) {\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Feedforward, store zs and activations by layer\r\n    const zs = [];\r\n    const activations = [input];\r\n    this.forward(zs, activations);\r\n\r\n    // Output error = lossDerivativeWRTa hadamardProduct outputActivationFunctionDerivative(outputZ)\r\n    const outputError = this.lossFunction.outputError(\r\n      zs[zs.length - 1],\r\n      activations[activations.length - 1],\r\n      targetOutput,\r\n      this.outputActivationFunction\r\n    );\r\n\r\n    // Output biasesGradient is simply the output error\r\n    biasesGradient[biasesGradient.length - 1] = outputError;\r\n\r\n    // Output weightsGradient = outputError * beforeOutputActivationTranspose\r\n    weightsGradient[weightsGradient.length - 1] = Matrix.mul(\r\n      outputError,\r\n      Matrix.transpose(activations[activations.length - 2])\r\n    );\r\n\r\n    // Backpropagate error to hidden layers\r\n    let hiddenError = outputError;\r\n    for (let i = 2; i < this.numLayers; i++) {\r\n      // Hidden error = (nextWeightsTranspose * nextError which is last pass's hidden error) hadamardProduct hiddenActivationFunctionDerivative(z)\r\n      const nextWeightsTranspose = Matrix.transpose(\r\n        this.weights[this.weights.length - i + 1]\r\n      );\r\n      const hiddenActivationFunctionDerivative = this.hiddenActivationFunction.derivative(\r\n        zs[zs.length - i]\r\n      );\r\n      hiddenError = Matrix.mul(nextWeightsTranspose, hiddenError).mul(\r\n        hiddenActivationFunctionDerivative\r\n      );\r\n\r\n      // Hidden biasesGradient is simply the hidden error\r\n      biasesGradient[biasesGradient.length - i] = hiddenError;\r\n\r\n      // Hidden weightsGradient = hiddenError * beforeHiddenActivationsTranspose\r\n      weightsGradient[weightsGradient.length - i] = Matrix.mul(\r\n        hiddenError,\r\n        Matrix.transpose(activations[activations.length - i - 1])\r\n      );\r\n    }\r\n\r\n    return [biasesGradient, weightsGradient];\r\n  }\r\n\r\n  /**\r\n   * Feedforward, but also keeping record of the z's and activations per layer.\r\n   * @param {Array} zs The array to store the z records\r\n   * @param {Array} activations The array to store the activation records\r\n   */\r\n  forward(zs, activations) {\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wa + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, activations[i]);\r\n      z.add(bias);\r\n      zs.push(z);\r\n\r\n      const a =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n      activations.push(a);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Creates an empty gradient with the target array's shape.\r\n   * @param {Array} arr The target array\r\n   * @return {Array} The empty gradient array with in the shape of the target array\r\n   */\r\n  createEmptyGradient(arr) {\r\n    const gradient = [];\r\n    for (let targetMatrix of arr) {\r\n      const gradientMatrix = new Matrix(targetMatrix.rows, targetMatrix.cols);\r\n      gradient.push(gradientMatrix);\r\n    }\r\n    return gradient;\r\n  }\r\n\r\n  /**\r\n   * Returns a count of how many test cases were passed.\r\n   * @param {Array} testDatas The array of test datas\r\n   * @return {number} The number of test cases passed\r\n   */\r\n  accuracy(testDatas) {\r\n    let count = 0;\r\n\r\n    for (let testData of testDatas) {\r\n      const input = testData[0];\r\n      const outputArr = this.predict(input);\r\n      const targetOutputArr = testData[1].toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const targetOutputInteger = targetOutputArr.indexOf(\r\n        Math.max(...targetOutputArr)\r\n      );\r\n\r\n      // Count number correct\r\n      if (outputInteger === targetOutputInteger) {\r\n        count++;\r\n      }\r\n    }\r\n\r\n    return count;\r\n  }\r\n\r\n  /**\r\n   * Returns the train cost and correct count for the data set using the regularization parameter.\r\n   * @param {Array} datas The array of data to get the train cost for\r\n   * @param {number} regularization The regularization parameter\r\n   * @return {Array} The train cost and correct count\r\n   */\r\n  trainCost(datas, regularization) {\r\n    let cost = 0;\r\n    let count = 0;\r\n\r\n    // Add loss of each data point\r\n    for (let data of datas) {\r\n      const input = data[0];\r\n      const targetOutput = data[1];\r\n\r\n      const outputArr = this.predict(input);\r\n      const targetOutputArr = targetOutput.toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const targetOutputInteger = targetOutputArr.indexOf(\r\n        Math.max(...targetOutputArr)\r\n      );\r\n\r\n      // Count correct\r\n      if (outputInteger === targetOutputInteger) {\r\n        count++;\r\n      }\r\n\r\n      // Output cost\r\n      cost +=\r\n        this.lossFunction.fn(Matrix.vectorFromArray(outputArr), targetOutput) /\r\n        datas.length;\r\n\r\n      // Regularization cost\r\n      let squaredWeights = 0;\r\n      for (let weight of this.weights) {\r\n        for (let r = 0; r < weight.rows; r++) {\r\n          for (let c = 0; c < weight.cols; c++) {\r\n            squaredWeights += weight.data[r][c] ** 2;\r\n          }\r\n        }\r\n      }\r\n      cost += 0.5 * (regularization / datas.length) * squaredWeights;\r\n    }\r\n\r\n    return [cost, count];\r\n  }\r\n\r\n  /**\r\n   * Performs gradient checking technique, manually calculating the gradient using the limit definition the derivative and a small epsilon.\r\n   * @param {Array} gradient The gradient to check\r\n   * @param {Array} weightOrBias A reference to the neural network's biases or weights\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} targetOutput The targed output matrix\r\n   * @return {number} The euclidean norm ratio which should be less than 10^-7\r\n   */\r\n  gradientCheck(gradient, weightOrBias, input, targetOutput) {\r\n    const targetOutputArr = targetOutput.toArray();\r\n    const epsilon = 10 ** -7;\r\n    const gradApprox = this.createEmptyGradient(gradient);\r\n\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          // Save the original bias or weight value to restore it at the end\r\n          const original = weightOrBias[i].data[r][c];\r\n\r\n          // Calculate the loss with plus epsilon\r\n          weightOrBias[i].data[r][c] = original + epsilon;\r\n          const outputPlus = this.predict(input);\r\n          let lossPlus = 0;\r\n          for (let j = 0; j < outputPlus.length; j++) {\r\n            lossPlus += 0.5 * (targetOutputArr[j] - outputPlus[j]) ** 2;\r\n          }\r\n\r\n          // Calculate the loss with minus epsilon\r\n          weightOrBias[i].data[r][c] = original - epsilon;\r\n          const outputMinus = this.predict(input);\r\n          let lossMinus = 0;\r\n          for (let j = 0; j < outputMinus.length; j++) {\r\n            lossMinus += 0.5 * (targetOutputArr[j] - outputMinus[j]) ** 2;\r\n          }\r\n\r\n          // Limit definition of derivative\r\n          const gradApproxVal = (lossPlus - lossMinus) / (2 * epsilon);\r\n          gradApprox[i].data[r][c] = gradApproxVal;\r\n\r\n          // Restore the initial bias or weight value\r\n          weightOrBias[i].data[r][c] = original;\r\n        }\r\n      }\r\n    }\r\n\r\n    let paramSum = 0;\r\n    let paramApproxSum = 0;\r\n    let errorSum = 0;\r\n\r\n    // Sum all Euclidean components\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          const gradientVal = gradient[i].data[r][c];\r\n          const gradApproxVal = gradApprox[i].data[r][c];\r\n\r\n          paramSum += gradientVal ** 2;\r\n          paramApproxSum += gradApproxVal ** 2;\r\n          errorSum += (gradApproxVal - gradientVal) ** 2;\r\n        }\r\n      }\r\n    }\r\n\r\n    return (\r\n      Math.sqrt(errorSum) / (Math.sqrt(paramApproxSum) + Math.sqrt(paramSum))\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Automation for choosing the regularization parameter.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {Array} valDatas The array of validation datas\r\n   * @param {Array} testDatas The array of test datas\r\n   */\r\n  static chooseHypeparameters(trainDatas, valDatas, testDatas) {\r\n    const miniBatchOptions = [1, 10, 20, 50, 100];\r\n    const learningRateOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    const regularizationOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    let bestMiniBatch = 1;\r\n    let bestLearningRate = 0.01;\r\n    let bestRegularization = 0.01;\r\n    let bestAccuracy = 0;\r\n    let bestNetwork = null;\r\n\r\n    // Train a different model for each combination of options\r\n    for (let i = 0; i < miniBatchOptions.length; i++) {\r\n      for (let j = 0; j < learningRateOptions.length; j++) {\r\n        for (let k = 0; k < regularizationOptions.length; k++) {\r\n          const curMiniBatch = miniBatchOptions[i];\r\n          const curLearningRate = learningRateOptions[j];\r\n          const curRegularization = regularizationOptions[k];\r\n\r\n          // Train the network using the current settings\r\n          const curNetwork = new FFNN([784, 30, 10]);\r\n          curNetwork.stochasticGradientDescent(\r\n            trainDatas,\r\n            1,\r\n            curMiniBatch,\r\n            curLearningRate,\r\n            curRegularization\r\n          );\r\n\r\n          // Evaluate accuracy using validation set\r\n          const valAccuracy = curNetwork.accuracy(valDatas);\r\n\r\n          // Choose best neural network based on validation set\r\n          if (valAccuracy > bestAccuracy) {\r\n            bestMiniBatch = curMiniBatch;\r\n            bestLearningRate = curLearningRate;\r\n            bestRegularization = curRegularization;\r\n            bestAccuracy = valAccuracy;\r\n            bestNetwork = curNetwork;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    console.log(\"Best mini batch size: \" + bestMiniBatch);\r\n    console.log(\"Best learning rate: \" + bestLearningRate);\r\n    console.log(\"Best regularization: \" + bestRegularization);\r\n    console.log(\r\n      \"Best validation set: \" +\r\n        bestAccuracy +\r\n        \"/\" +\r\n        valDatas.length +\r\n        \", \" +\r\n        (100 * bestAccuracy) / valDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Test the generalization of the selected network on the test set\r\n    const generalizationAccuracy = bestNetwork.accuracy(testDatas);\r\n    console.log(\r\n      \"Best test set: \" +\r\n        generalizationAccuracy +\r\n        \"/\" +\r\n        testDatas.length +\r\n        \", \" +\r\n        (100 * generalizationAccuracy) / testDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Log the best neural network\r\n    console.log(\"Best network:\", JSON.stringify(bestNetwork));\r\n  }\r\n}\r\n\r\nexport default FFNN;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass Conv {\r\n  /**\r\n   * Create a Conv layer with the given settings or loads a pretrained one.\r\n   * @param {number} numFilters The number of filters\r\n   * @param {number} filterSize The filter size, square only\r\n   * @param {Conv} conv The pretrained Conv\r\n   */\r\n  constructor(numFilters, filterSize = 3, conv = null) {\r\n    if (conv !== null) {\r\n      this.numFilters = conv.numFilters;\r\n      this.filterSize = conv.filterSize;\r\n      this.filters = [];\r\n\r\n      for (let filter of conv.filters) {\r\n        this.filters.push(new Matrix(null, null, filter));\r\n      }\r\n    } else {\r\n      this.numFilters = numFilters;\r\n      this.filterSize = filterSize;\r\n      this.filters = [];\r\n\r\n      for (let i = 0; i < numFilters; i++) {\r\n        this.filters.push(\r\n          new Matrix(filterSize, filterSize)\r\n            .randomizeNormal()\r\n            .div(filterSize ** 2)\r\n        );\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generator method for iterating over the image.\r\n   * @param {Matrix} image The image to iterate over\r\n   * @return {Array} The image region as a 2D Matrix and the coordinates of the region\r\n   */\r\n  *iterateRegions(image) {\r\n    const h = image.rows;\r\n    const w = image.cols;\r\n    const f = this.filterSize;\r\n\r\n    for (let y = 0; y < h - f + 1; y++) {\r\n      for (let x = 0; x < w - f + 1; x++) {\r\n        yield [image.getRegion(x, y, f, f), y, x];\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward implementation assuming a very simple CNN architecture (single channel).\r\n   * @param {Matrix} input The input image\r\n   * @return {Array} An array of images processed by the filters\r\n   */\r\n  forward(input) {\r\n    this.lastInput = input;\r\n\r\n    const h = input.rows;\r\n    const w = input.cols;\r\n    const f = this.filterSize;\r\n\r\n    const outputs = [];\r\n\r\n    // For each filter\r\n    for (let filter of this.filters) {\r\n      const output = new Matrix(h - f + 1, w - f + 1);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(input)) {\r\n        // Apply the filter to the region\r\n        for (let r = 0; r < f; r++) {\r\n          for (let c = 0; c < f; c++) {\r\n            output.data[y][x] += region.data[r][c] * filter.data[r][c];\r\n          }\r\n        }\r\n      }\r\n\r\n      outputs.push(output);\r\n    }\r\n\r\n    return outputs;\r\n  }\r\n\r\n  /**\r\n   * Backpropagation assuming only a single channel.\r\n   * @param {Array} dLdOut Array of loss gradients w.r.t. the conv layer's outputs\r\n   * @param {number} learningRate The learning rate\r\n   */\r\n  backprop(dLdOut, learningRate) {\r\n    const dLdFilters = [];\r\n\r\n    // For each filter\r\n    for (let i = 0; i < this.filters.length; i++) {\r\n      const filter = this.filters[i];\r\n      const dLdFilter = new Matrix(filter.rows, filter.cols);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(this.lastInput)) {\r\n        // Accumulate filter gradient\r\n        dLdFilter.add(region.mul(dLdOut[i].data[y][x]));\r\n      }\r\n      dLdFilters.push(dLdFilter);\r\n    }\r\n\r\n    // Update filters\r\n    for (let i = 0; i < this.filters.length; i++) {\r\n      const filter = this.filters[i];\r\n      const dLdFilter = dLdFilters[i];\r\n\r\n      filter.sub(dLdFilter.mul(learningRate));\r\n    }\r\n  }\r\n}\r\n\r\nexport default Conv;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass MaxPool {\r\n  /**\r\n   * Creates a max pool with the given size or loads the pool size from the given pool.\r\n   * @param {number} poolSize The pool size, square only, stride same as size\r\n   * @param {MaxPool} pool The preset pool, only containing size information\r\n   */\r\n  constructor(poolSize = 2, pool = null) {\r\n    if (pool !== null) {\r\n      this.poolSize = pool.poolSize;\r\n    } else {\r\n      this.poolSize = poolSize;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generator method for iterating over the image.\r\n   * @param {Matrix} image The image to iterate over\r\n   * @return {Array} The image region as a 2D Matrix and the coordinates of the region\r\n   */\r\n  *iterateRegions(image) {\r\n    const h = image.rows;\r\n    const w = image.cols;\r\n    const s = this.poolSize;\r\n\r\n    const newH = Math.floor(h / s);\r\n    const newW = Math.floor(w / s);\r\n\r\n    for (let y = 0; y < newH; y++) {\r\n      for (let x = 0; x < newW; x++) {\r\n        yield [image.getRegion(x * s, y * s, s, s), y, x];\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on the max pool.\r\n   * @param {Array} input The array of input images passed through a conv layer\r\n   * @return {Array} An array of images processed by the max pool\r\n   */\r\n  forward(input) {\r\n    this.lastInput = input;\r\n\r\n    const h = input[0].rows;\r\n    const w = input[0].cols;\r\n    const s = this.poolSize;\r\n\r\n    const newH = Math.floor(h / s);\r\n    const newW = Math.floor(w / s);\r\n\r\n    const outputs = [];\r\n\r\n    // For each channel\r\n    for (let channel of input) {\r\n      const output = new Matrix(newH, newW);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(channel)) {\r\n        // Apply the pool to the region\r\n        const [max, _, __] = region.max();\r\n        output.data[y][x] = max;\r\n      }\r\n\r\n      outputs.push(output);\r\n    }\r\n\r\n    return outputs;\r\n  }\r\n\r\n  /**\r\n   * Backpropagation on the max pool.\r\n   * @param {Array} dLdOut Array of loss gradients w.r.t. the pool layer's outputs\r\n   * @return {Array} Array of loss gradients w.r.t. the pool layer's inputs\r\n   */\r\n  backprop(dLdOut) {\r\n    const dLdInputs = [];\r\n\r\n    // For each channel\r\n    for (let i = 0; i < this.lastInput.length; i++) {\r\n      const channel = this.lastInput[i];\r\n      const dLdInput = new Matrix(channel.rows, channel.cols);\r\n\r\n      // For each region\r\n      for (let [region, y, x] of this.iterateRegions(channel)) {\r\n        // Apply the pool to the region\r\n        const [max, _, __] = region.max();\r\n\r\n        // Find all pixels matching the max value and replace with corresponding dLdOut\r\n        for (let r = 0; r < region.rows; r++) {\r\n          for (let c = 0; c < region.cols; c++) {\r\n            if (region.data[r][c] === max) {\r\n              dLdInput.data[y * this.poolSize + r][x * this.poolSize + c] =\r\n                dLdOut[i].data[y][x];\r\n            }\r\n          }\r\n        }\r\n      }\r\n\r\n      dLdInputs.push(dLdInput);\r\n    }\r\n\r\n    return dLdInputs;\r\n  }\r\n}\r\n\r\nexport default MaxPool;\r\n","import Matrix from \"../matrix\";\r\n\r\nclass Softmax {\r\n  /**\r\n   * Creates a new softmax layer or loads the pretrained layer.\r\n   * @param {number} inputLen The input layer size\r\n   * @param {number} nodes The output layer size\r\n   * @param {Softmax} softmax The pretrained softmax layer\r\n   */\r\n  constructor(inputLen, nodes, softmax = null) {\r\n    if (softmax !== null) {\r\n      this.weights = new Matrix(null, null, softmax.weights);\r\n      this.biases = new Matrix(null, null, softmax.biases);\r\n    } else {\r\n      this.weights = new Matrix(inputLen, nodes)\r\n        .randomizeNormal()\r\n        .div(inputLen);\r\n      this.biases = new Matrix(1, nodes);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on the softmax layer.\r\n   * @param {Array} input The array of input images passed through a max pool layer\r\n   * @return {Matrix} A row vector of final output probabilities\r\n   */\r\n  forward(input) {\r\n    this.lastInputShape = [input.length, input[0].rows, input[0].cols];\r\n\r\n    // Flattened row vector\r\n    const flattened = new Matrix(\r\n      1,\r\n      input[0].rows * input[0].cols * input.length\r\n    );\r\n    let flattenedCol = 0;\r\n\r\n    // Flatten\r\n    for (let channel of input) {\r\n      for (let r = 0; r < channel.rows; r++) {\r\n        for (let c = 0; c < channel.cols; c++) {\r\n          flattened.data[0][flattenedCol] = channel.data[r][c];\r\n          flattenedCol++;\r\n        }\r\n      }\r\n    }\r\n    this.lastInput = flattened;\r\n\r\n    // Product sum and bias\r\n    const z = Matrix.mul(flattened, this.weights).add(this.biases);\r\n    this.lastZ = z;\r\n\r\n    // Softmax function\r\n    const exp = Matrix.map(z, Math.exp);\r\n    let sum = 0;\r\n    for (let c = 0; c < exp.cols; c++) {\r\n      sum += exp.data[0][c];\r\n    }\r\n    return exp.div(sum);\r\n  }\r\n\r\n  /**\r\n   * Backpropagation on the softmax layer.\r\n   * @param {Matrix} dLdOut Row vector of loss gradients w.r.t. the softmax layer's outputs\r\n   * @param {number} learningRate The learning rate\r\n   * @return {Array} Array of loss gradients w.r.t. the softmax layer's inputs\r\n   */\r\n  backprop(dLdOut, learningRate) {\r\n    // Find correct label index\r\n    let correctI = 0;\r\n    for (let i = 0; i < dLdOut.cols; i++) {\r\n      if (dLdOut.data[0][i] !== 0) {\r\n        correctI = i;\r\n        break;\r\n      }\r\n    }\r\n    const gradient = dLdOut.data[0][correctI];\r\n\r\n    // e^z\r\n    const zExp = Matrix.map(this.lastZ, Math.exp);\r\n    const zExpCorrect = zExp.data[0][correctI];\r\n\r\n    // Sum of all e^z\r\n    let S = 0;\r\n    for (let c = 0; c < zExp.cols; c++) {\r\n      S += zExp.data[0][c];\r\n    }\r\n\r\n    /* Gradients of output w.r.t z\r\n          = -zExpCorrect * zExp / (S ** 2), for wrong label\r\n          = zExpCorrect * (S - zExpCorrect) / (S ** 2), for correct label\r\n      */\r\n    const dOutdZ = zExp.mul(-zExpCorrect / S ** 2);\r\n    dOutdZ.data[0][correctI] = (zExpCorrect * (S - zExpCorrect)) / S ** 2;\r\n\r\n    // Gradients of z w.r.t. weights/biases/input, dZdB = 1, so can ignore\r\n    const dZdW = this.lastInput;\r\n    const dZdInputs = this.weights;\r\n\r\n    // Gradients of loss w.r.t. z\r\n    const dLdZ = dOutdZ.mul(gradient);\r\n\r\n    // Gradients of loss w.r.t. weights/biases/input\r\n    const dLdW = Matrix.mul(Matrix.transpose(dZdW), dLdZ);\r\n    const dLdB = dLdZ;\r\n    const dLdInputs = Matrix.mul(dLdZ, Matrix.transpose(dZdInputs));\r\n\r\n    // Update weights and biases\r\n    this.weights.sub(dLdW.mul(learningRate));\r\n    this.biases.sub(dLdB.mul(learningRate));\r\n\r\n    // Reshape to original input shape\r\n    const channels = this.lastInputShape[0];\r\n    const rows = this.lastInputShape[1];\r\n    const cols = this.lastInputShape[2];\r\n    let index = 0;\r\n    const dLdInputsReshaped = [];\r\n\r\n    for (let i = 0; i < channels; i++) {\r\n      const dLdInputChannel = new Matrix(rows, cols);\r\n\r\n      for (let r = 0; r < rows; r++) {\r\n        for (let c = 0; c < cols; c++) {\r\n          dLdInputChannel.data[r][c] = dLdInputs.data[0][index];\r\n          index++;\r\n        }\r\n      }\r\n\r\n      dLdInputsReshaped.push(dLdInputChannel);\r\n    }\r\n\r\n    return dLdInputsReshaped;\r\n  }\r\n}\r\n\r\nexport default Softmax;\r\n","import Matrix from \"../matrix\";\r\nimport Conv from \"./conv\";\r\nimport MaxPool from \"./maxpool\";\r\nimport Softmax from \"./softmax\";\r\nimport { shuffle } from \"../utils\";\r\n\r\nconst OUTPUT_NETWORK = true;\r\n\r\nclass CNN {\r\n  /**\r\n   * Creates a new simple CNN or loads a pretrained model.\r\n   * @param {CNN} cnn The pretrained CNN model\r\n   */\r\n  constructor(cnn = null) {\r\n    if (cnn !== null) {\r\n      this.conv = new Conv(null, null, cnn.conv);\r\n      this.pool = new MaxPool(null, cnn.pool);\r\n      this.softmax = new Softmax(null, null, cnn.softmax);\r\n    } else {\r\n      this.conv = new Conv(8); // 28x28x1 -> 26x26x8\r\n      this.pool = new MaxPool(); // 26x26x8 -> 13x13x8\r\n      this.softmax = new Softmax(13 * 13 * 8, 10); // 13x13x8 -> 10\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Passes the image through the CNN.\r\n   * @param {Matrix} image The image as a 2D matrix\r\n   * @return {Array} The result as an array of probabilities\r\n   */\r\n  predict(image) {\r\n    // Out is a row vector of probabilities\r\n    let out = this.conv.forward(image); // 28x28x1 -> 26x26x8\r\n    out = this.pool.forward(out); // 26x26x8 -> 13x13x8\r\n    out = this.softmax.forward(out); // 13x13x8 -> 10\r\n    return out.toArray();\r\n  }\r\n\r\n  /**\r\n   * Trains the CNN.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} learningRate The learning rate\r\n   * @param {Array} testDatas The optional array of test datas\r\n   */\r\n  train(trainDatas, epochs, learningRate, testDatas = null) {\r\n    for (let epoch = 0; epoch < epochs; epoch++) {\r\n      shuffle(trainDatas);\r\n\r\n      let loss = 0;\r\n      let numCorrect = 0;\r\n\r\n      for (let i = 0; i < trainDatas.length; i++) {\r\n        const trainData = trainDatas[i];\r\n        const image = trainData[0];\r\n        const label = trainData[1];\r\n\r\n        // Label is a column vector\r\n        const [_, labelNum, __] = label.max();\r\n\r\n        // Forward, out is a row vector\r\n        const [out, l, acc] = this.forward(image, label);\r\n\r\n        // Save loss and number correct for printing\r\n        loss += l;\r\n        numCorrect += acc;\r\n\r\n        // Initial gradient = dL/dOut = d(-ln(Out))/dOut = -1/Out\r\n        let gradient = new Matrix(1, 10);\r\n        gradient.data[0][labelNum] = -1 / out.data[0][labelNum];\r\n\r\n        // Backprop\r\n        gradient = this.softmax.backprop(gradient, learningRate);\r\n        gradient = this.pool.backprop(gradient);\r\n        this.conv.backprop(gradient, learningRate);\r\n\r\n        if (i % 100 === 99) {\r\n          console.log(\r\n            \"Training: \" +\r\n              (i + 1) +\r\n              \"/\" +\r\n              trainDatas.length +\r\n              \" | Average Loss: \" +\r\n              loss / 100 +\r\n              \" | Accuracy: \" +\r\n              numCorrect +\r\n              \"/100\"\r\n          );\r\n          loss = 0;\r\n          numCorrect = 0;\r\n        }\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n\r\n    if (testDatas !== null) {\r\n      this.test(testDatas);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Feedforward on one image-label pair.\r\n   * @param {Matrix} image The image to feedforward\r\n   * @param {Matrix} label The correct label as a one-hot column vector\r\n   * @return {Array} The output probabilities as a 1x10 Matrix, the loss, and whether the CNN predicted correctly\r\n   */\r\n  forward(image, label) {\r\n    // Out is a row vector of probabilities\r\n    let out = this.conv.forward(image); // 28x28x1 -> 26x26x8\r\n    out = this.pool.forward(out); // 26x26x8 -> 13x13x8\r\n    out = this.softmax.forward(out); // 13x13x8 -> 10\r\n\r\n    // Label is a column vector\r\n    const [_, labelNum, __] = label.max();\r\n    const [___, ____, outMax] = out.max();\r\n\r\n    // Calculate cross entropy loss and accuracy\r\n    const loss = -Math.log(out.data[0][labelNum]);\r\n    const acc = outMax === labelNum ? 1 : 0;\r\n\r\n    return [out, loss, acc];\r\n  }\r\n\r\n  /**\r\n   * Prints the average test loss and accuracy of the CNN on the test set.\r\n   * @param {Array} testDatas The array of test datas\r\n   */\r\n  test(testDatas) {\r\n    let loss = 0;\r\n    let numCorrect = 0;\r\n\r\n    // Calculate loss and number correct for all test samples\r\n    for (let testData of testDatas) {\r\n      const image = testData[0];\r\n      const label = testData[1];\r\n\r\n      const [_, l, acc] = this.forward(image, label);\r\n      loss += l;\r\n      numCorrect += acc;\r\n    }\r\n\r\n    // Print the loss and accuracy\r\n    const numTests = testDatas.length;\r\n    console.log(\"Test loss:\", loss / numTests);\r\n    console.log(\r\n      \"Test accuracy: \" +\r\n        numCorrect +\r\n        \"/\" +\r\n        numTests +\r\n        \", \" +\r\n        (100 * numCorrect) / numTests +\r\n        \"%\"\r\n    );\r\n  }\r\n}\r\n\r\nexport default CNN;\r\n","import React, { Component } from \"react\";\r\nimport Button from \"./components/button\";\r\nimport Canvas from \"./components/canvas\";\r\nimport GithubCorner from \"react-github-corner\";\r\nimport loadMNIST from \"./logic/mnist\";\r\nimport mnistSamples from \"./data/mnist-samples.json\";\r\nimport ffnnModel from \"./data/ffnn-model.json\";\r\nimport cnnModel from \"./data/cnn-model.json\";\r\nimport Matrix from \"./logic/matrix\";\r\nimport FFNN from \"./logic/ffnn/ffnn\";\r\nimport CNN from \"./logic/cnn/cnn\";\r\n\r\nconst TRAIN_FFNN = false;\r\nconst TRAIN_CNN = false;\r\nconst NEW_FFNN = false;\r\nconst NEW_CNN = false;\r\nconst USE_STANDARDIZATION = false;\r\n\r\nconst LOAD_TRAIN = false;\r\nconst LOAD_VAL = false;\r\nconst LOAD_TEST = false;\r\n\r\nconst OUTPUT_FFNN_ACCURACY = false;\r\nconst OUTPUT_CNN_ACCURACY = false;\r\nconst OUTPUT_MNIST = false;\r\n\r\nconst NUM_TRAIN = 50000;\r\nconst NUM_VAL = 10000;\r\nconst NUM_TEST = 10000;\r\nconst EPSILON = 10 ** -100;\r\n\r\nconst NUM_MNIST_SAMPLES = 5;\r\n\r\nclass App extends Component {\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      ffnnOutputArr: [],\r\n      cnnOutputArr: [],\r\n      ffnnPred: \"\",\r\n      cnnPred: \"\",\r\n    };\r\n\r\n    // For training\r\n    if (TRAIN_FFNN || TRAIN_CNN) {\r\n      // Do everything after loading\r\n      loadMNIST((data) => {\r\n        this.mnist = data;\r\n        console.log(\"All files loaded\");\r\n\r\n        if (OUTPUT_MNIST) {\r\n          console.log(this.mnist);\r\n        }\r\n\r\n        // Format and normalize data\r\n        this.formatData();\r\n        this.normalizeData();\r\n        if (USE_STANDARDIZATION) {\r\n          this.standardizeData();\r\n        }\r\n\r\n        // FFNN\r\n        if (TRAIN_FFNN) {\r\n          console.log(\"Starting FFNN training\");\r\n\r\n          // Create new or load model\r\n          if (NEW_FFNN) {\r\n            this.ffnn = new FFNN([784, 30, 10]);\r\n          } else {\r\n            this.ffnn = new FFNN(null, ffnnModel);\r\n\r\n            if (OUTPUT_FFNN_ACCURACY) {\r\n              const accuracy = this.ffnn.accuracy(this.ffnnTestDatas);\r\n              console.log(\r\n                \"Accuracy: \" +\r\n                  accuracy +\r\n                  \"/\" +\r\n                  this.ffnnTestDatas.length +\r\n                  \", \" +\r\n                  (100 * accuracy) / this.ffnnTestDatas.length +\r\n                  \"%\"\r\n              );\r\n            }\r\n          }\r\n\r\n          // Remember to use much smaller learning rate when using ReLU\r\n          this.ffnn.stochasticGradientDescent(\r\n            this.ffnnTrainDatas,\r\n            1,\r\n            10,\r\n            0.03,\r\n            1.0,\r\n            this.ffnnTestDatas\r\n          );\r\n        }\r\n\r\n        // CNN\r\n        if (TRAIN_CNN) {\r\n          console.log(\"Starting CNN training\");\r\n\r\n          // Create new or load model\r\n          if (NEW_CNN) {\r\n            this.cnn = new CNN();\r\n          } else {\r\n            this.cnn = new CNN(cnnModel);\r\n\r\n            if (OUTPUT_CNN_ACCURACY) {\r\n              this.cnn.test(this.cnnTestDatas);\r\n            }\r\n          }\r\n\r\n          this.cnn.train(this.cnnTrainDatas, 1, 0.005, this.cnnTestDatas);\r\n        }\r\n      });\r\n    } else {\r\n      // No training, load both models\r\n      this.ffnn = new FFNN(null, ffnnModel);\r\n      this.cnn = new CNN(cnnModel);\r\n    }\r\n\r\n    this.canvasRef = React.createRef();\r\n  }\r\n\r\n  componentDidMount() {\r\n    // this.saveSamples();\r\n    this.showSamples();\r\n  }\r\n\r\n  /**\r\n   * Outputs JSON of MNIST samples.\r\n   */\r\n  saveSamples() {\r\n    const samples = [];\r\n\r\n    // For each digit\r\n    for (let i = 0; i < 10; i++) {\r\n      const sampleImages = [];\r\n\r\n      // Find digit samples from test set\r\n      for (let j = 0; j < this.mnist.testImages.length; j++) {\r\n        if (this.mnist.testLabels[j] === i) {\r\n          sampleImages.push(Array.from(this.mnist.testImages[j]));\r\n\r\n          // Found desired number of samples\r\n          if (sampleImages.length === NUM_MNIST_SAMPLES) {\r\n            break;\r\n          }\r\n        }\r\n      }\r\n\r\n      samples.push(sampleImages);\r\n    }\r\n\r\n    console.log(JSON.stringify(samples));\r\n  }\r\n\r\n  /**\r\n   * Shows MNISt samples.\r\n   */\r\n  showSamples() {\r\n    // For each digit\r\n    for (let i = 0; i < 10; i++) {\r\n      // For the desired number of samples\r\n      for (let j = 0; j < NUM_MNIST_SAMPLES; j++) {\r\n        // Retrieve canvas and context\r\n        const canvas = document.getElementById(`canvas-${i}-${j}`);\r\n        const ctx = canvas.getContext(\"2d\");\r\n\r\n        for (let y = 0; y < 28; y++) {\r\n          for (let x = 0; x < 28; x++) {\r\n            // Create single pixel block and retrieve saved pixel\r\n            const block = ctx.createImageData(1, 1);\r\n            const newVal = 255 * mnistSamples[i][j][y * 28 + x];\r\n\r\n            // Assign loaded pixel value\r\n            block.data[0] = newVal;\r\n            block.data[1] = newVal;\r\n            block.data[2] = newVal;\r\n            block.data[3] = 255;\r\n\r\n            // Draw to canvas\r\n            ctx.putImageData(block, x, y);\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Formats data to suitable format to pass to FFNN and CNN.\r\n   */\r\n  formatData() {\r\n    if (LOAD_TRAIN) {\r\n      console.log(\"Formatting train data\");\r\n      if (TRAIN_FFNN) {\r\n        this.ffnnTrainDatas = this.loadDatas(\r\n          this.mnist.trainImages.slice(0, NUM_TRAIN),\r\n          this.mnist.trainLabels.slice(0, NUM_TRAIN),\r\n          true\r\n        );\r\n      }\r\n      if (TRAIN_CNN) {\r\n        this.cnnTrainDatas = this.loadDatas(\r\n          this.mnist.trainImages.slice(0, NUM_TRAIN),\r\n          this.mnist.trainLabels.slice(0, NUM_TRAIN),\r\n          false\r\n        );\r\n      }\r\n    }\r\n\r\n    if (LOAD_VAL) {\r\n      console.log(\"Formatting validation data\");\r\n      if (TRAIN_FFNN) {\r\n        this.ffnnValDatas = this.loadDatas(\r\n          this.mnist.trainImages.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\r\n          this.mnist.trainLabels.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\r\n          true\r\n        );\r\n      }\r\n      if (TRAIN_CNN) {\r\n        this.cnnValDatas = this.loadDatas(\r\n          this.mnist.trainImages.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\r\n          this.mnist.trainLabels.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\r\n          false\r\n        );\r\n      }\r\n    }\r\n\r\n    if (LOAD_TEST) {\r\n      console.log(\"Formatting test data\");\r\n      if (TRAIN_FFNN) {\r\n        this.ffnnTestDatas = this.loadDatas(\r\n          this.mnist.testImages.slice(0, NUM_TEST),\r\n          this.mnist.testLabels.slice(0, NUM_TEST),\r\n          true\r\n        );\r\n      }\r\n      if (TRAIN_CNN) {\r\n        this.cnnTestDatas = this.loadDatas(\r\n          this.mnist.testImages.slice(0, NUM_TEST),\r\n          this.mnist.testLabels.slice(0, NUM_TEST),\r\n          false\r\n        );\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Loads data into image-label pairs.\r\n   * @param {Array} images Array of images\r\n   * @param {Array} labels Array of labels\r\n   * @param {boolean} isFFNN Whether to load the data for FFNN or CNN\r\n   * @return {Array} Array of image-label pairs\r\n   */\r\n  loadDatas(images, labels, isFFNN) {\r\n    const datas = [];\r\n\r\n    for (let i = 0; i < images.length; i++) {\r\n      const inputArr = images[i];\r\n      const targetInt = labels[i];\r\n      const targetArr = [];\r\n\r\n      for (let j = 0; j < 10; j++) {\r\n        if (targetInt === j) {\r\n          targetArr.push(1);\r\n        } else {\r\n          targetArr.push(0);\r\n        }\r\n      }\r\n\r\n      datas.push([\r\n        isFFNN\r\n          ? Matrix.vectorFromArray(inputArr)\r\n          : Matrix.matrixFromArray(inputArr, 28, 28),\r\n        Matrix.vectorFromArray(targetArr),\r\n      ]);\r\n    }\r\n\r\n    return datas;\r\n  }\r\n\r\n  /**\r\n   * Normalizes all data.\r\n   */\r\n  normalizeData() {\r\n    // Normalize train images\r\n    if (LOAD_TRAIN) {\r\n      console.log(\"Normalizing train data\");\r\n      if (TRAIN_FFNN) {\r\n        for (let trainData of this.ffnnTrainDatas) {\r\n          trainData[0].div(255);\r\n        }\r\n      }\r\n      if (TRAIN_CNN) {\r\n        for (let trainData of this.cnnTrainDatas) {\r\n          trainData[0].div(255);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Normalize validation images\r\n    if (LOAD_VAL) {\r\n      console.log(\"Normalizing validation data\");\r\n      if (TRAIN_FFNN) {\r\n        for (let valData of this.ffnnValDatas) {\r\n          valData[0].div(255);\r\n        }\r\n      }\r\n      if (TRAIN_CNN) {\r\n        for (let valData of this.cnnValDatas) {\r\n          valData[0].div(255);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Normalize test images\r\n    if (LOAD_TEST) {\r\n      console.log(\"Normalizing test data\");\r\n      if (TRAIN_FFNN) {\r\n        for (let testData of this.ffnnTestDatas) {\r\n          testData[0].div(255);\r\n        }\r\n      }\r\n      if (TRAIN_CNN) {\r\n        for (let testData of this.cnnTestDatas) {\r\n          testData[0].div(255);\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Standardizes all data.\r\n   */\r\n  standardizeData() {\r\n    // Neural network does NOT have predefined train mean and STD, calculate them and use that to standardize everything\r\n    if (!this.ffnn.hasOwnProperty(\"trainMean\")) {\r\n      const mean = new Matrix(784, 1); // mean = sum(pixels) / numTrain\r\n      const std = new Matrix(784, 1); // std = sqrt(sum((pixels - mean)^2) / numTrain)\r\n\r\n      // Calculate sum(pixels)\r\n      console.log(\"Calculating train data mean\");\r\n      for (let trainData of this.ffnnTrainDatas) {\r\n        mean.add(trainData[0]);\r\n      }\r\n\r\n      // Divide by total number of train datas\r\n      mean.map((x) => x / this.ffnnTrainDatas.length);\r\n\r\n      // Calculate sum((pixels - mean)^2)\r\n      console.log(\"Calculating train data standard deviation\");\r\n      for (let trainData of this.ffnnTrainDatas) {\r\n        std.add(Matrix.sub(trainData[0], mean).map((x) => x ** 2));\r\n      }\r\n\r\n      // Divide by total number of train datas and square root\r\n      std.map((x) => Math.sqrt(x / this.ffnnTrainDatas.length));\r\n\r\n      // Save to neural network\r\n      this.ffnn.trainMean = mean;\r\n      this.ffnn.trainSTD = std;\r\n    }\r\n\r\n    // Retrieve mean and std from neural network\r\n    const mean = this.ffnn.trainMean;\r\n    const std = this.ffnn.trainSTD;\r\n\r\n    // Standardize train images, add small epsilon so never divide by zero\r\n    if (LOAD_TRAIN) {\r\n      console.log(\"Standardizing train data\");\r\n      for (let i = 0; i < this.ffnnTrainDatas.length; i++) {\r\n        this.ffnnTrainDatas[i][0]\r\n          .sub(mean)\r\n          .div(Matrix.map(std, (x) => x + EPSILON));\r\n      }\r\n    }\r\n\r\n    // Standardize validation images, add small epsilon so never divide by zero\r\n    if (LOAD_VAL) {\r\n      console.log(\"Standardizing validation data\");\r\n      for (let i = 0; i < this.ffnnValDatas.length; i++) {\r\n        this.ffnnValDatas[i][0]\r\n          .sub(mean)\r\n          .div(Matrix.map(std, (x) => x + EPSILON));\r\n      }\r\n    }\r\n\r\n    // Standardize test images, add small epsilon so never divide by zero\r\n    if (LOAD_TEST) {\r\n      console.log(\"Standardizing test data\");\r\n      for (let i = 0; i < this.ffnnTestDatas.length; i++) {\r\n        this.ffnnTestDatas[i][0]\r\n          .sub(mean)\r\n          .div(Matrix.map(std, (x) => x + EPSILON));\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Makes predictions on the canvas input using FFNN and CNN and sets component state.\r\n   */\r\n  handlePredict = () => {\r\n    if (this.ffnn !== undefined && this.cnn !== undefined) {\r\n      const inputArr = this.canvasRef.current.predict();\r\n      const ffnnInput = Matrix.vectorFromArray(inputArr);\r\n      const cnnInput = Matrix.matrixFromArray(inputArr, 28, 28);\r\n\r\n      if (USE_STANDARDIZATION) {\r\n        ffnnInput\r\n          .sub(this.ffnn.trainMean)\r\n          .div(Matrix.map(this.ffnn.trainSTD, (x) => x + EPSILON));\r\n      }\r\n\r\n      const ffnnOutputArr = this.ffnn.predict(ffnnInput);\r\n      const ffnnPred = ffnnOutputArr.indexOf(Math.max(...ffnnOutputArr));\r\n\r\n      const cnnOutputArr = this.cnn.predict(cnnInput);\r\n      const cnnPred = cnnOutputArr.indexOf(Math.max(...cnnOutputArr));\r\n\r\n      // Update state about prediction and displayed probabilities\r\n      this.setState({\r\n        ffnnOutputArr,\r\n        cnnOutputArr,\r\n        ffnnPred,\r\n        cnnPred,\r\n      });\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Clears the canvas and resets component state.\r\n   */\r\n  handleClear = () => {\r\n    this.canvasRef.current.erase();\r\n\r\n    this.setState({\r\n      ffnnOutputArr: [],\r\n      cnnOutputArr: [],\r\n      ffnnPred: \"\",\r\n      cnnPred: \"\",\r\n    });\r\n  };\r\n\r\n  render() {\r\n    const sampleImages = [];\r\n    for (let i = 0; i < 10; i++) {\r\n      const cols = [];\r\n\r\n      for (let j = 0; j < NUM_MNIST_SAMPLES; j++) {\r\n        const col = (\r\n          <div className=\"col-auto\" key={`col-${i}-${j}`}>\r\n            <canvas\r\n              id={`canvas-${i}-${j}`}\r\n              width=\"28\"\r\n              height=\"28\"\r\n              style={{\r\n                border: \"2px solid aquamarine\",\r\n                borderRadius: \"5px\",\r\n                backgroundColor: \"white\",\r\n              }}\r\n            ></canvas>\r\n          </div>\r\n        );\r\n        cols.push(col);\r\n      }\r\n\r\n      const row = (\r\n        <div className=\"row justify-content-center\" key={`row-${i}`}>\r\n          {cols}\r\n        </div>\r\n      );\r\n      sampleImages.push(row);\r\n    }\r\n\r\n    const ffnnProbs = [];\r\n    for (let i = 0; i < 10; i++) {\r\n      const prob = (\r\n        <div className=\"row\" key={\"fnn\" + i}>\r\n          <div className=\"col text-right\">\r\n            <h5>{i}:</h5>\r\n          </div>\r\n          <div className=\"col text-left\">\r\n            <h5>\r\n              {this.state.ffnnOutputArr.length > 0\r\n                ? (this.state.ffnnOutputArr[i] * 100).toFixed(1) + \"%\"\r\n                : \"\"}\r\n            </h5>\r\n          </div>\r\n        </div>\r\n      );\r\n      ffnnProbs.push(prob);\r\n    }\r\n    const cnnProbs = [];\r\n    for (let i = 0; i < 10; i++) {\r\n      const prob = (\r\n        <div className=\"row\" key={\"cnn\" + i}>\r\n          <div className=\"col text-right\">\r\n            <h5>{i}:</h5>\r\n          </div>\r\n          <div className=\"col text-left\">\r\n            <h5>\r\n              {this.state.cnnOutputArr.length > 0\r\n                ? (this.state.cnnOutputArr[i] * 100).toFixed(1) + \"%\"\r\n                : \"\"}\r\n            </h5>\r\n          </div>\r\n        </div>\r\n      );\r\n      cnnProbs.push(prob);\r\n    }\r\n\r\n    return (\r\n      <div className=\"App container text-center py-5\">\r\n        <div className=\"row\">\r\n          <div className=\"col\">\r\n            <h1 className=\"font-weight-bold\">Digit Recognizer</h1>\r\n            <h5>\r\n              Recognizes user-drawn digits using self-implemented feedforward\r\n              (FFNN) and convolutional (CNN) neural networks.\r\n              <br />\r\n              Draw a number from 0 to 9 and see if the networks can predict your\r\n              number!\r\n            </h5>\r\n            <h3 className=\"pt-3\">MNIST Samples:</h3>\r\n            {sampleImages}\r\n            <div className=\"row justify-content-center pt-4\">\r\n              <div className=\"col-4 col-md-3 col-xl-2\">\r\n                <Button value=\"Predict\" onClick={this.handlePredict} />\r\n              </div>\r\n              <div className=\"col-4 col-md-3 col-xl-2\">\r\n                <Button value=\"Clear\" onClick={this.handleClear} />\r\n              </div>\r\n            </div>\r\n            <div className=\"pt-4\">\r\n              <Canvas ref={this.canvasRef} />\r\n            </div>\r\n            <canvas\r\n              id=\"canvas28\"\r\n              width=\"28\"\r\n              height=\"28\"\r\n              style={{\r\n                border: \"2px solid aquamarine\",\r\n                borderRadius: \"5px\",\r\n                backgroundColor: \"white\",\r\n              }}\r\n            ></canvas>\r\n            <div className=\"row justify-content-center\">\r\n              <div className=\"col-6 col-md-4 col-lg-3\">\r\n                <div className=\"row\">\r\n                  <div className=\"col text-right\">\r\n                    <h4 className=\"font-weight-bold\">FFNN:</h4>\r\n                  </div>\r\n                  <div className=\"col text-left\">\r\n                    <h4 className=\"font-weight-bold\">{this.state.ffnnPred}</h4>\r\n                  </div>\r\n                </div>\r\n                {ffnnProbs}\r\n              </div>\r\n              <div className=\"col-6 col-md-4 col-lg-3\">\r\n                <div className=\"row font-weight-bold\">\r\n                  <div className=\"col text-right\">\r\n                    <h4 className=\"font-weight-bold\">CNN:</h4>\r\n                  </div>\r\n                  <div className=\"col text-left\">\r\n                    <h4 className=\"font-weight-bold\">{this.state.cnnPred}</h4>\r\n                  </div>\r\n                </div>\r\n                {cnnProbs}\r\n              </div>\r\n            </div>\r\n          </div>\r\n        </div>\r\n        <GithubCorner\r\n          href=\"https://github.com/ryantran2165/digit-recognizer\"\r\n          bannerColor=\"#222\"\r\n          octoColor=\"#7fffd4\"\r\n          target=\"_blank\"\r\n        />\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nexport default App;\r\n","// This optional code is used to register a service worker.\r\n// register() is not called by default.\r\n\r\n// This lets the app load faster on subsequent visits in production, and gives\r\n// it offline capabilities. However, it also means that developers (and users)\r\n// will only see deployed updates on subsequent visits to a page, after all the\r\n// existing tabs open on the page have been closed, since previously cached\r\n// resources are updated in the background.\r\n\r\n// To learn more about the benefits of this model and instructions on how to\r\n// opt-in, read https://bit.ly/CRA-PWA\r\n\r\nconst isLocalhost = Boolean(\r\n  window.location.hostname === 'localhost' ||\r\n    // [::1] is the IPv6 localhost address.\r\n    window.location.hostname === '[::1]' ||\r\n    // 127.0.0.0/8 are considered localhost for IPv4.\r\n    window.location.hostname.match(\r\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\r\n    )\r\n);\r\n\r\nexport function register(config) {\r\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\r\n    // The URL constructor is available in all browsers that support SW.\r\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\r\n    if (publicUrl.origin !== window.location.origin) {\r\n      // Our service worker won't work if PUBLIC_URL is on a different origin\r\n      // from what our page is served on. This might happen if a CDN is used to\r\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\r\n      return;\r\n    }\r\n\r\n    window.addEventListener('load', () => {\r\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\r\n\r\n      if (isLocalhost) {\r\n        // This is running on localhost. Let's check if a service worker still exists or not.\r\n        checkValidServiceWorker(swUrl, config);\r\n\r\n        // Add some additional logging to localhost, pointing developers to the\r\n        // service worker/PWA documentation.\r\n        navigator.serviceWorker.ready.then(() => {\r\n          console.log(\r\n            'This web app is being served cache-first by a service ' +\r\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\r\n          );\r\n        });\r\n      } else {\r\n        // Is not localhost. Just register service worker\r\n        registerValidSW(swUrl, config);\r\n      }\r\n    });\r\n  }\r\n}\r\n\r\nfunction registerValidSW(swUrl, config) {\r\n  navigator.serviceWorker\r\n    .register(swUrl)\r\n    .then(registration => {\r\n      registration.onupdatefound = () => {\r\n        const installingWorker = registration.installing;\r\n        if (installingWorker == null) {\r\n          return;\r\n        }\r\n        installingWorker.onstatechange = () => {\r\n          if (installingWorker.state === 'installed') {\r\n            if (navigator.serviceWorker.controller) {\r\n              // At this point, the updated precached content has been fetched,\r\n              // but the previous service worker will still serve the older\r\n              // content until all client tabs are closed.\r\n              console.log(\r\n                'New content is available and will be used when all ' +\r\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\r\n              );\r\n\r\n              // Execute callback\r\n              if (config && config.onUpdate) {\r\n                config.onUpdate(registration);\r\n              }\r\n            } else {\r\n              // At this point, everything has been precached.\r\n              // It's the perfect time to display a\r\n              // \"Content is cached for offline use.\" message.\r\n              console.log('Content is cached for offline use.');\r\n\r\n              // Execute callback\r\n              if (config && config.onSuccess) {\r\n                config.onSuccess(registration);\r\n              }\r\n            }\r\n          }\r\n        };\r\n      };\r\n    })\r\n    .catch(error => {\r\n      console.error('Error during service worker registration:', error);\r\n    });\r\n}\r\n\r\nfunction checkValidServiceWorker(swUrl, config) {\r\n  // Check if the service worker can be found. If it can't reload the page.\r\n  fetch(swUrl, {\r\n    headers: { 'Service-Worker': 'script' }\r\n  })\r\n    .then(response => {\r\n      // Ensure service worker exists, and that we really are getting a JS file.\r\n      const contentType = response.headers.get('content-type');\r\n      if (\r\n        response.status === 404 ||\r\n        (contentType != null && contentType.indexOf('javascript') === -1)\r\n      ) {\r\n        // No service worker found. Probably a different app. Reload the page.\r\n        navigator.serviceWorker.ready.then(registration => {\r\n          registration.unregister().then(() => {\r\n            window.location.reload();\r\n          });\r\n        });\r\n      } else {\r\n        // Service worker found. Proceed as normal.\r\n        registerValidSW(swUrl, config);\r\n      }\r\n    })\r\n    .catch(() => {\r\n      console.log(\r\n        'No internet connection found. App is running in offline mode.'\r\n      );\r\n    });\r\n}\r\n\r\nexport function unregister() {\r\n  if ('serviceWorker' in navigator) {\r\n    navigator.serviceWorker.ready.then(registration => {\r\n      registration.unregister();\r\n    });\r\n  }\r\n}\r\n","import React from \"react\";\r\nimport ReactDOM from \"react-dom\";\r\nimport App from \"./App\";\r\nimport * as serviceWorker from \"./serviceWorker\";\r\nimport \"bootstrap/dist/css/bootstrap.css\";\r\nimport \"./index.scss\";\r\n\r\nReactDOM.render(<App />, document.getElementById(\"root\"));\r\n\r\n// If you want your app to work offline and load faster, you can change\r\n// unregister() to register() below. Note this comes with some pitfalls.\r\n// Learn more about service workers: https://bit.ly/CRA-PWA\r\nserviceWorker.unregister();\r\n"],"sourceRoot":""}