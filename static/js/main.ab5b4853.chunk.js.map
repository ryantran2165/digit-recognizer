{"version":3,"sources":["components/title.js","components/description.js","components/button.js","logic/matrix.js","logic/helpers.js","logic/ffnn.js","logic/mnist.js","components/canvas.js","App.js","serviceWorker.js","index.js"],"names":["Title","text","Description","split","map","index","Fragment","key","defaultProps","Button","value","onClick","className","type","e","target","blur","Matrix","rows","cols","matrix","add","console","log","x","i","j","data","sub","mul","div","toArray","arr","push","copy","_","func","randomize","Math","random","randomizeNormal","u","v","sqrt","cos","PI","print","table","this","Array","fill","matrix1","matrix2","sum","k","transpose","vectorFromArray","length","SigmoidActivation","fn","z","z_i","exp","derivative","sigmoid","a_i","ReLUActivation","max","LeakyReLUActivation","SoftmaxActivation","r","softmax","QuadraticCost","a","y","diffMatrix","cost","c","outputError","outputActivationFunction","EPSILON","CrossEntropyCost","yIsOne","yIsZero","y_i","shuffle","randomIndex","floor","temp","FFNN","sizes","ffnn","feedforward","input","output","numLayers","bias","biases","weight","weights","hiddenActivationFunction","stochasticGradientDescent","trainDatas","epochs","miniBatchSize","learningRate","regularization","testDatas","trainDataSize","miniBatches","miniBatch","updateMiniBatch","accuracy","JSON","stringify","biasesGradient","createEmptyGradient","weightsGradient","trainData","desiredOutput","gradientDelta","backpropagate","biasesGradientDelta","weightsGradientDelta","learningRateWithAvg","zs","activations","trainingFeedforward","hiddenError","nextWeightsTranspose","hiddenActivationFunctionDerivative","gradient","targetMatrix","gradientMatrix","count","testData","outputArr","desiredOutputArr","indexOf","trainCost","datas","squaredWeights","gradientCheck","desiredArr","epsilon","pow","gradApprox","original","outputPlus","costPlus","outputMinus","costMinus","gradApproxVal","paramSum","paramApproxSum","errorSum","gradientVal","size","hasOwnProperty","trainMean","trainSTD","b","w","chooseHypeparameters","valDatas","miniBatchOptions","learningRateOptions","regularizationOptions","bestMiniBatch","bestLearningRate","bestRegularization","bestAccuracy","bestNetwork","curMiniBatch","curLearningRate","curRegularization","curNetwork","valAccuracy","generalizationAccuracy","loadFile","file","fetch","response","arrayBuffer","buffer","headerCount","headerView","DataView","headers","getUint32","dataLength","Error","Uint8Array","dataArr","subarray","loadMNIST","callback","mnist","files","trainImages","trainLabels","testImages","testLabels","Promise","all","Object","keys","then","Canvas","findxy","res","currX","clientX","canvas","getBoundingClientRect","left","currY","clientY","top","ctx","beginPath","lineWidth","arc","LINE_WIDTH","stroke","closePath","paths","paintFlag","prevX","prevY","currPath","draw","x1","y1","x2","y2","strokeStyle","lineCap","lineJoin","moveTo","lineTo","erase","clearRect","width","height","ctx28","canvas28","imageDataToGrayscale","imgData","grayscaleImg","offset","getBoundingRect","img","threshold","columns","minX","minY","maxX","maxY","centerImage","meanX","meanY","sumPixels","pixel","transX","round","transY","predict","getImageData","boundingRect","trans","canvasCopy","document","createElement","copyCtx","getContext","brW","brH","scaling","translate","scale","p","nnInput","mean","h","block","newVal","putImageData","getElementById","addEventListener","id","toString","style","border","borderRadius","backgroundColor","Component","App","props","showSamples","labelArr","createImageData","formatData","loadDatas","slice","images","labels","inputArr","desiredInteger","standardizeData","std","normalizeData","handlePredict","undefined","canvasRef","current","ffnnOutputArr","ffnnPred","setState","handleClear","cnnOutputArr","cnnPred","state","ffnnModel","React","createRef","col","row","ffnnProbs","prob","toFixed","cnnProbs","ref","href","bannerColor","octoColor","Boolean","window","location","hostname","match","ReactDOM","render","navigator","serviceWorker","ready","registration","unregister"],"mappings":"+9peAWeA,EARD,SAAC,GAAc,IAAZC,EAAW,EAAXA,KACf,OAAO,4BAAKA,ICDRC,EAAc,SAAC,GAAc,IAAZD,EAAW,EAAXA,KASrB,OAAO,4BAAmBA,EAPjBE,MAAM,MAAMC,KAAI,SAACH,EAAMI,GAAP,OACrB,kBAAC,IAAMC,SAAP,CAAgBC,IAAG,UAAKN,EAAL,YAAaI,IAC7BJ,EACD,mCAORC,EAAYM,aAAe,CACzBP,KAAM,uBAOOC,QCEAO,EAtBA,SAAC,GAAwB,IAAtBC,EAAqB,EAArBA,MAAOC,EAAc,EAAdA,QAMvB,OACE,4BACEC,UAAU,yBACVC,KAAK,SACLF,QATkB,SAACG,GACrBA,EAAEC,OAAOC,OACTL,MASGD,ICfDO,EACJ,WAAYC,EAAMC,EAAMC,GAAS,IAAD,OAC9B,GAD8B,yBAqBhCC,IAAM,SAACD,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,sCAGP,EAAKnB,KAAI,SAACoB,EAAGC,EAAGC,GAAP,OAAaF,EAAIJ,EAAOO,KAAKF,GAAGC,MAE3C,EAAKtB,KAAI,SAACoB,GAAD,OAAOA,EAAIJ,MA7BG,KA0ChCQ,IAAM,SAACR,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKnB,KAAI,SAACoB,EAAGC,EAAGC,GAAP,OAAaF,EAAIJ,EAAOO,KAAKF,GAAGC,MAE3C,EAAKtB,KAAI,SAACoB,GAAD,OAAOA,EAAIJ,MAlDG,KA+DhCS,IAAM,SAACT,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKnB,KAAI,SAACoB,EAAGC,EAAGC,GAAP,OAAaF,EAAIJ,EAAOO,KAAKF,GAAGC,MAE3C,EAAKtB,KAAI,SAACoB,GAAD,OAAOA,EAAIJ,MAvEG,KA0FhCU,IAAM,SAACV,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKnB,KAAI,SAACoB,EAAGC,EAAGC,GAAP,OAAaF,EAAIJ,EAAOO,KAAKF,GAAGC,MAE3C,EAAKtB,KAAI,SAACoB,GAAD,OAAOA,EAAIJ,MAlGG,KA+GhCW,QAAU,WAER,IADA,IAAMC,EAAM,GACHP,EAAI,EAAGA,EAAI,EAAKP,KAAMO,IAC7B,IAAK,IAAIC,EAAI,EAAGA,EAAI,EAAKP,KAAMO,IAC7BM,EAAIC,KAAK,EAAKN,KAAKF,GAAGC,IAG1B,OAAOM,GAtHuB,KAyHhCE,KAAO,WACL,OAAO,IAAIjB,EAAO,EAAKC,KAAM,EAAKC,MAAMf,KAAI,SAAC+B,EAAGV,EAAGC,GAAP,OAAa,EAAKC,KAAKF,GAAGC,OA1HxC,KA6HhCtB,IAAM,SAACgC,GACL,IAAK,IAAIX,EAAI,EAAGA,EAAI,EAAKP,KAAMO,IAC7B,IAAK,IAAIC,EAAI,EAAGA,EAAI,EAAKP,KAAMO,IAC7B,EAAKC,KAAKF,GAAGC,GAAKU,EAAK,EAAKT,KAAKF,GAAGC,GAAID,EAAGC,GAG/C,OAAO,GAnIuB,KA4IhCW,UAAY,WACV,OAAO,EAAKjC,KAAI,kBAAsB,EAAhBkC,KAAKC,SAAe,MA7IZ,KAiJhCC,gBAAkB,WAChB,OAAO,EAAKpC,KAAI,WAGd,IAFA,IAAIqC,EAAI,EACJC,EAAI,EACK,IAAND,GAASA,EAAIH,KAAKC,SACzB,KAAa,IAANG,GAASA,EAAIJ,KAAKC,SACzB,OAAOD,KAAKK,MAAM,EAAML,KAAKf,IAAIkB,IAAMH,KAAKM,IAAI,EAAMN,KAAKO,GAAKH,OAvJpC,KA2JhCI,MAAQ,WAEN,OADAxB,QAAQyB,MAAM,EAAKpB,MACZ,GA5JHP,EAAQ,CAEV4B,KAAK9B,KAAOE,EAAOF,KACnB8B,KAAK7B,KAAOC,EAAOD,KACnB6B,KAAKrB,KAAO,GACZ,IAAK,IAAIF,EAAI,EAAGA,EAAIuB,KAAK9B,KAAMO,IAAK,CAClCuB,KAAKrB,KAAKM,KAAK,IACf,IAAK,IAAIP,EAAI,EAAGA,EAAIsB,KAAK7B,KAAMO,IAC7BsB,KAAKrB,KAAKF,GAAGQ,KAAKb,EAAOO,KAAKF,GAAGC,UAIrCsB,KAAK9B,KAAOA,EACZ8B,KAAK7B,KAAOA,EACZ6B,KAAKrB,KAAOsB,MAAM/B,GACfgC,OACA9C,KAAI,kBAAM6C,MAAM9B,GAAM+B,KAAK,OAlB9BjC,EAiCGI,IAAM,SAAC8B,EAASC,GACrB,GAAID,EAAQjC,OAASkC,EAAQlC,MAAQiC,EAAQhC,OAASiC,EAAQjC,KAI9D,OAAO,IAAIF,EAAOkC,EAAQjC,KAAMiC,EAAQhC,MAAMf,KAC5C,SAAC+B,EAAGV,EAAGC,GAAP,OAAayB,EAAQxB,KAAKF,GAAGC,GAAK0B,EAAQzB,KAAKF,GAAGC,MAJlDJ,QAAQC,IAAI,uCAnCZN,EAsDGW,IAAM,SAACuB,EAASC,GACrB,GAAID,EAAQjC,OAASkC,EAAQlC,MAAQiC,EAAQhC,OAASiC,EAAQjC,KAI9D,OAAO,IAAIF,EAAOkC,EAAQjC,KAAMiC,EAAQhC,MAAMf,KAC5C,SAAC+B,EAAGV,EAAGC,GAAP,OAAayB,EAAQxB,KAAKF,GAAGC,GAAK0B,EAAQzB,KAAKF,GAAGC,MAJlDJ,QAAQC,IAAI,4CAxDZN,EA2EGY,IAAM,SAACsB,EAASC,GACrB,GAAID,EAAQhC,OAASiC,EAAQlC,KAM7B,OAAO,IAAID,EAAOkC,EAAQjC,KAAMkC,EAAQjC,MAAMf,KAAI,SAAC+B,EAAGV,EAAGC,GAEvD,IADA,IAAI2B,EAAM,EACDC,EAAI,EAAGA,EAAIH,EAAQhC,KAAMmC,IAChCD,GAAOF,EAAQxB,KAAKF,GAAG6B,GAAKF,EAAQzB,KAAK2B,GAAG5B,GAE9C,OAAO2B,KAVP/B,QAAQC,IACN,qEA9EFN,EAsGGsC,UAAY,SAACnC,GAClB,OAAO,IAAIH,EAAOG,EAAOD,KAAMC,EAAOF,MAAMd,KAC1C,SAAC+B,EAAGV,EAAGC,GAAP,OAAaN,EAAOO,KAAKD,GAAGD,OAxG5BR,EA4GGuC,gBAAkB,SAACxB,GACxB,OAAO,IAAIf,EAAOe,EAAIyB,OAAQ,GAAGrD,KAAI,SAAC+B,EAAGV,GAAJ,OAAUO,EAAIP,OA7GjDR,EAuIGb,IAAM,SAACgB,EAAQgB,GACpB,OAAO,IAAInB,EAAOG,EAAOF,KAAME,EAAOD,MAAMf,KAAI,SAAC+B,EAAGV,EAAGC,GAAP,OAC9CU,EAAKhB,EAAOO,KAAKF,GAAGC,GAAID,EAAGC,OAyBlBT,QC7JFyC,EAAb,kCAAaA,EAMJC,GAAK,SAACC,GACX,OAAO3C,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAAS,GAAK,EAAIvB,KAAKwB,KAAKD,QAPxCH,EAeJK,WAAa,SAACH,GACnB,IAAMI,EAAUN,EAAkBC,GAAGC,GACrC,OAAOI,EAAQnC,IAAIZ,EAAOb,IAAI4D,GAAS,SAACC,GAAD,OAAS,EAAIA,OAOjD,IAAMC,EAAb,kCAAaA,EAMJP,GAAK,SAACC,GACX,OAAO3C,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAASvB,KAAK6B,IAAI,EAAGN,OAPjCK,EAeJH,WAAa,SAACH,GACnB,OAAO3C,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,MAO1C,IAAMO,EAAb,kCAAaA,EAMJT,GAAK,SAACC,GACX,OAAO3C,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAIA,EAAM,IAAOA,MAP7CO,EAeJL,WAAa,SAACH,GACnB,OAAO3C,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,QAO1C,IAAMQ,EAAb,kCAAaA,EAMJV,GAAK,SAACC,GAEX,IADA,IAAIP,EAAM,EACDiB,EAAI,EAAGA,EAAIV,EAAE1C,KAAMoD,IAC1BjB,GAAOf,KAAKwB,IAAIF,EAAEjC,KAAK2C,GAAG,IAE5B,OAAOrD,EAAOb,IAAIwD,GAAG,SAACC,GAAD,OAASvB,KAAKwB,IAAID,GAAOR,MAXrCgB,EAmBJN,WAAa,SAACH,GACnB,IAAMW,EAAUF,EAAkBV,GAAGC,GACrC,OAAOW,EAAQ1C,IAAIZ,EAAOb,IAAImE,GAAS,SAACN,GAAD,OAAS,EAAIA,OAOjD,IAAMO,EAAb,kCAAaA,EAOJb,GAAK,SAACc,EAAGC,GAGd,IAFA,IAAMC,EAAa1D,EAAOW,IAAI6C,EAAGC,GAC7BE,EAAO,EACFN,EAAI,EAAGA,EAAIK,EAAWzD,KAAMoD,IACnC,IAAK,IAAIO,EAAI,EAAGA,EAAIF,EAAWxD,KAAM0D,IACnCD,GAAQ,YAAMD,EAAWhD,KAAK2C,GAAGO,GAAM,GAG3C,OAAOD,GAfEJ,EA0BJM,YAAc,SAAClB,EAAGa,EAAGC,EAAGK,GAE7B,OAD2B9D,EAAOW,IAAI6C,EAAGC,GACf7C,IAAIkD,EAAyBhB,WAAWH,KAItE,IAAMoB,EAAO,SAAG,IAAO,KAKVC,EAAb,kCAAaA,EAOJtB,GAAK,SAACc,EAAGC,GACd,IAAMQ,EAASjE,EAAOY,IACpBZ,EAAOsC,UAAUmB,GACjBzD,EAAOb,IAAIqE,GAAG,SAACR,GAEb,OAAO3B,KAAKf,IAAI0C,EAAMe,OAGpBG,EAAUlE,EAAOY,IACrBZ,EAAOsC,UAAUtC,EAAOb,IAAIsE,GAAG,SAACU,GAAD,OAAS,EAAIA,MAC5CnE,EAAOb,IAAIqE,GAAG,SAACR,GAEb,OAAO3B,KAAKf,IAAI,EAAI0C,EAAMe,OAG9B,QAASE,EAAOvD,KAAK,GAAG,GAAKwD,EAAQxD,KAAK,GAAG,KAtBpCsD,EAiCJH,YAAc,SAAClB,EAAGa,EAAGC,EAAGK,GAO7B,OAN2B9D,EAAOW,IAAI6C,EAAGC,GAAG7C,IAC1CZ,EAAOb,IAAIqE,GAAG,SAACR,GAEb,OAAO,GAAKA,GAAO,EAAIA,GAAOe,OAGRnD,IAAIkD,EAAyBhB,WAAWH,KAS/D,IAAMyB,EAAU,SAACrD,GACtB,IAAK,IAAIP,EAAIO,EAAIyB,OAAS,EAAGhC,EAAI,EAAGA,IAAK,CACvC,IAAM6D,EAAchD,KAAKiD,MAAMjD,KAAKC,UAAYd,EAAI,IAC9C+D,EAAOxD,EAAIP,GACjBO,EAAIP,GAAKO,EAAIsD,GACbtD,EAAIsD,GAAeE,EAErB,OAAOxD,GCpLHyD,EAMJ,WAAYC,EAAOC,GAAO,IAAD,OAKvB,GALuB,yBAsEzBC,YAAc,SAACC,GAGb,IAFA,IAAIC,EAASD,EAEJpE,EAAI,EAAGA,EAAI,EAAKsE,UAAY,EAAGtE,IAAK,CAC3C,IAAMuE,EAAO,EAAKC,OAAOxE,GACnByE,EAAS,EAAKC,QAAQ1E,GAGtBmC,EAAI3C,EAAOY,IAAIqE,EAAQJ,GAC7BlC,EAAEvC,IAAI2E,GACNF,EACErE,IAAM,EAAKsE,UAAY,EACnB,EAAKhB,yBAAyBpB,GAAGC,GACjC,EAAKwC,yBAAyBzC,GAAGC,GAGzC,OAAOkC,EAAO/D,WAtFS,KAkGzBsE,0BAA4B,SAC1BC,EACAC,EACAC,EACAC,EACAC,GAOA,IALI,IADJC,EACG,uDADS,KAGNC,EAAgBN,EAAW7C,OAGxBhC,EAAI,EAAGA,EAAI8E,EAAQ9E,IAAK,CAE/B4D,EAAQiB,GAIR,IADA,IAAMO,EAAc,GACXnF,EAAI,EAAGA,EAAIkF,EAAelF,GAAK8E,EAAe,CAKrD,IAHA,IAAMM,EAAY,GAGTxD,EAAI5B,EAAG4B,EAAI5B,EAAI8E,EAAelD,IACrCwD,EAAU7E,KAAKqE,EAAWhD,IAE5BuD,EAAY5E,KAAK6E,GAInB,IAAK,IAAIpF,EAAI,EAAGA,EAAImF,EAAYpD,OAAQ/B,IAAK,CAC3C,EAAKqF,gBACHF,EAAYnF,GACZ+E,EACAC,EACAE,GAqBAtF,QAAQC,IACN,wBAA0BG,EAAI,GAAK,IAAMmF,EAAYpD,QAsB3D,GAAkB,OAAdkD,EAAoB,CACtB,IAAMK,EAAW,EAAKA,SAASL,GAC/BrF,QAAQC,IACN,kBACGE,EAAI,GACL,IACA8E,EACA,KACAS,EACA,IACAL,EAAUlD,OACV,KACC,IAAMuD,EAAYL,EAAUlD,OAC7B,KAKJnC,QAAQC,IAAI0F,KAAKC,UAAU,MAnMR,KA+MzBH,gBAAkB,SAChBD,EACAL,EACAC,EACAE,GAGA,IAFG,EAEGO,EAAiB,EAAKC,oBAAoB,EAAKnB,QAC/CoB,EAAkB,EAAKD,oBAAoB,EAAKjB,SAHnD,cAMmBW,GANnB,IAMH,2BA0BE,IA1BgC,IAAzBQ,EAAwB,QACzBzB,EAAQyB,EAAU,GAClBC,EAAgBD,EAAU,GAC1BE,EAAgB,EAAKC,cAAc5B,EAAO0B,GAC1CG,EAAsBF,EAAc,GACpCG,EAAuBH,EAAc,GAqBlC/F,EAAI,EAAGA,EAAI,EAAKsE,UAAY,EAAGtE,IACtC0F,EAAe1F,GAAGJ,IAAIqG,EAAoBjG,IAC1C4F,EAAgB5F,GAAGJ,IAAIsG,EAAqBlG,IAlC7C,8BAuCH,IAAK,IAAIA,EAAI,EAAGA,EAAI,EAAKsE,UAAY,EAAGtE,IAAK,CAC3C,IAAMmG,EAAsBnB,EAAeK,EAAUrD,OAGrD,EAAKwC,OAAOxE,GAAGG,IAAIuF,EAAe1F,GAAGI,IAAI+F,IAGzC,EAAKzB,QAAQ1E,GAAGI,IAAI,EAAI4E,GAAgBC,EAAiBE,IAGzD,EAAKT,QAAQ1E,GAAGG,IAAIyF,EAAgB5F,GAAGI,IAAI+F,MArQtB,KA+QzBH,cAAgB,SAAC5B,EAAO0B,GACtB,IAAMJ,EAAiB,EAAKC,oBAAoB,EAAKnB,QAC/CoB,EAAkB,EAAKD,oBAAoB,EAAKjB,SAGhD0B,EAAK,GACLC,EAAc,CAACjC,GACrB,EAAKkC,oBAAoBF,EAAIC,GAG7B,IAAMhD,EAAc,EAAKF,KAAKE,YAC5B+C,EAAGA,EAAGpE,OAAS,GACfqE,EAAYA,EAAYrE,OAAS,GACjC8D,EACA,EAAKxC,0BAIPoC,EAAeA,EAAe1D,OAAS,GAAKqB,EAG5CuC,EAAgBA,EAAgB5D,OAAS,GAAKxC,EAAOY,IACnDiD,EACA7D,EAAOsC,UAAUuE,EAAYA,EAAYrE,OAAS,KAKpD,IADA,IAAIuE,EAAclD,EACTrD,EAAI,EAAGA,EAAI,EAAKsE,UAAWtE,IAAK,CAEvC,IAAMwG,EAAuBhH,EAAOsC,UAClC,EAAK4C,QAAQ,EAAKA,QAAQ1C,OAAShC,EAAI,IAEnCyG,EAAqC,EAAK9B,yBAAyBrC,WACvE8D,EAAGA,EAAGpE,OAAShC,IAEjBuG,EAAc/G,EAAOY,IAAIoG,EAAsBD,GAAanG,IAC1DqG,GAIFf,EAAeA,EAAe1D,OAAShC,GAAKuG,EAG5CX,EAAgBA,EAAgB5D,OAAShC,GAAKR,EAAOY,IACnDmG,EACA/G,EAAOsC,UAAUuE,EAAYA,EAAYrE,OAAShC,EAAI,KAI1D,MAAO,CAAC0F,EAAgBE,IAjUD,KAyUzBU,oBAAsB,SAACF,EAAIC,GACzB,IAAK,IAAIrG,EAAI,EAAGA,EAAI,EAAKsE,UAAY,EAAGtE,IAAK,CAC3C,IAAMuE,EAAO,EAAKC,OAAOxE,GACnByE,EAAS,EAAKC,QAAQ1E,GAGtBmC,EAAI3C,EAAOY,IAAIqE,EAAQ4B,EAAYrG,IACzCmC,EAAEvC,IAAI2E,GACN6B,EAAG5F,KAAK2B,GAER,IAAMa,EACJhD,IAAM,EAAKsE,UAAY,EACnB,EAAKhB,yBAAyBpB,GAAGC,GACjC,EAAKwC,yBAAyBzC,GAAGC,GACvCkE,EAAY7F,KAAKwC,KAvVI,KAgWzB2C,oBAAsB,SAACrG,GACrB,IADgC,EAC1BoH,EAAW,GADe,cAEPpH,GAFO,IAEhC,2BAAiC,CAAC,IAAzBqH,EAAwB,QACzBC,EAAiB,IAAIpH,EAAOmH,EAAalH,KAAMkH,EAAajH,MAClEgH,EAASlG,KAAKoG,IAJgB,8BAMhC,OAAOF,GAtWgB,KA8WzBnB,SAAW,SAACL,GACV,IADwB,EACpB2B,EAAQ,EADY,cAGH3B,GAHG,IAGxB,2BAAgC,CAAC,IAAxB4B,EAAuB,QACxB1C,EAAQ0C,EAAS,GACjBC,EAAY,EAAK5C,YAAYC,GAC7B4C,EAAmBF,EAAS,GAAGxG,UACfyG,EAAUE,QAAQpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQkG,OACvBC,EAAiBC,QAC5CpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQmG,MAKZH,KAdoB,8BAkBxB,OAAOA,GAhYgB,KAyYzBK,UAAY,SAACC,EAAOlC,GAClB,IADqC,EACjC9B,EAAO,EACP0D,EAAQ,EAFyB,cAKpBM,GALoB,IAKrC,2BAAwB,CAAC,IAAhBjH,EAAe,QAChBkE,EAAQlE,EAAK,GACb4F,EAAgB5F,EAAK,GAErB6G,EAAY,EAAK5C,YAAYC,GAC7B4C,EAAmBlB,EAAcxF,UACjByG,EAAUE,QAAQpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQkG,OACvBC,EAAiBC,QAC5CpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQmG,MAKZH,IAIF1D,GACE,EAAKA,KAAKjB,GAAG1C,EAAOuC,gBAAgBgF,GAAYjB,GAChDqB,EAAMnF,OAGR,IAtBsB,EAsBlBoF,EAAiB,EAtBC,cAuBH,EAAK1C,SAvBF,IAuBtB,2BACE,IADgC,IAAzBD,EAAwB,QACtB5B,EAAI,EAAGA,EAAI4B,EAAOhF,KAAMoD,IAC/B,IAAK,IAAIO,EAAI,EAAGA,EAAIqB,EAAO/E,KAAM0D,IAC/BgE,GAAc,SAAI3C,EAAOvE,KAAK2C,GAAGO,GAAM,GA1BvB,8BA8BtBD,GAAe8B,EAAiBkC,EAAMnF,OAA9B,GAAwCoF,GAnCb,8BAsCrC,MAAO,CAACjE,EAAM0D,IA/aS,KA0bzBQ,cAAgB,SAACX,EAAUpH,EAAQ8E,EAAO0B,GAKxC,IAJA,IAAMwB,EAAaxB,EAAcxF,UAC3BiH,EAAU1G,KAAK2G,IAAI,IAAK,GACxBC,EAAa,EAAK9B,oBAAoBe,GAEnC1G,EAAI,EAAGA,EAAIyH,EAAWzF,OAAQhC,IACrC,IAAK,IAAI6C,EAAI,EAAGA,EAAI4E,EAAWzH,GAAGP,KAAMoD,IACtC,IAAK,IAAIO,EAAI,EAAGA,EAAIqE,EAAWzH,GAAGN,KAAM0D,IAAK,CAE3C,IAAMsE,EAAWpI,EAAOU,GAAGE,KAAK2C,GAAGO,GAGnC9D,EAAOU,GAAGE,KAAK2C,GAAGO,GAAKsE,EAAWH,EAGlC,IAFA,IAAMI,EAAa,EAAKxD,YAAYC,GAChCwD,EAAW,EACN3H,EAAI,EAAGA,EAAI0H,EAAW3F,OAAQ/B,IACrC2H,GAAY,GAAM/G,KAAK2G,IAAIF,EAAWrH,GAAK0H,EAAW1H,GAAI,GAI5DX,EAAOU,GAAGE,KAAK2C,GAAGO,GAAKsE,EAAWH,EAGlC,IAFA,IAAMM,EAAc,EAAK1D,YAAYC,GACjC0D,EAAY,EACP7H,EAAI,EAAGA,EAAI4H,EAAY7F,OAAQ/B,IACtC6H,GAAa,GAAMjH,KAAK2G,IAAIF,EAAWrH,GAAK4H,EAAY5H,GAAI,GAI9D,IAAM8H,GAAiBH,EAAWE,IAAc,EAAIP,GACpDE,EAAWzH,GAAGE,KAAK2C,GAAGO,GAAK2E,EAG3BzI,EAAOU,GAAGE,KAAK2C,GAAGO,GAAKsE,EAU7B,IALA,IAAIM,EAAW,EACXC,EAAiB,EACjBC,EAAW,EAGNlI,EAAI,EAAGA,EAAIyH,EAAWzF,OAAQhC,IACrC,IAAK,IAAI6C,EAAI,EAAGA,EAAI4E,EAAWzH,GAAGP,KAAMoD,IACtC,IAAK,IAAIO,EAAI,EAAGA,EAAIqE,EAAWzH,GAAGN,KAAM0D,IAAK,CAC3C,IAAM+E,EAAczB,EAAS1G,GAAGE,KAAK2C,GAAGO,GAClC2E,EAAgBN,EAAWzH,GAAGE,KAAK2C,GAAGO,GAE5C4E,GAAYnH,KAAK2G,IAAIW,EAAa,GAClCF,GAAkBpH,KAAK2G,IAAIO,EAAe,GAC1CG,GAAYrH,KAAK2G,IAAIO,EAAgBI,EAAa,GAKxD,OACEtH,KAAKK,KAAKgH,IAAarH,KAAKK,KAAK+G,GAAkBpH,KAAKK,KAAK8G,KAjf/DzG,KAAKoD,yBAA2BlC,EAChClB,KAAK+B,yBAA2BV,EAChCrB,KAAK4B,KAAOK,EAERU,EAAM,CAER3C,KAAK+C,UAAYJ,EAAKD,MAAMjC,OAC5BT,KAAK0C,MAAQ,GAHL,oBAISC,EAAKD,OAJd,IAIR,2BAA6B,CAAC,IAArBmE,EAAoB,QAC3B7G,KAAK0C,MAAMzD,KAAK4H,IALV,8BASR7G,KAAKiD,OAAS,GATN,oBAUSN,EAAKM,QAVd,IAUR,2BAA8B,CAAC,IAAtBD,EAAqB,QAC5BhD,KAAKiD,OAAOhE,KAAK,IAAIhB,EAAO,KAAM,KAAM+E,KAXlC,8BAeRhD,KAAKmD,QAAU,GAfP,oBAgBWR,EAAKQ,SAhBhB,IAgBR,2BAAiC,CAAC,IAAzBD,EAAwB,QAC/BlD,KAAKmD,QAAQlE,KAAK,IAAIhB,EAAO,KAAM,KAAMiF,KAjBnC,8BAqBJP,EAAKmE,eAAe,eACtB9G,KAAK+G,UAAY,IAAI9I,EAAO,KAAM,KAAM0E,EAAKoE,WAC7C/G,KAAKgH,SAAW,IAAI/I,EAAO,KAAM,KAAM0E,EAAKqE,eAEzC,CACLhH,KAAK+C,UAAYL,EAAMjC,OACvBT,KAAK0C,MAAQA,EAGb1C,KAAKiD,OAAS,GACd,IAAK,IAAIxE,EAAI,EAAGA,EAAIiE,EAAMjC,OAAQhC,IAAK,CACrC,IAAMuE,EAAO,IAAI/E,EAAOyE,EAAMjE,GAAI,GAE9BuB,KAAKoD,2BAA6BlC,EAEpC8B,EAAK5F,KAAI,SAAC6J,GAAD,OAAO,KAEhBjE,EAAKxD,kBAGPQ,KAAKiD,OAAOhE,KAAK+D,GAInBhD,KAAKmD,QAAU,GACf,IArBK,eAqBI1E,GACP,IAAMyE,EAAS,IAAIjF,EAAOyE,EAAMjE,GAAIiE,EAAMjE,EAAI,IAG9CyE,EAAO1D,kBACH,EAAK4D,2BAA6BlC,GACpCgC,EAAO9F,KAAI,SAAC8J,GAAD,OAAOA,EAAI5H,KAAKK,KAAK,EAAI+C,EAAMjE,EAAI,OAGhD,EAAK0E,QAAQlE,KAAKiE,IATXzE,EAAI,EAAGA,EAAIiE,EAAMjC,OAAQhC,IAAM,EAA/BA,KAzDTgE,EAkgBG0E,qBAAuB,SAAC7D,EAAY8D,EAAUzD,GAWnD,IAVA,IAAM0D,EAAmB,CAAC,EAAG,GAAI,GAAI,GAAI,KACnCC,EAAsB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACnDC,EAAwB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACvDC,EAAgB,EAChBC,EAAmB,IACnBC,EAAqB,IACrBC,EAAe,EACfC,EAAc,KAGTnJ,EAAI,EAAGA,EAAI4I,EAAiB5G,OAAQhC,IAC3C,IAAK,IAAIC,EAAI,EAAGA,EAAI4I,EAAoB7G,OAAQ/B,IAC9C,IAAK,IAAI4B,EAAI,EAAGA,EAAIiH,EAAsB9G,OAAQH,IAAK,CACrD,IAAMuH,EAAeR,EAAiB5I,GAChCqJ,EAAkBR,EAAoB5I,GACtCqJ,EAAoBR,EAAsBjH,GAG1C0H,EAAa,IAAIvF,EAAK,CAAC,IAAK,GAAI,KACtCuF,EAAW3E,0BACTC,EACA,EACAuE,EACAC,EACAC,GAIF,IAAME,EAAcD,EAAWhE,SAASoD,GAGpCa,EAAcN,IAChBH,EAAgBK,EAChBJ,EAAmBK,EACnBJ,EAAqBK,EACrBJ,EAAeM,EACfL,EAAcI,GAMtB1J,QAAQC,IAAI,yBAA2BiJ,GACvClJ,QAAQC,IAAI,uBAAyBkJ,GACrCnJ,QAAQC,IAAI,wBAA0BmJ,GACtCpJ,QAAQC,IACN,wBACEoJ,EACA,IACAP,EAAS3G,OACT,KACC,IAAMkH,EAAgBP,EAAS3G,OAChC,KAIJ,IAAMyH,EAAyBN,EAAY5D,SAASL,GACpDrF,QAAQC,IACN,kBACE2J,EACA,IACAvE,EAAUlD,OACV,KACC,IAAMyH,EAA0BvE,EAAUlD,OAC3C,KAIJnC,QAAQC,IAAI,gBAAiB0F,KAAKC,UAAU0D,KAIjCnF,Q,iCChkBA0F,E,8EAAf,WAAwBC,GAAxB,iCAAA3G,EAAA,sEAEuB4G,MAAMD,GAF7B,cAEME,EAFN,gBAKqBA,EAASC,cAL9B,UAKMC,EALN,OAQMC,EAAc,EAGdC,EAAa,IAAIC,SAASH,EAAQ,EAAG,EAAIC,GAS1B,QANfG,EAAU,IAAI3I,MAAMwI,GACrBvI,OACA9C,KAAI,SAAC+B,EAAGV,GAAJ,OAAUiK,EAAWG,UAAU,EAAIpK,GAAG,OAIjC,GApBd,iBAqBIZ,EAAO,QACPiL,EAAa,EACbL,EAAc,EAvBlB,2BAwB4B,OAAfG,EAAQ,GAxBrB,iBAyBI/K,EAAO,QACPiL,EAAaF,EAAQ,GAAKA,EAAQ,GA1BtC,8BA4BU,IAAIG,MAAM,qBAAuBH,EAAQ,IA5BnD,WAgCMjK,EAAO,IAAIqK,WAAWR,EAAsB,EAAdC,GAGrB,UAAT5K,EAnCN,iBAqCI,IADIoL,EAAU,GACLxK,EAAI,EAAGA,EAAImK,EAAQ,GAAInK,IAC9BwK,EAAQhK,KAAKN,EAAKuK,SAASJ,EAAarK,EAAGqK,GAAcrK,EAAI,KAtCnE,OAwCIH,QAAQC,IAAI,eAAgB6J,GAxChC,kBAyCWa,GAzCX,eA6CE3K,QAAQC,IAAI,eAAgB6J,GA7C9B,kBA8CSzJ,GA9CT,6C,sBAiDewK,MAvEf,SAAmBC,GACjB,IAAIC,EAAQ,GACRC,EAAQ,CACVC,YAAa,4BACbC,YAAa,4BACbC,WAAY,2BACZC,WAAY,4BAId,OAAOC,QAAQC,IACbC,OAAOC,KAAKR,GAAOlM,IAAnB,iBAAAyM,OAAA,IAAAA,CAAA,UAAuB,WAAOzB,GAAP,SAAA3G,EAAA,sEACD0G,EAASmB,EAAMlB,IADd,OACrBiB,EAAMjB,GADe,kDAAvB,wDAGA2B,MAAK,kBAAMX,EAASC,O,yBC8TTW,E,4MAzRbC,OAAS,SAACC,EAAKpM,GA2Bb,GA1BY,SAARoM,IAEF,EAAKC,MAAQrM,EAAEsM,QAAU,EAAKC,OAAOC,wBAAwBC,KAC7D,EAAKC,MAAQ1M,EAAE2M,QAAU,EAAKJ,OAAOC,wBAAwBI,IAG7D,EAAKC,IAAIC,YACT,EAAKD,IAAIE,UAAY,EACrB,EAAKF,IAAIG,IAAI,EAAKX,MAAO,EAAKK,MAAOO,GAAgB,EAAG,EAAIzL,KAAKO,IACjE,EAAK8K,IAAIK,SACT,EAAKL,IAAIM,YACT,EAAKN,IAAIzK,OAGT,EAAKgL,MAAMjM,KAAK,CAAC,CAAC,EAAKkL,OAAQ,CAAC,EAAKK,SAGrC,EAAKW,WAAY,GAIP,OAARjB,GAAwB,QAARA,IAClB,EAAKiB,WAAY,GAIP,SAARjB,GAAkB,EAAKiB,UAAW,CAEpC,EAAKC,MAAQ,EAAKjB,MAClB,EAAKkB,MAAQ,EAAKb,MAGlB,EAAKL,MAAQrM,EAAEsM,QAAU,EAAKC,OAAOC,wBAAwBC,KAC7D,EAAKC,MAAQ1M,EAAE2M,QAAU,EAAKJ,OAAOC,wBAAwBI,IAG7D,IAAMY,EAAW,EAAKJ,MAAM,EAAKA,MAAMzK,OAAS,GAChD6K,EAAS,GAAGrM,KAAK,EAAKkL,OACtBmB,EAAS,GAAGrM,KAAK,EAAKuL,OACtB,EAAKU,MAAM,EAAKA,MAAMzK,OAAS,GAAK6K,EAGpC,EAAKC,KACH,EAAKZ,IA9FM,GAgGX,EAAKS,MACL,EAAKC,MACL,EAAKlB,MACL,EAAKK,S,EAMXe,KAAO,SAACZ,EAAKE,EAAWW,EAAIC,EAAIC,EAAIC,GAClChB,EAAIC,YACJD,EAAIiB,YA1GM,QA2GVjB,EAAIE,UAAYA,EAChBF,EAAIkB,QAAU,QACdlB,EAAImB,SAAW,QACfnB,EAAIoB,OAAOP,EAAIC,GACfd,EAAIqB,OAAON,EAAIC,GACfhB,EAAIK,SACJL,EAAIM,a,EAINgB,MAAQ,WACN,EAAKtB,IAAIuB,UAAU,EAAG,EAAG,EAAK7B,OAAO8B,MAAO,EAAK9B,OAAO+B,QACxD,EAAKlB,MAAQ,GAEb,EAAKmB,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,S,EAGhEG,qBAAuB,SAACC,GAItB,IAFA,IAAMC,EAAe,GAEZ/K,EAAI,EAAGA,EAAI8K,EAAQJ,OAAQ1K,IAAK,CAEvC+K,EAAa/K,GAAK,GAElB,IAAK,IAAIlD,EAAI,EAAGA,EAAIgO,EAAQL,MAAO3N,IAAK,CAEtC,IAAMkO,EAAa,EAAJhL,EAAQ8K,EAAQL,MAAQ,EAAI3N,EAM7B,IAHAgO,EAAQ7N,KAAK+N,EAAS,KAIlCF,EAAQ7N,KAAK+N,GAAU,KAIzBD,EAAa/K,GAAGlD,GAAKgO,EAAQ7N,KAAK+N,GAAU,KAKhD,OAAOD,G,EAGTE,gBAAkB,SAACC,EAAKC,GAQtB,IAPA,IAAM3O,EAAO0O,EAAInM,OACXqM,EAAUF,EAAI,GAAGnM,OACnBsM,EAAOD,EACPE,EAAO9O,EACP+O,GAAQ,EACRC,GAAQ,EAEHxL,EAAI,EAAGA,EAAIxD,EAAMwD,IACxB,IAAK,IAAIlD,EAAI,EAAGA,EAAIsO,EAAStO,IAEvBoO,EAAIlL,GAAGlD,GAAKqO,IACVE,EAAOvO,IAAGuO,EAAOvO,GACjByO,EAAOzO,IAAGyO,EAAOzO,GACjBwO,EAAOtL,IAAGsL,EAAOtL,GACjBwL,EAAOxL,IAAGwL,EAAOxL,IAK3B,MAAO,CAAEsL,KAAMA,EAAMD,KAAMA,EAAMG,KAAMA,EAAMD,KAAMA,I,EAGrDE,YAAc,SAACP,GAQb,IAPA,IAAM1O,EAAO0O,EAAInM,OACXqM,EAAUF,EAAI,GAAGnM,OACnB2M,EAAQ,EACRC,EAAQ,EACRC,EAAY,EAGP5L,EAAI,EAAGA,EAAIxD,EAAMwD,IACxB,IAAK,IAAIlD,EAAI,EAAGA,EAAIsO,EAAStO,IAAK,CAChC,IAAI+O,EAAQ,EAAIX,EAAIlL,GAAGlD,GACvB4O,GAAS5O,EAAI+O,EACbF,GAAS3L,EAAI6L,EACbD,GAAaC,EASjB,OANAH,GAASE,EACTD,GAASC,EAKF,CAAEE,OAHAlO,KAAKmO,MAAMX,EAAU,EAAIM,GAGbM,OAFZpO,KAAKmO,MAAMvP,EAAO,EAAImP,K,EAKjCM,QAAU,WAER,IAAInB,EAAU,EAAK7B,IAAIiD,aAAa,EAAG,EAhN7B,IACC,KAgNPnB,EAAe,EAAKF,qBAAqBC,GAGvCqB,EAAe,EAAKlB,gBAAgBF,EAjNnB,KAmNjBqB,EAAQ,EAAKX,YAAYV,GAGzBsB,EAAaC,SAASC,cAAc,UAC1CF,EAAW5B,MAAQK,EAAQL,MAC3B4B,EAAW3B,OAASI,EAAQJ,OAC5B,IAAM8B,EAAUH,EAAWI,WAAW,MAGhCC,EAAMP,EAAaZ,KAAOY,EAAad,KAAO,EAC9CsB,EAAMR,EAAaX,KAAOW,EAAab,KAAO,EAC9CsB,EA/NS,KA+NeF,EAAMC,EAAMD,EAAMC,GAGhDH,EAAQK,UAAU,EAAKlE,OAAO8B,MAAQ,EAAG,EAAK9B,OAAO+B,OAAS,GAC9D8B,EAAQM,MAAMF,EAASA,GACvBJ,EAAQK,WAAW,EAAKlE,OAAO8B,MAAQ,GAAI,EAAK9B,OAAO+B,OAAS,GAGhE8B,EAAQK,UAAUT,EAAMN,OAAQM,EAAMJ,QAIpC,IAAK,IAAIe,EAAI,EAAGA,EAAI,EAAKvD,MAAMzK,OAAQgO,IACrC,IAAK,IAAIhQ,EAAI,EAAGA,EAAI,EAAKyM,MAAMuD,GAAG,GAAGhO,OAAS,EAAGhC,IAAK,CACpD,IAAM+M,EAAK,EAAKN,MAAMuD,GAAG,GAAGhQ,GACtBgN,EAAK,EAAKP,MAAMuD,GAAG,GAAGhQ,GACtBiN,EAAK,EAAKR,MAAMuD,GAAG,GAAGhQ,EAAI,GAC1BkN,EAAK,EAAKT,MAAMuD,GAAG,GAAGhQ,EAAI,GAChC,EAAK8M,KAAK2C,EA/OD,GA+OuBI,EAAS9C,EAAIC,EAAIC,EAAIC,GAQ3Da,EAAU0B,EAAQN,aAAa,EAAG,EA3PxB,IACC,KA2PXnB,EAAe,EAAKF,qBAAqBC,GAMzC,IAHA,IAAMkC,EAAU,IAAIzO,MAAM,KAGjByB,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIlD,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAE3B,IADA,IAAImQ,EAAO,EACFjP,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIkP,EAAI,EAAGA,EAAI,GAAIA,IACtBD,GAAQlC,EAAiB,GAAJ/K,EAAShC,GAAO,GAAJlB,EAASoQ,GAK9CF,EAAY,GAAJhN,EAASlD,GAAK,EAAImQ,EAAO,IAMrC,EAAKtC,MAAMH,UAAU,EAAG,EAAG,EAAKI,SAASH,MAAO,EAAKG,SAASF,QAE9D,IAAK,IAAI1K,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIlD,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMqQ,EAAQ,EAAKxC,MAAMuB,aAAapP,EAAGkD,EAAG,EAAG,GACzCoN,EAAS,IAAMJ,EAAY,GAAJhN,EAASlD,GAEtCqQ,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAK,IAEhB,EAAK0N,MAAM0C,aAAaF,EAAOrQ,EAAGkD,GA8BtC,OAAOgN,G,kEAjTY,IAAD,OAClB1O,KAAKqK,OAAS2D,SAASgB,eAAe,eACtChP,KAAK2K,IAAM3K,KAAKqK,OAAO8D,WAAW,MAClCnO,KAAKsM,SAAW0B,SAASgB,eAAe,YACxChP,KAAKqM,MAAQrM,KAAKsM,SAAS6B,WAAW,MAEtCnO,KAAKqK,OAAO4E,iBACV,aACA,SAACnR,GACC,EAAKmM,OAAO,OAAQnM,MAEtB,GAEFkC,KAAKqK,OAAO4E,iBACV,aACA,SAACnR,GACC,EAAKmM,OAAO,OAAQnM,MAEtB,GAEFkC,KAAKqK,OAAO4E,iBACV,WACA,SAACnR,GACC,EAAKmM,OAAO,KAAMnM,MAEpB,GAEFkC,KAAKqK,OAAO4E,iBACV,YACA,SAACnR,GACC,EAAKmM,OAAO,MAAOnM,MAErB,GAGFkC,KAAKoL,MAAQ,EACbpL,KAAKmK,MAAQ,EACbnK,KAAKqL,MAAQ,EACbrL,KAAKwK,MAAQ,EACbxK,KAAKkL,MAAQ,GACblL,KAAKmL,WAAY,I,+BA6QjB,OACE,4BACE+D,GAAG,cACH/C,MAnUM,KAmUOgD,WACb/C,OAnUO,KAmUQ+C,WACfC,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,e,GA9TNC,aCafxN,EAAO,SAAG,IAAO,KAkbRyN,E,kDA7ab,WAAYC,GAAQ,IAAD,8BACjB,cAAMA,IAgERC,YAAc,WAEZ,IAAK,IAAIlR,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAD2B,EACvBgL,EAAa,GADU,cAGN,EAAK9F,WAHC,IAG3B,2BAAqC,CAAC,IAA7B4B,EAA4B,QAC7BqK,EAAWrK,EAAS,GAAGxG,UAI7B,GAHc6Q,EAASlK,QAAQpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQsQ,OAG7BnR,IACZgL,EAAWxK,KAAKsG,EAAS,GAAGxG,WA/Eb,IAkFX0K,EAAWhJ,QACb,OAbqB,8BAmB3B,IAAK,IAAI/B,EAAI,EAAGA,EAAI,EAAGA,IAIrB,IAHA,IACMiM,EADSqD,SAASgB,eAAT,iBAAkCvQ,EAAlC,YAAuCC,IACnCyP,WAAW,MAErBzM,EAAI,EAAGA,EAAI,GAAIA,IACtB,IAAK,IAAIlD,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMqQ,EAAQlE,EAAIkF,gBAAgB,EAAG,GAC/Bf,EAAS,IAAMrF,EAAW/K,GAAO,GAAJgD,EAASlD,GAE5CqQ,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAKmQ,EAChBD,EAAMlQ,KAAK,GAAK,IAEhBgM,EAAIoE,aAAaF,EAAOrQ,EAAGkD,MApGlB,EA2GnBoO,WAAa,WAkBTxR,QAAQC,IAAI,wBACZ,EAAKoF,UAAY,EAAKoM,UACpB,EAAK1G,MAAMI,WAAWuG,MAAM,EArInB,KAsIT,EAAK3G,MAAMK,WAAWsG,MAAM,EAtInB,OAMI,EAqInBD,UAAY,SAACE,EAAQC,GAGnB,IAFA,IAAMtK,EAAQ,GAELnH,EAAI,EAAGA,EAAIwR,EAAOxP,OAAQhC,IAAK,CAKtC,IAJA,IAAM0R,EAAWF,EAAOxR,GAClB2R,EAAiBF,EAAOzR,GACxBsH,EAAa,GAEVrH,EAAI,EAAGA,EAAI,GAAIA,IAClB0R,IAAmB1R,EACrBqH,EAAW9G,KAAK,GAEhB8G,EAAW9G,KAAK,GAIpB2G,EAAM3G,KAAK,CACThB,EAAOuC,gBAAgB2P,GACvBlS,EAAOuC,gBAAgBuF,KAI3B,OAAOH,GA3JU,EA8JnByK,gBAAkB,WAEhB,IAAK,EAAK1N,KAAKmE,eAAe,aAAc,CAC1C,IAAM6H,EAAO,IAAI1Q,EAAO,IAAK,GACvBqS,EAAM,IAAIrS,EAAO,IAAK,GAG5BK,QAAQC,IAAI,+BAL8B,oBAMpB,EAAK+E,YANe,IAM1C,2BAAuC,CAAC,IAA/BgB,EAA8B,QACrCqK,EAAKtQ,IAAIiG,EAAU,KAPqB,8BAW1CqK,EAAKvR,KAAI,SAACoB,GAAD,OAAOA,EAAI,EAAK8E,WAAW7C,UAGpCnC,QAAQC,IAAI,6CAd8B,oBAepB,EAAK+E,YAfe,IAe1C,2BAAuC,CAAC,IAA/BgB,EAA8B,QACrCgM,EAAIjS,IAAIJ,EAAOW,IAAI0F,EAAU,GAAIqK,GAAMvR,KAAI,SAACoB,GAAD,gBAAOA,EAAK,QAhBf,8BAoB1C8R,EAAIlT,KAAI,SAACoB,GAAD,OAAOc,KAAKK,KAAKnB,EAAI,EAAK8E,WAAW7C,WAG7C,EAAKkC,KAAKoE,UAAY4H,EACtB,EAAKhM,KAAKqE,SAAWsJ,EAIvB,IAAM3B,EAAO,EAAKhM,KAAKoE,UACjBuJ,EAAM,EAAK3N,KAAKqE,SAsBpB1I,QAAQC,IAAI,2BACZ,IAAK,IAAIE,EAAI,EAAGA,EAAI,EAAKkF,UAAUlD,OAAQhC,IACzC,EAAKkF,UAAUlF,GAAG,GAAGG,IAAI+P,GAAM7P,IAAIb,EAAOb,IAAIkT,GAAK,SAAC9R,GAAD,OAAOA,EAAIwD,OArNjD,EA0NnBuO,cAAgB,WAEG,IAaF,gBAEQ,EAAK5M,WAFb,IAEb,2BAAqC,SAC1B,GAAG7E,IAAI,MAHL,gCAzOE,EAiPnB0R,cAAgB,WACd,QAAkBC,IAAd,EAAK9N,KAAoB,CAC3B,IAAME,EAAQ5E,EAAOuC,gBAAgB,EAAKkQ,UAAUC,QAAQhD,WApQtC,EAgRtB,IAAMiD,EAAgB,EAAKjO,KAAKC,YAAYC,GACtCgO,EAAWD,EAAclL,QAAQpG,KAAK6B,IAAL,MAAA7B,KAAI,YAAQsR,KAGnD,EAAKE,SAAS,CACZF,gBACAC,eArQa,EA0QnBE,YAAc,WACZ,EAAKL,UAAUC,QAAQ1E,QAEvB,EAAK6E,SAAS,CACZF,cAAe,GACfI,aAAc,GACdH,SAAU,GACVI,QAAS,MA/QX,EAAKC,MAAQ,CACXN,cAAe,GACfI,aAAc,GACdH,SAAU,GACVI,QAAS,IAGX9H,GAAU,SAACxK,GACT,EAAK0K,MAAQ1K,EACbL,QAAQC,IAAI,oBAMZ,EAAKuR,aAIH,EAAKS,gBAGP,EAAKZ,cAqBH,EAAKhN,KAAO,IAAIF,EAAK,KAAM0O,MAiB/B,EAAKT,UAAYU,IAAMC,YA9DN,E,qDAuRjB,IADA,IAAM5H,EAAa,GACVhL,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAG3B,IAFA,IAAMN,EAAO,GAEJO,EAAI,EAAGA,EA7RG,EA6RmBA,IAAK,CACzC,IAAM4S,EACJ,yBAAK1T,UAAU,WAAWL,IAAG,cAASkB,EAAT,YAAcC,IACzC,4BACEwQ,GAAE,iBAAYzQ,EAAZ,YAAiBC,GACnByN,MAAM,KACNC,OAAO,KACPgD,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,YAKzBpR,EAAKc,KAAKqS,GAGZ,IAAMC,EACJ,yBAAK3T,UAAU,6BAA6BL,IAAG,cAASkB,IACrDN,GAGLsL,EAAWxK,KAAKsS,GAIlB,IADA,IAAMC,EAAY,GACT/S,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMgT,EACJ,yBAAK7T,UAAU,MAAML,IAAK,MAAQkB,GAChC,yBAAKb,UAAU,kBACb,4BAAKa,EAAL,MAEF,yBAAKb,UAAU,iBACb,4BACGoC,KAAKkR,MAAMN,cAAcnQ,OAAS,GACA,IAA9BT,KAAKkR,MAAMN,cAAcnS,IAAUiT,QAAQ,GAAK,IACjD,MAKZF,EAAUvS,KAAKwS,GAGjB,IADA,IAAME,EAAW,GACRlT,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMgT,EACJ,yBAAK7T,UAAU,MAAML,IAAK,MAAQkB,GAChC,yBAAKb,UAAU,kBACb,4BAAKa,EAAL,MAEF,yBAAKb,UAAU,iBACb,4BACGoC,KAAKkR,MAAMF,aAAavQ,OAAS,GACA,IAA7BT,KAAKkR,MAAMF,aAAavS,IAAUiT,QAAQ,GAAK,IAChD,MAKZC,EAAS1S,KAAKwS,GAGhB,OACE,yBAAK7T,UAAU,kCACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAOX,KAAK,uBAGhB,yBAAKW,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CACEX,KACE,0FAKR,yBAAKW,UAAU,YACb,yBAAKA,UAAU,OACb,+CAGH6L,EACD,yBAAK7L,UAAU,mCACb,yBAAKA,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,UAAUC,QAASqC,KAAKwQ,iBAExC,yBAAK5S,UAAU,2BACb,kBAAC,EAAD,CAAQF,MAAM,QAAQC,QAASqC,KAAK+Q,gBAGxC,yBAAKnT,UAAU,YACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAQgU,IAAK5R,KAAK0Q,cAGtB,yBAAK9S,UAAU,OACb,yBAAKA,UAAU,OACb,4BACEsR,GAAG,WACH/C,MAAM,KACNC,OAAO,KACPgD,MAAO,CACLC,OAAQ,uBACRC,aAAc,MACdC,gBAAiB,aAKzB,yBAAK3R,UAAU,mCACb,yBAAKA,UAAU,2BACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,kBACb,sCAEF,yBAAKA,UAAU,iBACb,4BAAKoC,KAAKkR,MAAML,YAGnBW,GAEH,yBAAK5T,UAAU,2BACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,kBACb,qCAEF,yBAAKA,UAAU,iBACb,4BAAKoC,KAAKkR,MAAMD,WAGnBU,IAGL,kBAAC,IAAD,CACEE,KAAK,mDACLC,YAAY,OACZC,UAAU,UACVhU,OAAO,gB,GAvaCyR,aCjBEwC,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASC,MACvB,2D,YCXNC,IAASC,OAAO,kBAAC,EAAD,MAAStE,SAASgB,eAAe,SD4H3C,kBAAmBuD,WACrBA,UAAUC,cAAcC,MAAM1I,MAAK,SAAA2I,GACjCA,EAAaC,kB","file":"static/js/main.ab5b4853.chunk.js","sourcesContent":["import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Title = ({ text }) => {\r\n  return <h1>{text}</h1>;\r\n};\r\n\r\nTitle.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Title;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Description = ({ text }) => {\r\n  const addLineBreaks = string =>\r\n    string.split(\"\\n\").map((text, index) => (\r\n      <React.Fragment key={`${text}-${index}`}>\r\n        {text}\r\n        <br />\r\n      </React.Fragment>\r\n    ));\r\n\r\n  return <h5>{addLineBreaks(text)}</h5>;\r\n};\r\n\r\nDescription.defaultProps = {\r\n  text: \"Default description\"\r\n};\r\n\r\nDescription.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Description;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Button = ({ value, onClick }) => {\r\n  const handleOnClick = (e) => {\r\n    e.target.blur();\r\n    onClick();\r\n  };\r\n\r\n  return (\r\n    <button\r\n      className=\"btn btn-primary btn-lg\"\r\n      type=\"button\"\r\n      onClick={handleOnClick}\r\n    >\r\n      {value}\r\n    </button>\r\n  );\r\n};\r\n\r\nButton.propTypes = {\r\n  value: PropTypes.string,\r\n  onClick: PropTypes.func,\r\n};\r\n\r\nexport default Button;\r\n","class Matrix {\r\n  constructor(rows, cols, matrix) {\r\n    if (matrix) {\r\n      // Deep copy\r\n      this.rows = matrix.rows;\r\n      this.cols = matrix.cols;\r\n      this.data = [];\r\n      for (let i = 0; i < this.rows; i++) {\r\n        this.data.push([]);\r\n        for (let j = 0; j < this.cols; j++) {\r\n          this.data[i].push(matrix.data[i][j]);\r\n        }\r\n      }\r\n    } else {\r\n      this.rows = rows;\r\n      this.cols = cols;\r\n      this.data = Array(rows)\r\n        .fill()\r\n        .map(() => Array(cols).fill(0));\r\n    }\r\n  }\r\n\r\n  add = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Add: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x + matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x + matrix);\r\n  };\r\n\r\n  static add = (matrix1, matrix2) => {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Add: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] + matrix2.data[i][j]\r\n    );\r\n  };\r\n\r\n  sub = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Subtract: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x - matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x - matrix);\r\n  };\r\n\r\n  static sub = (matrix1, matrix2) => {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Subtract: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] - matrix2.data[i][j]\r\n    );\r\n  };\r\n\r\n  mul = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Multiply: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x * matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x * matrix);\r\n  };\r\n\r\n  static mul = (matrix1, matrix2) => {\r\n    if (matrix1.cols !== matrix2.rows) {\r\n      console.log(\r\n        \"Multiply: first matrix's columns must match second matrix's rows\"\r\n      );\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix2.cols).map((_, i, j) => {\r\n      let sum = 0;\r\n      for (let k = 0; k < matrix1.cols; k++) {\r\n        sum += matrix1.data[i][k] * matrix2.data[k][j];\r\n      }\r\n      return sum;\r\n    });\r\n  };\r\n\r\n  div = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Division: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x / matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x / matrix);\r\n  };\r\n\r\n  static transpose = (matrix) => {\r\n    return new Matrix(matrix.cols, matrix.rows).map(\r\n      (_, i, j) => matrix.data[j][i]\r\n    );\r\n  };\r\n\r\n  static vectorFromArray = (arr) => {\r\n    return new Matrix(arr.length, 1).map((_, i) => arr[i]);\r\n  };\r\n\r\n  toArray = () => {\r\n    const arr = [];\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        arr.push(this.data[i][j]);\r\n      }\r\n    }\r\n    return arr;\r\n  };\r\n\r\n  copy = () => {\r\n    return new Matrix(this.rows, this.cols).map((_, i, j) => this.data[i][j]);\r\n  };\r\n\r\n  map = (func) => {\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        this.data[i][j] = func(this.data[i][j], i, j);\r\n      }\r\n    }\r\n    return this;\r\n  };\r\n\r\n  static map = (matrix, func) => {\r\n    return new Matrix(matrix.rows, matrix.cols).map((_, i, j) =>\r\n      func(matrix.data[i][j], i, j)\r\n    );\r\n  };\r\n\r\n  randomize = () => {\r\n    return this.map(() => Math.random() * 2 - 1);\r\n  };\r\n\r\n  // Box-Muller Transform for normal distribution, mean = 0, variance = 1\r\n  randomizeNormal = () => {\r\n    return this.map(() => {\r\n      let u = 0;\r\n      let v = 0;\r\n      while (u === 0) u = Math.random();\r\n      while (v === 0) v = Math.random();\r\n      return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\r\n    });\r\n  };\r\n\r\n  print = () => {\r\n    console.table(this.data);\r\n    return this;\r\n  };\r\n}\r\n\r\nexport default Matrix;\r\n","import Matrix from \"./matrix\";\r\n\r\n/**\r\n * The sigmoid activation function and derivative.\r\n */\r\nexport class SigmoidActivation {\r\n  /**\r\n   * Returns the matrix mapped with sigmoid.\r\n   * @param {Matrix} z The matrix to apply the sigmoid function to\r\n   * @return {Matrix} The matrix mapped with sigmoid\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => 1 / (1 + Math.exp(-z_i)));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with sigmoid derivative.\r\n   * @param {Matrix} z The matrix to apply the sigmoid derivative function to\r\n   * @return {Matrix} The matrix mapped with sigmoid derivative\r\n   */\r\n  static derivative = (z) => {\r\n    const sigmoid = SigmoidActivation.fn(z);\r\n    return sigmoid.mul(Matrix.map(sigmoid, (a_i) => 1 - a_i));\r\n  };\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class ReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with ReLU.\r\n   * @param {Matrix} z The matrix to apply the ReLu function to\r\n   * @return {Matrix} The matrix mapped with ReLu\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => Math.max(0, z_i));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with ReLU derivative\r\n   */\r\n  static derivative = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0));\r\n  };\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class LeakyReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLu function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLu\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? z_i : 0.01 * z_i));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLU derivative\r\n   */\r\n  static derivative = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0.01));\r\n  };\r\n}\r\n\r\n/**\r\n * The softmax activation function and derivative.\r\n */\r\nexport class SoftmaxActivation {\r\n  /**\r\n   * Returns the matrix mapped with softmax.\r\n   * @param {Matrix} z The matrix to apply the softmax function to\r\n   * @return {Matrix} The matrix mapped with softmax\r\n   */\r\n  static fn = (z) => {\r\n    let sum = 0;\r\n    for (let r = 0; r < z.rows; r++) {\r\n      sum += Math.exp(z.data[r][0]);\r\n    }\r\n    return Matrix.map(z, (z_i) => Math.exp(z_i) / sum);\r\n  };\r\n\r\n  /**\r\n   * Returns the softmax derivative of the given number.\r\n   * @param {Matrix} z The matrix to apply the softmax derivative function to\r\n   * @return {Matrix} The matrix mapped with softmax derivative\r\n   */\r\n  static derivative = (z) => {\r\n    const softmax = SoftmaxActivation.fn(z);\r\n    return softmax.mul(Matrix.map(softmax, (a_i) => 1 - a_i));\r\n  };\r\n}\r\n\r\n/**\r\n * The quadratic cost function and output layer error.\r\n */\r\nexport class QuadraticCost {\r\n  /**\r\n   * Returns the cost = sum over all (0.5 * (a - y)^2).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The cost\r\n   */\r\n  static fn = (a, y) => {\r\n    const diffMatrix = Matrix.sub(a, y);\r\n    let cost = 0;\r\n    for (let r = 0; r < diffMatrix.rows; r++) {\r\n      for (let c = 0; c < diffMatrix.cols; c++) {\r\n        cost += 0.5 * diffMatrix.data[r][c] ** 2;\r\n      }\r\n    }\r\n    return cost;\r\n  };\r\n\r\n  /**\r\n   * Returns the output error = (a - y) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error\r\n   */\r\n  static outputError = (z, a, y, outputActivationFunction) => {\r\n    const costDerivativeWRTa = Matrix.sub(a, y);\r\n    return costDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  };\r\n}\r\n\r\nconst EPSILON = 10 ** -100;\r\n\r\n/**\r\n * The cross entropy cost function and output layer error.\r\n */\r\nexport class CrossEntropyCost {\r\n  /**\r\n   * Returns the cost = sum over all -(y * ln(a) + (1 - y) * ln(1 - a)).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The cost\r\n   */\r\n  static fn = (a, y) => {\r\n    const yIsOne = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    const yIsZero = Matrix.mul(\r\n      Matrix.transpose(Matrix.map(y, (y_i) => 1 - y_i)),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 1, not doing log(0)\r\n        return Math.log(1 - a_i + EPSILON);\r\n      })\r\n    );\r\n    return -(yIsOne.data[0][0] + yIsZero.data[0][0]);\r\n  };\r\n\r\n  /**\r\n   * Returns the output error = [(a - y) / (a * (1 - a))] hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The derivative with respect to a\r\n   */\r\n  static outputError = (z, a, y, outputActivationFunction) => {\r\n    const costDerivativeWRTa = Matrix.sub(a, y).mul(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return 1 / (a_i * (1 - a_i) + EPSILON);\r\n      })\r\n    );\r\n    return costDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  };\r\n}\r\n\r\n/**\r\n * Fisher-Yates shuffle.\r\n * @param {Array} arr The array to shuffle\r\n * @return {Array} The shuffled array\r\n */\r\nexport const shuffle = (arr) => {\r\n  for (let i = arr.length - 1; i > 0; i--) {\r\n    const randomIndex = Math.floor(Math.random() * (i + 1));\r\n    const temp = arr[i];\r\n    arr[i] = arr[randomIndex];\r\n    arr[randomIndex] = temp;\r\n  }\r\n  return arr;\r\n};\r\n","import Matrix from \"./matrix\";\r\nimport {\r\n  SigmoidActivation,\r\n  ReLUActivation,\r\n  LeakyReLUActivation,\r\n  SoftmaxActivation,\r\n  QuadraticCost,\r\n  CrossEntropyCost,\r\n  shuffle,\r\n} from \"./helpers\";\r\n\r\nconst CHECK_GRADIENTS = false;\r\nconst LOG_MINI_BATCH_ACCURACY = false;\r\nconst LOG_MINI_BATCH_COST = false;\r\nconst OUTPUT_NETWORK = true;\r\n\r\nclass FFNN {\r\n  /**\r\n   * Creates a FFNN with the givens layer sizes or using the preset settings from the optional FFNN.\r\n   * @param {Array} sizes An array of layer sizes\r\n   * @param {FFNN} ffnn Optional initial settings\r\n   */\r\n  constructor(sizes, ffnn) {\r\n    this.hiddenActivationFunction = ReLUActivation;\r\n    this.outputActivationFunction = SoftmaxActivation;\r\n    this.cost = CrossEntropyCost;\r\n\r\n    if (ffnn) {\r\n      // Deep copy\r\n      this.numLayers = ffnn.sizes.length;\r\n      this.sizes = [];\r\n      for (let size of ffnn.sizes) {\r\n        this.sizes.push(size);\r\n      }\r\n\r\n      // Copy bias vectors\r\n      this.biases = [];\r\n      for (let bias of ffnn.biases) {\r\n        this.biases.push(new Matrix(null, null, bias));\r\n      }\r\n\r\n      // Copy weight matrices\r\n      this.weights = [];\r\n      for (let weight of ffnn.weights) {\r\n        this.weights.push(new Matrix(null, null, weight));\r\n      }\r\n\r\n      // Save mean and std in case of standardization\r\n      if (ffnn.hasOwnProperty(\"trainMean\")) {\r\n        this.trainMean = new Matrix(null, null, ffnn.trainMean);\r\n        this.trainSTD = new Matrix(null, null, ffnn.trainSTD);\r\n      }\r\n    } else {\r\n      this.numLayers = sizes.length;\r\n      this.sizes = sizes;\r\n\r\n      // Create bias vectors\r\n      this.biases = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const bias = new Matrix(sizes[i], 1);\r\n\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          // He initialization, biases = 0\r\n          bias.map((b) => 0);\r\n        } else {\r\n          bias.randomizeNormal();\r\n        }\r\n\r\n        this.biases.push(bias);\r\n      }\r\n\r\n      // Create weight matrices\r\n      this.weights = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const weight = new Matrix(sizes[i], sizes[i - 1]);\r\n\r\n        // He initialization, weights random standard normal * sqrt(2 / # incoming connections)\r\n        weight.randomizeNormal();\r\n        if (this.hiddenActivationFunction === ReLUActivation) {\r\n          weight.map((w) => w * Math.sqrt(2 / sizes[i - 1]));\r\n        }\r\n\r\n        this.weights.push(weight);\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Performs feedforward and returns the result as an array.\r\n   * @param {Matrix} input The input as a Matrix object (vector)\r\n   * @return {Array} The result as an array\r\n   */\r\n  feedforward = (input) => {\r\n    let output = input;\r\n\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wx + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, output);\r\n      z.add(bias);\r\n      output =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n    }\r\n\r\n    return output.toArray();\r\n  };\r\n\r\n  /**\r\n   * Performs stochastic gradient descent with the specified hyperparameters.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} miniBatchSize The size of the mini batches\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {Array} testDatas The optional test datas\r\n   */\r\n  stochasticGradientDescent = (\r\n    trainDatas,\r\n    epochs,\r\n    miniBatchSize,\r\n    learningRate,\r\n    regularization,\r\n    testDatas = null\r\n  ) => {\r\n    // Train datas = [trainData == [Matrix(input), Matrix(desiredOutput)]]\r\n    const trainDataSize = trainDatas.length;\r\n\r\n    // Train for specified number of epochs\r\n    for (let i = 0; i < epochs; i++) {\r\n      // Shuffle the train datas every epoch\r\n      shuffle(trainDatas);\r\n\r\n      // Mini batches = [miniBatch == [trainData == [Matrix(input), Matrix(desiredOutput)]]]\r\n      const miniBatches = [];\r\n      for (let j = 0; j < trainDataSize; j += miniBatchSize) {\r\n        // Mini batch = [trainData == [Matrix(input), Matrix(desiredOutput)]]\r\n        const miniBatch = [];\r\n\r\n        // Train data = [Matrix(input), Matrix(desiredOutput)]\r\n        for (let k = j; k < j + miniBatchSize; k++) {\r\n          miniBatch.push(trainDatas[k]);\r\n        }\r\n        miniBatches.push(miniBatch);\r\n      }\r\n\r\n      // Update each mini batch\r\n      for (let j = 0; j < miniBatches.length; j++) {\r\n        this.updateMiniBatch(\r\n          miniBatches[j],\r\n          learningRate,\r\n          regularization,\r\n          trainDataSize\r\n        );\r\n\r\n        // Accuracy on test set\r\n        if (LOG_MINI_BATCH_ACCURACY) {\r\n          const accuracy = this.accuracy(testDatas);\r\n          console.log(\r\n            \"Testing mini batch \" +\r\n              (j + 1) +\r\n              \"/\" +\r\n              miniBatches.length +\r\n              \": \" +\r\n              accuracy +\r\n              \"/\" +\r\n              testDatas.length +\r\n              \", \" +\r\n              (100 * accuracy) / testDatas.length +\r\n              \"%\"\r\n          );\r\n        } else {\r\n          // Only log this if not doing the more detailed accuracy logging\r\n          console.log(\r\n            \"Finished mini batch \" + (j + 1) + \"/\" + miniBatches.length\r\n          );\r\n        }\r\n\r\n        // Cost on train set\r\n        if (LOG_MINI_BATCH_COST) {\r\n          const trainCost = this.trainCost(trainDatas, regularization);\r\n          console.log(\r\n            \"Train cost: \" +\r\n              trainCost[0] +\r\n              \", \" +\r\n              trainCost[1] +\r\n              \"/\" +\r\n              trainDatas.length +\r\n              \", \" +\r\n              (100 * trainCost[1]) / trainDatas.length +\r\n              \"%\"\r\n          );\r\n        }\r\n      }\r\n\r\n      // Testing\r\n      if (testDatas !== null) {\r\n        const accuracy = this.accuracy(testDatas);\r\n        console.log(\r\n          \"Testing epoch \" +\r\n            (i + 1) +\r\n            \"/\" +\r\n            epochs +\r\n            \": \" +\r\n            accuracy +\r\n            \"/\" +\r\n            testDatas.length +\r\n            \", \" +\r\n            (100 * accuracy) / testDatas.length +\r\n            \"%\"\r\n        );\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Updates the mini batch by getting the gradient and then applying it.\r\n   * @param {Array} miniBatch The mini batch of train data\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {number} trainDataSize The size of the train data set\r\n   */\r\n  updateMiniBatch = (\r\n    miniBatch,\r\n    learningRate,\r\n    regularization,\r\n    trainDataSize\r\n  ) => {\r\n    // Cumulative gradients for mini batch\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Calculates the cumulative biases and weights gradients for all train data in the mini batch\r\n    for (let trainData of miniBatch) {\r\n      const input = trainData[0];\r\n      const desiredOutput = trainData[1];\r\n      const gradientDelta = this.backpropagate(input, desiredOutput);\r\n      const biasesGradientDelta = gradientDelta[0];\r\n      const weightsGradientDelta = gradientDelta[1];\r\n\r\n      // Do gradient checking\r\n      if (CHECK_GRADIENTS) {\r\n        const biasesCheck = this.gradientCheck(\r\n          biasesGradientDelta,\r\n          this.biases,\r\n          input,\r\n          desiredOutput\r\n        );\r\n        console.log(\"Gradient check biases:\", biasesCheck);\r\n        const weightsCheck = this.gradientCheck(\r\n          weightsGradientDelta,\r\n          this.weights,\r\n          input,\r\n          desiredOutput\r\n        );\r\n        console.log(\"Gradient check weights:\", weightsCheck);\r\n      }\r\n\r\n      // Add gradient delta to miniBatch\r\n      for (let i = 0; i < this.numLayers - 1; i++) {\r\n        biasesGradient[i].add(biasesGradientDelta[i]);\r\n        weightsGradient[i].add(weightsGradientDelta[i]);\r\n      }\r\n    }\r\n\r\n    // Apply the cumulative biases and weights gradients to the network's biases and weights\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const learningRateWithAvg = learningRate / miniBatch.length;\r\n\r\n      // Bias adjustment by gradient, no regularization\r\n      this.biases[i].sub(biasesGradient[i].mul(learningRateWithAvg));\r\n\r\n      // Weight regularization\r\n      this.weights[i].mul(1 - learningRate * (regularization / trainDataSize));\r\n\r\n      // Weight adjustment by gradient\r\n      this.weights[i].sub(weightsGradient[i].mul(learningRateWithAvg));\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Performs backpropagation to calculate the gradient for one train data.\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} desiredOutput The desired output matrix\r\n   * @return {Array} The array consisting of the biasesGradient and weightsGradient for this one train data\r\n   */\r\n  backpropagate = (input, desiredOutput) => {\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Feedforward, store zs and activations by layer\r\n    const zs = [];\r\n    const activations = [input];\r\n    this.trainingFeedforward(zs, activations);\r\n\r\n    // Output error = costDerivativeWRTa hadamardProduct outputActivationFunctionDerivative(outputZ)\r\n    const outputError = this.cost.outputError(\r\n      zs[zs.length - 1],\r\n      activations[activations.length - 1],\r\n      desiredOutput,\r\n      this.outputActivationFunction\r\n    );\r\n\r\n    // Output biasesGradient is simply the output error\r\n    biasesGradient[biasesGradient.length - 1] = outputError;\r\n\r\n    // Output weightsGradient = outputError * beforeOutputActivationTranspose\r\n    weightsGradient[weightsGradient.length - 1] = Matrix.mul(\r\n      outputError,\r\n      Matrix.transpose(activations[activations.length - 2])\r\n    );\r\n\r\n    // Backpropagate error to hidden layers\r\n    let hiddenError = outputError;\r\n    for (let i = 2; i < this.numLayers; i++) {\r\n      // Hidden error = (nextWeightsTranspose * nextError which is last pass's hidden error) hadamardProduct hiddenActivationFunctionDerivative(z)\r\n      const nextWeightsTranspose = Matrix.transpose(\r\n        this.weights[this.weights.length - i + 1]\r\n      );\r\n      const hiddenActivationFunctionDerivative = this.hiddenActivationFunction.derivative(\r\n        zs[zs.length - i]\r\n      );\r\n      hiddenError = Matrix.mul(nextWeightsTranspose, hiddenError).mul(\r\n        hiddenActivationFunctionDerivative\r\n      );\r\n\r\n      // Hidden biasesGradient is simply the hidden error\r\n      biasesGradient[biasesGradient.length - i] = hiddenError;\r\n\r\n      // Hidden weightsGradient = hiddenError * beforeHiddenActivationsTranspose\r\n      weightsGradient[weightsGradient.length - i] = Matrix.mul(\r\n        hiddenError,\r\n        Matrix.transpose(activations[activations.length - i - 1])\r\n      );\r\n    }\r\n\r\n    return [biasesGradient, weightsGradient];\r\n  };\r\n\r\n  /**\r\n   * Feedforward, but also keeping record of the z's and activations per layer.\r\n   * @param {Array} zs The array to store the z records\r\n   * @param {Array} activations The array to store the activation records\r\n   */\r\n  trainingFeedforward = (zs, activations) => {\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wa + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, activations[i]);\r\n      z.add(bias);\r\n      zs.push(z);\r\n\r\n      const a =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n      activations.push(a);\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Creates an empty gradient with the target array's shape.\r\n   * @param {Array} target The target array\r\n   * @return {Array} The empty gradient array with in the shape of the target array\r\n   */\r\n  createEmptyGradient = (target) => {\r\n    const gradient = [];\r\n    for (let targetMatrix of target) {\r\n      const gradientMatrix = new Matrix(targetMatrix.rows, targetMatrix.cols);\r\n      gradient.push(gradientMatrix);\r\n    }\r\n    return gradient;\r\n  };\r\n\r\n  /**\r\n   * Returns a count of how many test cases were passed.\r\n   * @param {Array} testDatas The array of test datas\r\n   * @return {number} The number of test cases passed\r\n   */\r\n  accuracy = (testDatas) => {\r\n    let count = 0;\r\n\r\n    for (let testData of testDatas) {\r\n      const input = testData[0];\r\n      const outputArr = this.feedforward(input);\r\n      const desiredOutputArr = testData[1].toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const desiredOutputInteger = desiredOutputArr.indexOf(\r\n        Math.max(...desiredOutputArr)\r\n      );\r\n\r\n      // Count number correct\r\n      if (outputInteger === desiredOutputInteger) {\r\n        count++;\r\n      }\r\n    }\r\n\r\n    return count;\r\n  };\r\n\r\n  /**\r\n   * Returns the train cost and correct count for the data set using the regularization parameter.\r\n   * @param {Array} datas The array of data to get the train cost for\r\n   * @param {number} regularization The regularization parameter\r\n   * @return {Array} The train cost and correct count\r\n   */\r\n  trainCost = (datas, regularization) => {\r\n    let cost = 0;\r\n    let count = 0;\r\n\r\n    // Add cost of each data point\r\n    for (let data of datas) {\r\n      const input = data[0];\r\n      const desiredOutput = data[1];\r\n\r\n      const outputArr = this.feedforward(input);\r\n      const desiredOutputArr = desiredOutput.toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const desiredOutputInteger = desiredOutputArr.indexOf(\r\n        Math.max(...desiredOutputArr)\r\n      );\r\n\r\n      // Count correct\r\n      if (outputInteger === desiredOutputInteger) {\r\n        count++;\r\n      }\r\n\r\n      // Output cost\r\n      cost +=\r\n        this.cost.fn(Matrix.vectorFromArray(outputArr), desiredOutput) /\r\n        datas.length;\r\n\r\n      // Regularization cost\r\n      let squaredWeights = 0;\r\n      for (let weight of this.weights) {\r\n        for (let r = 0; r < weight.rows; r++) {\r\n          for (let c = 0; c < weight.cols; c++) {\r\n            squaredWeights += weight.data[r][c] ** 2;\r\n          }\r\n        }\r\n      }\r\n      cost += 0.5 * (regularization / datas.length) * squaredWeights;\r\n    }\r\n\r\n    return [cost, count];\r\n  };\r\n\r\n  /**\r\n   * Performs gradient checking technique, manually calculating the gradient using the limit definition the derivative and a small epsilon.\r\n   * @param {Array} gradient The gradient to check\r\n   * @param {Array} target A reference to the neural network's biases or weights\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} desiredOutput The desired output matrix\r\n   * @return {number} The euclidean norm ratio which should be less than 10^-7\r\n   */\r\n  gradientCheck = (gradient, target, input, desiredOutput) => {\r\n    const desiredArr = desiredOutput.toArray();\r\n    const epsilon = Math.pow(10, -7);\r\n    const gradApprox = this.createEmptyGradient(gradient);\r\n\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          // Save the original bias or weight value to restore it at the end\r\n          const original = target[i].data[r][c];\r\n\r\n          // Calculate the cost with plus epsilon\r\n          target[i].data[r][c] = original + epsilon;\r\n          const outputPlus = this.feedforward(input);\r\n          let costPlus = 0;\r\n          for (let j = 0; j < outputPlus.length; j++) {\r\n            costPlus += 0.5 * Math.pow(desiredArr[j] - outputPlus[j], 2);\r\n          }\r\n\r\n          // Calculate the cost with minus epsilon\r\n          target[i].data[r][c] = original - epsilon;\r\n          const outputMinus = this.feedforward(input);\r\n          let costMinus = 0;\r\n          for (let j = 0; j < outputMinus.length; j++) {\r\n            costMinus += 0.5 * Math.pow(desiredArr[j] - outputMinus[j], 2);\r\n          }\r\n\r\n          // Limit definition of derivative\r\n          const gradApproxVal = (costPlus - costMinus) / (2 * epsilon);\r\n          gradApprox[i].data[r][c] = gradApproxVal;\r\n\r\n          // Restore the initial bias or weight value\r\n          target[i].data[r][c] = original;\r\n        }\r\n      }\r\n    }\r\n\r\n    let paramSum = 0;\r\n    let paramApproxSum = 0;\r\n    let errorSum = 0;\r\n\r\n    // Sum all Euclidean components\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          const gradientVal = gradient[i].data[r][c];\r\n          const gradApproxVal = gradApprox[i].data[r][c];\r\n\r\n          paramSum += Math.pow(gradientVal, 2);\r\n          paramApproxSum += Math.pow(gradApproxVal, 2);\r\n          errorSum += Math.pow(gradApproxVal - gradientVal, 2);\r\n        }\r\n      }\r\n    }\r\n\r\n    return (\r\n      Math.sqrt(errorSum) / (Math.sqrt(paramApproxSum) + Math.sqrt(paramSum))\r\n    );\r\n  };\r\n\r\n  /**\r\n   * Automation for choosing the regularization parameter.\r\n   * @param {Array} trainDatas The array of train datas\r\n   * @param {Array} valDatas The array of validation datas\r\n   * @param {Array} testDatas The array of test datas\r\n   */\r\n  static chooseHypeparameters = (trainDatas, valDatas, testDatas) => {\r\n    const miniBatchOptions = [1, 10, 20, 50, 100];\r\n    const learningRateOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    const regularizationOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    let bestMiniBatch = 1;\r\n    let bestLearningRate = 0.01;\r\n    let bestRegularization = 0.01;\r\n    let bestAccuracy = 0;\r\n    let bestNetwork = null;\r\n\r\n    // Train a different model for each combination of options\r\n    for (let i = 0; i < miniBatchOptions.length; i++) {\r\n      for (let j = 0; j < learningRateOptions.length; j++) {\r\n        for (let k = 0; k < regularizationOptions.length; k++) {\r\n          const curMiniBatch = miniBatchOptions[i];\r\n          const curLearningRate = learningRateOptions[j];\r\n          const curRegularization = regularizationOptions[k];\r\n\r\n          // Train the network using the current settings\r\n          const curNetwork = new FFNN([784, 30, 10]);\r\n          curNetwork.stochasticGradientDescent(\r\n            trainDatas,\r\n            1,\r\n            curMiniBatch,\r\n            curLearningRate,\r\n            curRegularization\r\n          );\r\n\r\n          // Evaluate accuracy using validation set\r\n          const valAccuracy = curNetwork.accuracy(valDatas);\r\n\r\n          // Choose best neural network based on validation set\r\n          if (valAccuracy > bestAccuracy) {\r\n            bestMiniBatch = curMiniBatch;\r\n            bestLearningRate = curLearningRate;\r\n            bestRegularization = curRegularization;\r\n            bestAccuracy = valAccuracy;\r\n            bestNetwork = curNetwork;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    console.log(\"Best mini batch size: \" + bestMiniBatch);\r\n    console.log(\"Best learning rate: \" + bestLearningRate);\r\n    console.log(\"Best regularization: \" + bestRegularization);\r\n    console.log(\r\n      \"Best validation set: \" +\r\n        bestAccuracy +\r\n        \"/\" +\r\n        valDatas.length +\r\n        \", \" +\r\n        (100 * bestAccuracy) / valDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Test the generalization of the selected network on the test set\r\n    const generalizationAccuracy = bestNetwork.accuracy(testDatas);\r\n    console.log(\r\n      \"Best test set: \" +\r\n        generalizationAccuracy +\r\n        \"/\" +\r\n        testDatas.length +\r\n        \", \" +\r\n        (100 * generalizationAccuracy) / testDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Log the best neural network\r\n    console.log(\"Best network:\", JSON.stringify(bestNetwork));\r\n  };\r\n}\r\n\r\nexport default FFNN;\r\n","/**\r\n * Loads the MNIST data.\r\n * @param {function} callback The callback function to be called when loading is finished\r\n * @return {Promise} The resolved promise\r\n */\r\nfunction loadMNIST(callback) {\r\n  let mnist = {};\r\n  let files = {\r\n    trainImages: \"./train-images.idx3-ubyte\",\r\n    trainLabels: \"./train-labels.idx1-ubyte\",\r\n    testImages: \"./t10k-images.idx3-ubyte\",\r\n    testLabels: \"./t10k-labels.idx1-ubyte\",\r\n  };\r\n\r\n  // Load all files\r\n  return Promise.all(\r\n    Object.keys(files).map(async (file) => {\r\n      mnist[file] = await loadFile(files[file]);\r\n    })\r\n  ).then(() => callback(mnist));\r\n}\r\n\r\n/**\r\n * Parses the MNIST file into an array of data.\r\n * @param {string} file The filename\r\n * @return {Array} The MNIST data\r\n */\r\nasync function loadFile(file) {\r\n  // Fetch file response\r\n  let response = await fetch(file);\r\n\r\n  // Get 8-bit/1-byte array\r\n  let buffer = await response.arrayBuffer();\r\n\r\n  // Default header count is 4 for images, change to 2 for labels later\r\n  let headerCount = 4;\r\n\r\n  // Can't access data straight from ArrayBuffer, extract headers using DataView\r\n  let headerView = new DataView(buffer, 0, 4 * headerCount);\r\n\r\n  // Create Array of 32-bit/4-byte headers\r\n  let headers = new Array(headerCount)\r\n    .fill()\r\n    .map((_, i) => headerView.getUint32(4 * i, false));\r\n\r\n  // Get file type: image or label\r\n  let type, dataLength;\r\n  if (headers[0] === 2049) {\r\n    type = \"label\";\r\n    dataLength = 1;\r\n    headerCount = 2;\r\n  } else if (headers[0] === 2051) {\r\n    type = \"image\";\r\n    dataLength = headers[2] * headers[3];\r\n  } else {\r\n    throw new Error(\"Unknown file type \" + headers[0]);\r\n  }\r\n\r\n  // Create array of data only, headers removed\r\n  let data = new Uint8Array(buffer, headerCount * 4);\r\n\r\n  // Image, create array of subarrays of 28 * 28 = 784\r\n  if (type === \"image\") {\r\n    let dataArr = [];\r\n    for (let i = 0; i < headers[1]; i++) {\r\n      dataArr.push(data.subarray(dataLength * i, dataLength * (i + 1)));\r\n    }\r\n    console.log(\"Loaded file:\", file);\r\n    return dataArr;\r\n  }\r\n\r\n  // Label, just return data straight away\r\n  console.log(\"Loaded file:\", file);\r\n  return data;\r\n}\r\n\r\nexport default loadMNIST;\r\n","import React, { Component } from \"react\";\r\n\r\nconst WIDTH = 280;\r\nconst HEIGHT = 280;\r\nconst SCALE_SIZE = 190;\r\nconst BOUNDING_THRESHOLD = 0.01;\r\nconst LINE_WIDTH = 20;\r\nconst COLOR = \"black\";\r\nconst SCALE_PATH = true;\r\n\r\nconst DEBUG = false;\r\n\r\nclass Canvas extends Component {\r\n  componentDidMount() {\r\n    this.canvas = document.getElementById(\"main-canvas\");\r\n    this.ctx = this.canvas.getContext(\"2d\");\r\n    this.canvas28 = document.getElementById(\"canvas28\");\r\n    this.ctx28 = this.canvas28.getContext(\"2d\");\r\n\r\n    this.canvas.addEventListener(\r\n      \"mousemove\",\r\n      (e) => {\r\n        this.findxy(\"move\", e);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mousedown\",\r\n      (e) => {\r\n        this.findxy(\"down\", e);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseup\",\r\n      (e) => {\r\n        this.findxy(\"up\", e);\r\n      },\r\n      false\r\n    );\r\n    this.canvas.addEventListener(\r\n      \"mouseout\",\r\n      (e) => {\r\n        this.findxy(\"out\", e);\r\n      },\r\n      false\r\n    );\r\n\r\n    this.prevX = 0;\r\n    this.currX = 0;\r\n    this.prevY = 0;\r\n    this.currY = 0;\r\n    this.paths = [];\r\n    this.paintFlag = false;\r\n  }\r\n\r\n  findxy = (res, e) => {\r\n    if (res === \"down\") {\r\n      // Get touch down point\r\n      this.currX = e.clientX - this.canvas.getBoundingClientRect().left;\r\n      this.currY = e.clientY - this.canvas.getBoundingClientRect().top;\r\n\r\n      // Draw circle\r\n      this.ctx.beginPath();\r\n      this.ctx.lineWidth = 1;\r\n      this.ctx.arc(this.currX, this.currY, LINE_WIDTH / 2, 0, 2 * Math.PI);\r\n      this.ctx.stroke();\r\n      this.ctx.closePath();\r\n      this.ctx.fill();\r\n\r\n      // Add start of new path\r\n      this.paths.push([[this.currX], [this.currY]]);\r\n\r\n      // Activate paint flag\r\n      this.paintFlag = true;\r\n    }\r\n\r\n    // Deactivate paint flag on touch up or mouse off canvas\r\n    if (res === \"up\" || res === \"out\") {\r\n      this.paintFlag = false;\r\n    }\r\n\r\n    // If moving and paint flag activated, draw!\r\n    if (res === \"move\" && this.paintFlag) {\r\n      // Save previous point\r\n      this.prevX = this.currX;\r\n      this.prevY = this.currY;\r\n\r\n      // Get new point\r\n      this.currX = e.clientX - this.canvas.getBoundingClientRect().left;\r\n      this.currY = e.clientY - this.canvas.getBoundingClientRect().top;\r\n\r\n      // Add point to last path\r\n      const currPath = this.paths[this.paths.length - 1];\r\n      currPath[0].push(this.currX);\r\n      currPath[1].push(this.currY);\r\n      this.paths[this.paths.length - 1] = currPath;\r\n\r\n      // Draw line between new point and previous point\r\n      this.draw(\r\n        this.ctx,\r\n        LINE_WIDTH,\r\n        this.prevX,\r\n        this.prevY,\r\n        this.currX,\r\n        this.currY\r\n      );\r\n    }\r\n  };\r\n\r\n  // Draw line between 2 points\r\n  draw = (ctx, lineWidth, x1, y1, x2, y2) => {\r\n    ctx.beginPath();\r\n    ctx.strokeStyle = COLOR;\r\n    ctx.lineWidth = lineWidth;\r\n    ctx.lineCap = \"round\";\r\n    ctx.lineJoin = \"round\";\r\n    ctx.moveTo(x1, y1);\r\n    ctx.lineTo(x2, y2);\r\n    ctx.stroke();\r\n    ctx.closePath();\r\n  };\r\n\r\n  // Erase canvas and clear paths\r\n  erase = () => {\r\n    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n    this.paths = [];\r\n\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n  };\r\n\r\n  imageDataToGrayscale = (imgData) => {\r\n    // 2D array\r\n    const grayscaleImg = [];\r\n\r\n    for (let y = 0; y < imgData.height; y++) {\r\n      // Row number y\r\n      grayscaleImg[y] = [];\r\n\r\n      for (let x = 0; x < imgData.width; x++) {\r\n        // Each pixel has four values, RGBA\r\n        const offset = y * 4 * imgData.width + 4 * x;\r\n\r\n        // Alpha === 0 means no drawing\r\n        const alpha = imgData.data[offset + 3];\r\n\r\n        // No drawing, set value to white\r\n        if (alpha === 0) {\r\n          imgData.data[offset] = 255;\r\n        }\r\n\r\n        // Take only RED value since grayscale and scale to [0, 1]\r\n        grayscaleImg[y][x] = imgData.data[offset] / 255;\r\n        // grayscaleImg[y][x] = imgData.data[offset];\r\n      }\r\n    }\r\n\r\n    return grayscaleImg;\r\n  };\r\n\r\n  getBoundingRect = (img, threshold) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let minX = columns;\r\n    let minY = rows;\r\n    let maxX = -1;\r\n    let maxY = -1;\r\n\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        // Black === 0, so must be lower than some darkness threshold to be considered significant\r\n        if (img[y][x] < threshold) {\r\n          if (minX > x) minX = x;\r\n          if (maxX < x) maxX = x;\r\n          if (minY > y) minY = y;\r\n          if (maxY < y) maxY = y;\r\n        }\r\n      }\r\n    }\r\n\r\n    return { minY: minY, minX: minX, maxY: maxY, maxX: maxX };\r\n  };\r\n\r\n  centerImage = (img) => {\r\n    const rows = img.length;\r\n    const columns = img[0].length;\r\n    let meanX = 0;\r\n    let meanY = 0;\r\n    let sumPixels = 0;\r\n\r\n    // Center of mass, weighted by color intensity\r\n    for (let y = 0; y < rows; y++) {\r\n      for (let x = 0; x < columns; x++) {\r\n        let pixel = 1 - img[y][x];\r\n        meanX += x * pixel;\r\n        meanY += y * pixel;\r\n        sumPixels += pixel;\r\n      }\r\n    }\r\n    meanX /= sumPixels;\r\n    meanY /= sumPixels;\r\n\r\n    let dx = Math.round(columns / 2 - meanX);\r\n    let dy = Math.round(rows / 2 - meanY);\r\n\r\n    return { transX: dx, transY: dy };\r\n  };\r\n\r\n  predict = () => {\r\n    // Get image and convert to grayscale\r\n    let imgData = this.ctx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    let grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Get bounding rectangle and center of mass translation amount\r\n    const boundingRect = this.getBoundingRect(grayscaleImg, BOUNDING_THRESHOLD);\r\n    // const boundingRect = this.getBoundingRect(grayscaleImg, 25);\r\n    const trans = this.centerImage(grayscaleImg);\r\n\r\n    // Create hidden copy of canvas context\r\n    const canvasCopy = document.createElement(\"canvas\");\r\n    canvasCopy.width = imgData.width;\r\n    canvasCopy.height = imgData.height;\r\n    const copyCtx = canvasCopy.getContext(\"2d\");\r\n\r\n    // Scale largest dimension to SCALE_SIZE\r\n    const brW = boundingRect.maxX - boundingRect.minX + 1;\r\n    const brH = boundingRect.maxY - boundingRect.minY + 1;\r\n    const scaling = SCALE_SIZE / (brW > brH ? brW : brH);\r\n\r\n    // Scale\r\n    copyCtx.translate(this.canvas.width / 2, this.canvas.height / 2);\r\n    copyCtx.scale(scaling, scaling);\r\n    copyCtx.translate(-this.canvas.width / 2, -this.canvas.height / 2);\r\n\r\n    // Center on canvas over center of mass\r\n    copyCtx.translate(trans.transX, trans.transY);\r\n\r\n    if (SCALE_PATH) {\r\n      // Scale path line width\r\n      for (let p = 0; p < this.paths.length; p++) {\r\n        for (let i = 0; i < this.paths[p][0].length - 1; i++) {\r\n          const x1 = this.paths[p][0][i];\r\n          const y1 = this.paths[p][1][i];\r\n          const x2 = this.paths[p][0][i + 1];\r\n          const y2 = this.paths[p][1][i + 1];\r\n          this.draw(copyCtx, LINE_WIDTH / scaling, x1, y1, x2, y2);\r\n        }\r\n      }\r\n    } else {\r\n      copyCtx.drawImage(this.ctx.canvas, 0, 0);\r\n    }\r\n\r\n    // Get scaled and translated image and convert to grayscale\r\n    imgData = copyCtx.getImageData(0, 0, WIDTH, HEIGHT);\r\n    grayscaleImg = this.imageDataToGrayscale(imgData);\r\n\r\n    // Final input array for neural net\r\n    const nnInput = new Array(784);\r\n\r\n    // Convert to 28x28\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        let mean = 0;\r\n        for (let v = 0; v < 10; v++) {\r\n          for (let h = 0; h < 10; h++) {\r\n            mean += grayscaleImg[y * 10 + v][x * 10 + h];\r\n          }\r\n        }\r\n\r\n        // Average and invert color\r\n        nnInput[y * 28 + x] = 1 - mean / 100;\r\n        // nnInput[y + 28 * x] = 255 - mean / 100;\r\n      }\r\n    }\r\n\r\n    // Draw to 28x28 canvas\r\n    this.ctx28.clearRect(0, 0, this.canvas28.width, this.canvas28.height);\r\n\r\n    for (let y = 0; y < 28; y++) {\r\n      for (let x = 0; x < 28; x++) {\r\n        const block = this.ctx28.getImageData(x, y, 1, 1);\r\n        const newVal = 255 * nnInput[y * 28 + x];\r\n\r\n        block.data[0] = newVal;\r\n        block.data[1] = newVal;\r\n        block.data[2] = newVal;\r\n        block.data[3] = 255;\r\n\r\n        this.ctx28.putImageData(block, x, y);\r\n      }\r\n    }\r\n\r\n    // Draw neural network input back to canvas\r\n    if (DEBUG) {\r\n      // Clear canvas\r\n      this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\r\n\r\n      for (let y = 0; y < 28; y++) {\r\n        for (let x = 0; x < 28; x++) {\r\n          // Blocks of 10\r\n          const block = this.ctx.getImageData(x * 10, y * 10, 10, 10);\r\n          const newVal = 255 * nnInput[y * 28 + x];\r\n          // const newVal = nnInput[y + 28 * x];\r\n\r\n          // R=G=B since grayscale, A=255 for full opacity\r\n          for (let i = 0; i < 4 * 10 * 10; i += 4) {\r\n            block.data[i] = newVal;\r\n            block.data[i + 1] = newVal;\r\n            block.data[i + 2] = newVal;\r\n            block.data[i + 3] = 255;\r\n          }\r\n\r\n          // Paint new data to canvas\r\n          this.ctx.putImageData(block, x * 10, y * 10);\r\n        }\r\n      }\r\n    }\r\n\r\n    return nnInput;\r\n  };\r\n\r\n  render() {\r\n    return (\r\n      <canvas\r\n        id=\"main-canvas\"\r\n        width={WIDTH.toString()}\r\n        height={HEIGHT.toString()}\r\n        style={{\r\n          border: \"5px solid aquamarine\",\r\n          borderRadius: \"5px\",\r\n          backgroundColor: \"white\",\r\n        }}\r\n      ></canvas>\r\n    );\r\n  }\r\n}\r\n\r\nexport default Canvas;\r\n","import React, { Component } from \"react\";\nimport Title from \"./components/title\";\nimport Description from \"./components/description\";\nimport Button from \"./components/button\";\nimport FFNN from \"./logic/ffnn\";\nimport Matrix from \"./logic/matrix\";\nimport loadMNIST from \"./logic/mnist\";\nimport ffnnModel from \"./models/ffnn-model.json\";\nimport GithubCorner from \"react-github-corner\";\nimport Canvas from \"./components/canvas\";\n\nconst TRAIN_NET = false;\nconst NEW_NET = false;\nconst USE_STANDARDIZATION = false;\n\nconst LOAD_TRAIN = false;\nconst LOAD_VAL = false;\nconst LOAD_TEST = true;\n\nconst OUTPUT_ACCURACY = false;\nconst OUTPUT_MNIST = false;\n\nconst NUM_TRAIN = 50000;\nconst NUM_VAL = 10000;\nconst NUM_TEST = 150;\nconst EPSILON = 10 ** -100;\n\nconst NUM_TEST_SAMPLES = 5;\n\nclass App extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      ffnnOutputArr: [],\n      cnnOutputArr: [],\n      ffnnPred: \"\",\n      cnnPred: \"\",\n    };\n\n    loadMNIST((data) => {\n      this.mnist = data;\n      console.log(\"All files loaded\");\n\n      if (OUTPUT_MNIST) {\n        console.log(this.mnist);\n      }\n\n      this.formatData();\n      if (USE_STANDARDIZATION) {\n        this.standardizeData();\n      } else {\n        this.normalizeData();\n      }\n\n      this.showSamples();\n\n      if (TRAIN_NET) {\n        console.log(\"Starting training\");\n\n        if (NEW_NET) {\n          this.ffnn = new FFNN([784, 30, 10]);\n        } else {\n          this.ffnn = new FFNN(null, ffnnModel);\n        }\n\n        // Remember to use much smaller learning rate when using ReLU\n        this.ffnn.stochasticGradientDescent(\n          this.trainDatas,\n          1,\n          10,\n          0.03,\n          1.0,\n          this.testDatas\n        );\n      } else {\n        this.ffnn = new FFNN(null, ffnnModel);\n\n        if (OUTPUT_ACCURACY) {\n          const accuracy = this.ffnn.accuracy(this.testDatas);\n          console.log(\n            \"Accuracy: \" +\n              accuracy +\n              \"/\" +\n              this.testDatas.length +\n              \", \" +\n              (100 * accuracy) / this.testDatas.length +\n              \"%\"\n          );\n        }\n      }\n    });\n\n    this.canvasRef = React.createRef();\n  }\n\n  showSamples = () => {\n    // Find test images for digit i\n    for (let i = 0; i < 10; i++) {\n      let testImages = [];\n\n      for (let testData of this.testDatas) {\n        const labelArr = testData[1].toArray();\n        const label = labelArr.indexOf(Math.max(...labelArr));\n\n        // Found digit\n        if (label === i) {\n          testImages.push(testData[0].toArray());\n\n          // Found required number of digits\n          if (testImages.length === NUM_TEST_SAMPLES) {\n            break;\n          }\n        }\n      }\n\n      // Display sample test images\n      for (let j = 0; j < 5; j++) {\n        const canvas = document.getElementById(`canvas-${i}-${j}`);\n        const ctx = canvas.getContext(\"2d\");\n\n        for (let y = 0; y < 28; y++) {\n          for (let x = 0; x < 28; x++) {\n            const block = ctx.createImageData(1, 1);\n            const newVal = 255 * testImages[j][y * 28 + x];\n\n            block.data[0] = newVal;\n            block.data[1] = newVal;\n            block.data[2] = newVal;\n            block.data[3] = 255;\n\n            ctx.putImageData(block, x, y);\n          }\n        }\n      }\n    }\n  };\n\n  formatData = () => {\n    if (LOAD_TRAIN) {\n      console.log(\"Formatting train data\");\n      this.trainDatas = this.loadDatas(\n        this.mnist.trainImages.slice(0, NUM_TRAIN),\n        this.mnist.trainLabels.slice(0, NUM_TRAIN)\n      );\n    }\n\n    if (LOAD_VAL) {\n      console.log(\"Formatting validation data\");\n      this.valDatas = this.loadDatas(\n        this.mnist.trainImages.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL),\n        this.mnist.trainLabels.slice(NUM_TRAIN, NUM_TRAIN + NUM_VAL)\n      );\n    }\n\n    if (LOAD_TEST) {\n      console.log(\"Formatting test data\");\n      this.testDatas = this.loadDatas(\n        this.mnist.testImages.slice(0, NUM_TEST),\n        this.mnist.testLabels.slice(0, NUM_TEST)\n      );\n    }\n  };\n\n  loadDatas = (images, labels) => {\n    const datas = [];\n\n    for (let i = 0; i < images.length; i++) {\n      const inputArr = images[i];\n      const desiredInteger = labels[i];\n      const desiredArr = [];\n\n      for (let j = 0; j < 10; j++) {\n        if (desiredInteger === j) {\n          desiredArr.push(1);\n        } else {\n          desiredArr.push(0);\n        }\n      }\n\n      datas.push([\n        Matrix.vectorFromArray(inputArr),\n        Matrix.vectorFromArray(desiredArr),\n      ]);\n    }\n\n    return datas;\n  };\n\n  standardizeData = () => {\n    // Neural network does NOT have predefined train mean and STD, calculate them and use that to standardize everything\n    if (!this.ffnn.hasOwnProperty(\"trainMean\")) {\n      const mean = new Matrix(784, 1); // mean = sum(pixels) / numTrain\n      const std = new Matrix(784, 1); // std = sqrt(sum((pixels - mean)^2) / numTrain)\n\n      // Calculate sum(pixels)\n      console.log(\"Calculating train data mean\");\n      for (let trainData of this.trainDatas) {\n        mean.add(trainData[0]);\n      }\n\n      // Divide by total number of train datas\n      mean.map((x) => x / this.trainDatas.length);\n\n      // Calculate sum((pixels - mean)^2)\n      console.log(\"Calculating train data standard deviation\");\n      for (let trainData of this.trainDatas) {\n        std.add(Matrix.sub(trainData[0], mean).map((x) => x ** 2));\n      }\n\n      // Divide by total number of train datas and square root\n      std.map((x) => Math.sqrt(x / this.trainDatas.length));\n\n      // Save to neural network\n      this.ffnn.trainMean = mean;\n      this.ffnn.trainSTD = std;\n    }\n\n    // Retrieve mean and std from neural network\n    const mean = this.ffnn.trainMean;\n    const std = this.ffnn.trainSTD;\n\n    // Standardize train images, add small epsilon so never divide by zero\n    if (LOAD_TRAIN) {\n      console.log(\"Standardizing train data\");\n      for (let i = 0; i < this.trainDatas.length; i++) {\n        this.trainDatas[i][0]\n          .sub(mean)\n          .div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n\n    if (LOAD_VAL) {\n      // Standardize validation images, add small epsilon so never divide by zero\n      console.log(\"Standardizing validation data\");\n      for (let i = 0; i < this.valDatas.length; i++) {\n        this.valDatas[i][0].sub(mean).div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n\n    if (LOAD_TEST) {\n      // Standardize test images, add small epsilon so never divide by zero\n      console.log(\"Standardizing test data\");\n      for (let i = 0; i < this.testDatas.length; i++) {\n        this.testDatas[i][0].sub(mean).div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n  };\n\n  normalizeData = () => {\n    // Normalize train images\n    if (LOAD_TRAIN) {\n      for (let trainData of this.trainDatas) {\n        trainData[0].div(255);\n      }\n    }\n\n    if (LOAD_VAL) {\n      // Normalize validation images\n      for (let valData of this.valDatas) {\n        valData[0].div(255);\n      }\n    }\n\n    if (LOAD_TEST) {\n      // Normalize test images\n      for (let testData of this.testDatas) {\n        testData[0].div(255);\n      }\n    }\n  };\n\n  handlePredict = () => {\n    if (this.ffnn !== undefined) {\n      const input = Matrix.vectorFromArray(this.canvasRef.current.predict());\n      // input.mul(255);\n      // input.map(Math.round);\n\n      // Standardize or normalize input pixels\n      if (USE_STANDARDIZATION) {\n        input\n          .sub(this.ffnn.trainMean)\n          .div(Matrix.map(this.ffnn.trainSTD, (x) => x + EPSILON));\n      } else {\n        // input.div(255);\n      }\n      const ffnnOutputArr = this.ffnn.feedforward(input);\n      const ffnnPred = ffnnOutputArr.indexOf(Math.max(...ffnnOutputArr));\n\n      // Update state about prediction and displayed probabilities\n      this.setState({\n        ffnnOutputArr,\n        ffnnPred,\n      });\n    }\n  };\n\n  handleClear = () => {\n    this.canvasRef.current.erase();\n\n    this.setState({\n      ffnnOutputArr: [],\n      cnnOutputArr: [],\n      ffnnPred: \"\",\n      cnnPred: \"\",\n    });\n  };\n\n  render() {\n    const testImages = [];\n    for (let i = 0; i < 10; i++) {\n      const cols = [];\n\n      for (let j = 0; j < NUM_TEST_SAMPLES; j++) {\n        const col = (\n          <div className=\"col-auto\" key={`col-${i}-${j}`}>\n            <canvas\n              id={`canvas-${i}-${j}`}\n              width=\"28\"\n              height=\"28\"\n              style={{\n                border: \"2px solid aquamarine\",\n                borderRadius: \"5px\",\n                backgroundColor: \"white\",\n              }}\n            ></canvas>\n          </div>\n        );\n        cols.push(col);\n      }\n\n      const row = (\n        <div className=\"row justify-content-center\" key={`row-${i}`}>\n          {cols}\n        </div>\n      );\n      testImages.push(row);\n    }\n\n    const ffnnProbs = [];\n    for (let i = 0; i < 10; i++) {\n      const prob = (\n        <div className=\"row\" key={\"fnn\" + i}>\n          <div className=\"col text-right\">\n            <h5>{i}:</h5>\n          </div>\n          <div className=\"col text-left\">\n            <h5>\n              {this.state.ffnnOutputArr.length > 0\n                ? (this.state.ffnnOutputArr[i] * 100).toFixed(1) + \"%\"\n                : \"\"}\n            </h5>\n          </div>\n        </div>\n      );\n      ffnnProbs.push(prob);\n    }\n    const cnnProbs = [];\n    for (let i = 0; i < 10; i++) {\n      const prob = (\n        <div className=\"row\" key={\"cnn\" + i}>\n          <div className=\"col text-right\">\n            <h5>{i}:</h5>\n          </div>\n          <div className=\"col text-left\">\n            <h5>\n              {this.state.cnnOutputArr.length > 0\n                ? (this.state.cnnOutputArr[i] * 100).toFixed(1) + \"%\"\n                : \"\"}\n            </h5>\n          </div>\n        </div>\n      );\n      cnnProbs.push(prob);\n    }\n\n    return (\n      <div className=\"App container text-center pt-5\">\n        <div className=\"row\">\n          <div className=\"col\">\n            <Title text=\"Digit Recognizer\" />\n          </div>\n        </div>\n        <div className=\"row\">\n          <div className=\"col\">\n            <Description\n              text={\n                \"Digit recognition with feed forward (FFNN) and convolutional (CNN) neural networks.\"\n              }\n            />\n          </div>\n        </div>\n        <div className=\"row pt-3\">\n          <div className=\"col\">\n            <h3>Test Samples:</h3>\n          </div>\n        </div>\n        {testImages}\n        <div className=\"row justify-content-center pt-5\">\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Predict\" onClick={this.handlePredict} />\n          </div>\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Clear\" onClick={this.handleClear} />\n          </div>\n        </div>\n        <div className=\"row pt-3\">\n          <div className=\"col\">\n            <Canvas ref={this.canvasRef} />\n          </div>\n        </div>\n        <div className=\"row\">\n          <div className=\"col\">\n            <canvas\n              id=\"canvas28\"\n              width=\"28\"\n              height=\"28\"\n              style={{\n                border: \"2px solid aquamarine\",\n                borderRadius: \"5px\",\n                backgroundColor: \"white\",\n              }}\n            ></canvas>\n          </div>\n        </div>\n        <div className=\"row justify-content-center pb-5\">\n          <div className=\"col-6 col-md-4 col-lg-3\">\n            <div className=\"row\">\n              <div className=\"col text-right\">\n                <h5>FFNN:</h5>\n              </div>\n              <div className=\"col text-left\">\n                <h5>{this.state.ffnnPred}</h5>\n              </div>\n            </div>\n            {ffnnProbs}\n          </div>\n          <div className=\"col-6 col-md-4 col-lg-3\">\n            <div className=\"row\">\n              <div className=\"col text-right\">\n                <h5>CNN:</h5>\n              </div>\n              <div className=\"col text-left\">\n                <h5>{this.state.cnnPred}</h5>\n              </div>\n            </div>\n            {cnnProbs}\n          </div>\n        </div>\n        <GithubCorner\n          href=\"https://github.com/ryantran2165/digit-recognizer\"\n          bannerColor=\"#222\"\n          octoColor=\"#7fffd4\"\n          target=\"_blank\"\n        />\n      </div>\n    );\n  }\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.0/8 are considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl, {\n    headers: { 'Service-Worker': 'script' }\n  })\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport App from \"./App\";\nimport * as serviceWorker from \"./serviceWorker\";\nimport \"bootstrap/dist/css/bootstrap.css\";\nimport \"./index.scss\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}