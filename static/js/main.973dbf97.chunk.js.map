{"version":3,"sources":["components/title.js","components/description.js","components/sketch.js","components/button.js","components/range-input.js","components/label.js","logic/matrix.js","logic/helpers.js","logic/neural-network.js","logic/mnist.js","App.js","serviceWorker.js","index.js"],"names":["Title","text","Description","split","map","index","Fragment","key","Sketch","newSketch","hasOwnProperty","myp5","remove","p5","sketch","setup","width","Math","min","props","window","innerWidth","height","isSquare","innerHeight","createCanvas","background","draw","clearRequested","onClear","mouseDragged","withinCanvas","strokeWeight","stroke","line","pmouseX","pmouseY","mouseX","mouseY","mouseReleased","img","get","resize","loadPixels","input","i","color","pixels","onDraw","this","addEventListener","removeEventListener","id","Component","defaultProps","Button","value","loadingValue","isLoading","onClick","className","type","e","target","blur","RangeInput","max","step","defaultValue","onChange","Label","Matrix","rows","cols","matrix","add","console","log","x","j","data","sub","mul","div","toArray","arr","push","copy","_","func","randomize","random","randomizeNormal","u","v","sqrt","cos","PI","print","table","Array","fill","matrix1","matrix2","sum","k","transpose","vectorFromArray","length","SigmoidActivation","fn","z","z_i","exp","derivative","sigmoid","a_i","ReLUActivation","LeakyReLUActivation","SoftmaxActivation","r","softmax","QuadraticCost","a","y","diffMatrix","cost","c","outputError","outputActivationFunction","EPSILON","CrossEntropyCost","yIsOne","yIsZero","y_i","shuffle","randomIndex","floor","temp","NeuralNetwork","sizes","neuralNetwork","feedforward","output","numLayers","bias","biases","weight","weights","hiddenActivationFunction","stochasticGradientDescent","trainingDatas","epochs","miniBatchSize","learningRate","regularization","testDatas","trainingDataSize","miniBatches","miniBatch","updateMiniBatch","accuracy","biasesGradient","createEmptyGradient","weightsGradient","trainingData","desiredOutput","gradientDelta","backpropagate","biasesGradientDelta","weightsGradientDelta","learningRateWithAvg","zs","activations","trainingFeedforward","hiddenError","nextWeightsTranspose","hiddenActivationFunctionDerivative","gradient","targetMatrix","gradientMatrix","count","testData","outputArr","desiredOutputArr","indexOf","trainingCost","datas","squaredWeights","gradientCheck","desiredArr","epsilon","pow","gradApprox","original","outputPlus","costPlus","outputMinus","costMinus","gradApproxVal","paramSum","paramApproxSum","errorSum","gradientVal","size","b","w","chooseHypeparameters","crossValDatas","miniBatchOptions","learningRateOptions","regularizationOptions","bestMiniBatch","bestLearningRate","bestRegularization","bestAccuracy","bestNetwork","curMiniBatch","curLearningRate","curRegularization","curNetwork","crossValAccuracy","generalizationAccuracy","JSON","stringify","loadFile","file","fetch","response","arrayBuffer","buffer","headerCount","headerView","DataView","headers","getUint32","dataLength","Error","Uint8Array","dataArr","subarray","loadMNIST","callback","mnist","files","trainingImages","trainingLabels","testImages","testLabels","Promise","all","Object","keys","then","App","handleClickTrain","undefined","setState","isTraining","timer","setTimeout","standardizationOverNormalization","alreadyFormatted","formatData","standardizeData","slice","state","trainingSize","prevState","clearTimeout","loadDatas","images","labels","inputArr","desiredInteger","mean","std","trainingMean","trainingSTD","normalizeData","handleClickGuess","guess","handleClickClear","handleClear","handleDraw","handleSwitchChange","usePretrained","neuralNetworkPretrained","updateTrainingSize","Number","dataFormatted","probabilities","probability","number","toFixed","checked","htmlFor","href","bannerColor","octoColor","Boolean","location","hostname","match","ReactDOM","render","document","getElementById","navigator","serviceWorker","ready","registration","unregister"],"mappings":"ku5fAWeA,EARD,SAAC,GAAc,IAAZC,EAAW,EAAXA,KACf,OAAO,4BAAKA,ICeCC,EAhBK,SAAC,GAAc,IAAZD,EAAW,EAAXA,KASrB,OAAO,4BAAmBA,EAPjBE,MAAM,MAAMC,KAAI,SAACH,EAAMI,GAAP,OACrB,kBAAC,IAAMC,SAAP,CAAgBC,IAAG,UAAKN,EAAL,YAAaI,IAC7BJ,EACD,mC,iBCJFO,E,4MAUJC,UAAY,WACN,EAAKC,eAAe,SACtB,EAAKC,KAAKC,SAGZ,EAAKD,KAAO,IAAIE,KAAG,SAACC,GAClBA,EAAOC,MAAQ,WACb,IAAIC,EAAQC,KAAKC,IAAI,EAAKC,MAAMH,MAA2B,GAApBI,OAAOC,YAC1CC,EAAS,EAAKH,MAAMI,SACpBP,EACAC,KAAKC,IAAI,EAAKC,MAAMG,OAA6B,GAArBF,OAAOI,aACvCV,EAAOW,aAAaT,EAAOM,GAC3BR,EAAOY,WAAW,YAGpBZ,EAAOa,KAAO,WACR,EAAKR,MAAMS,iBACbd,EAAOY,WAAW,WAClB,EAAKP,MAAMU,YAIff,EAAOgB,aAAe,WACpB,GAAIC,IASF,OARAjB,EAAOkB,aAAa,IACpBlB,EAAOmB,OAAO,GACdnB,EAAOoB,KACLpB,EAAOqB,QACPrB,EAAOsB,QACPtB,EAAOuB,OACPvB,EAAOwB,SAEF,GAIXxB,EAAOyB,cAAgB,WACrB,GAAIR,IAAgB,CAClB,IAAIS,EAAM1B,EAAO2B,MACjBD,EAAIE,OAAO,GAAI,IACfF,EAAIG,aAGJ,IADA,IAAIC,EAAQ,GACHC,EAAI,EAAGA,EAAI,IAASA,IAAK,CAChC,IAAIC,EAAQN,EAAIO,OAAW,EAAJF,GAQvBD,EAAMC,GAAe,MAAVC,EAAgB,EAAI,IAAMA,EAGvC,OADA,EAAK3B,MAAM6B,OAAOJ,IACX,IAIX,IAAMb,EAAe,WACnB,OACEjB,EAAOuB,OAAS,GAChBvB,EAAOuB,OAASvB,EAAOE,OACvBF,EAAOwB,OAAS,GAChBxB,EAAOwB,OAASxB,EAAOQ,UAG1B,a,kEA3EH2B,KAAKxC,YACLW,OAAO8B,iBAAiB,SAAUD,KAAKxC,a,6CAIvCW,OAAO+B,oBAAoB,SAAUF,KAAKxC,a,+BA0E1C,OAAO,yBAAK2C,GAAG,iB,GAjFEC,aAqFrB7C,EAAO8C,aAAe,CACpBtC,MAAO,IACPM,OAAQ,IACRC,UAAU,GAYGf,QChEA+C,EArCA,SAAC,GAAiD,IAA/CC,EAA8C,EAA9CA,MAAOC,EAAuC,EAAvCA,aAAcC,EAAyB,EAAzBA,UAAWC,EAAc,EAAdA,QAmBhD,OACE,4BACEC,UAAU,yBACVC,KAAK,SACLF,QAtBkB,SAAAG,GACpBA,EAAEC,OAAOC,OACTL,MAIID,EAEA,kBAAC,IAAMpD,SAAP,KACE,0BAAMsD,UAAU,2CACfH,GAIED,ICfPS,EAAa,SAAC,GAAoD,IAAlD/C,EAAiD,EAAjDA,IAAKgD,EAA4C,EAA5CA,IAAKC,EAAuC,EAAvCA,KAAMC,EAAiC,EAAjCA,aAAchB,EAAmB,EAAnBA,GAAIiB,EAAe,EAAfA,SACtD,OACE,2BACER,KAAK,QACL3C,IAAKA,EACLgD,IAAKA,EACLC,KAAMA,EACNC,aAAcA,EACdhB,GAAIA,EACJiB,SAAUA,KAKhBJ,EAAWX,aAAe,CACxBpC,IAAK,EACLgD,IAAK,EACLC,KAAM,EACNC,aAAc,EACdhB,GAAI,IAYSa,QClBAK,EAbD,SAAC,GAAqB,IAAnBrE,EAAkB,EAAlBA,KAAMuD,EAAY,EAAZA,MACrB,OACE,wBAAII,UAAU,cACX3D,EADH,KACWuD,ICNTe,EACJ,WAAYC,EAAMC,EAAMC,GAAS,IAAD,OAC9B,GAD8B,yBAqBhCC,IAAM,SAACD,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,sCAGP,EAAKzE,KAAI,SAAC0E,EAAGjC,EAAGkC,GAAP,OAAaD,EAAIJ,EAAOM,KAAKnC,GAAGkC,MAE3C,EAAK3E,KAAI,SAAC0E,GAAD,OAAOA,EAAIJ,MA7BG,KA0ChCO,IAAM,SAACP,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKzE,KAAI,SAAC0E,EAAGjC,EAAGkC,GAAP,OAAaD,EAAIJ,EAAOM,KAAKnC,GAAGkC,MAE3C,EAAK3E,KAAI,SAAC0E,GAAD,OAAOA,EAAIJ,MAlDG,KA+DhCQ,IAAM,SAACR,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKzE,KAAI,SAAC0E,EAAGjC,EAAGkC,GAAP,OAAaD,EAAIJ,EAAOM,KAAKnC,GAAGkC,MAE3C,EAAK3E,KAAI,SAAC0E,GAAD,OAAOA,EAAIJ,MAvEG,KA0FhCS,IAAM,SAACT,GACL,OAAIA,aAAkBH,EAChB,EAAKC,OAASE,EAAOF,MAAQ,EAAKC,OAASC,EAAOD,UACpDG,QAAQC,IAAI,2CAGP,EAAKzE,KAAI,SAAC0E,EAAGjC,EAAGkC,GAAP,OAAaD,EAAIJ,EAAOM,KAAKnC,GAAGkC,MAE3C,EAAK3E,KAAI,SAAC0E,GAAD,OAAOA,EAAIJ,MAlGG,KA+GhCU,QAAU,WAER,IADA,IAAMC,EAAM,GACHxC,EAAI,EAAGA,EAAI,EAAK2B,KAAM3B,IAC7B,IAAK,IAAIkC,EAAI,EAAGA,EAAI,EAAKN,KAAMM,IAC7BM,EAAIC,KAAK,EAAKN,KAAKnC,GAAGkC,IAG1B,OAAOM,GAtHuB,KAyHhCE,KAAO,WACL,OAAO,IAAIhB,EAAO,EAAKC,KAAM,EAAKC,MAAMrE,KAAI,SAACoF,EAAG3C,EAAGkC,GAAP,OAAa,EAAKC,KAAKnC,GAAGkC,OA1HxC,KA6HhC3E,IAAM,SAACqF,GACL,IAAK,IAAI5C,EAAI,EAAGA,EAAI,EAAK2B,KAAM3B,IAC7B,IAAK,IAAIkC,EAAI,EAAGA,EAAI,EAAKN,KAAMM,IAC7B,EAAKC,KAAKnC,GAAGkC,GAAKU,EAAK,EAAKT,KAAKnC,GAAGkC,GAAIlC,EAAGkC,GAG/C,OAAO,GAnIuB,KA4IhCW,UAAY,WACV,OAAO,EAAKtF,KAAI,kBAAsB,EAAhBa,KAAK0E,SAAe,MA7IZ,KAiJhCC,gBAAkB,WAChB,OAAO,EAAKxF,KAAI,WAGd,IAFA,IAAIyF,EAAI,EACJC,EAAI,EACK,IAAND,GAASA,EAAI5E,KAAK0E,SACzB,KAAa,IAANG,GAASA,EAAI7E,KAAK0E,SACzB,OAAO1E,KAAK8E,MAAM,EAAM9E,KAAK4D,IAAIgB,IAAM5E,KAAK+E,IAAI,EAAM/E,KAAKgF,GAAKH,OAvJpC,KA2JhCI,MAAQ,WAEN,OADAtB,QAAQuB,MAAM,EAAKnB,MACZ,GA5JHN,EAAQ,CAEVzB,KAAKuB,KAAOE,EAAOF,KACnBvB,KAAKwB,KAAOC,EAAOD,KACnBxB,KAAK+B,KAAO,GACZ,IAAK,IAAInC,EAAI,EAAGA,EAAII,KAAKuB,KAAM3B,IAAK,CAClCI,KAAK+B,KAAKM,KAAK,IACf,IAAK,IAAIP,EAAI,EAAGA,EAAI9B,KAAKwB,KAAMM,IAC7B9B,KAAK+B,KAAKnC,GAAGyC,KAAKZ,EAAOM,KAAKnC,GAAGkC,UAIrC9B,KAAKuB,KAAOA,EACZvB,KAAKwB,KAAOA,EACZxB,KAAK+B,KAAOoB,MAAM5B,GACf6B,OACAjG,KAAI,kBAAMgG,MAAM3B,GAAM4B,KAAK,OAlB9B9B,EAiCGI,IAAM,SAAC2B,EAASC,GACrB,GAAID,EAAQ9B,OAAS+B,EAAQ/B,MAAQ8B,EAAQ7B,OAAS8B,EAAQ9B,KAI9D,OAAO,IAAIF,EAAO+B,EAAQ9B,KAAM8B,EAAQ7B,MAAMrE,KAC5C,SAACoF,EAAG3C,EAAGkC,GAAP,OAAauB,EAAQtB,KAAKnC,GAAGkC,GAAKwB,EAAQvB,KAAKnC,GAAGkC,MAJlDH,QAAQC,IAAI,uCAnCZN,EAsDGU,IAAM,SAACqB,EAASC,GACrB,GAAID,EAAQ9B,OAAS+B,EAAQ/B,MAAQ8B,EAAQ7B,OAAS8B,EAAQ9B,KAI9D,OAAO,IAAIF,EAAO+B,EAAQ9B,KAAM8B,EAAQ7B,MAAMrE,KAC5C,SAACoF,EAAG3C,EAAGkC,GAAP,OAAauB,EAAQtB,KAAKnC,GAAGkC,GAAKwB,EAAQvB,KAAKnC,GAAGkC,MAJlDH,QAAQC,IAAI,4CAxDZN,EA2EGW,IAAM,SAACoB,EAASC,GACrB,GAAID,EAAQ7B,OAAS8B,EAAQ/B,KAM7B,OAAO,IAAID,EAAO+B,EAAQ9B,KAAM+B,EAAQ9B,MAAMrE,KAAI,SAACoF,EAAG3C,EAAGkC,GAEvD,IADA,IAAIyB,EAAM,EACDC,EAAI,EAAGA,EAAIH,EAAQ7B,KAAMgC,IAChCD,GAAOF,EAAQtB,KAAKnC,GAAG4D,GAAKF,EAAQvB,KAAKyB,GAAG1B,GAE9C,OAAOyB,KAVP5B,QAAQC,IACN,qEA9EFN,EAsGGmC,UAAY,SAAChC,GAClB,OAAO,IAAIH,EAAOG,EAAOD,KAAMC,EAAOF,MAAMpE,KAC1C,SAACoF,EAAG3C,EAAGkC,GAAP,OAAaL,EAAOM,KAAKD,GAAGlC,OAxG5B0B,EA4GGoC,gBAAkB,SAACtB,GACxB,OAAO,IAAId,EAAOc,EAAIuB,OAAQ,GAAGxG,KAAI,SAACoF,EAAG3C,GAAJ,OAAUwC,EAAIxC,OA7GjD0B,EAuIGnE,IAAM,SAACsE,EAAQe,GACpB,OAAO,IAAIlB,EAAOG,EAAOF,KAAME,EAAOD,MAAMrE,KAAI,SAACoF,EAAG3C,EAAGkC,GAAP,OAC9CU,EAAKf,EAAOM,KAAKnC,GAAGkC,GAAIlC,EAAGkC,OAyBlBR,QC7JFsC,EAAb,kCAAaA,EAMJC,GAAK,SAACC,GACX,OAAOxC,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAS,GAAK,EAAI/F,KAAKgG,KAAKD,QAPxCH,EAeJK,WAAa,SAACH,GACnB,IAAMI,EAAUN,EAAkBC,GAAGC,GACrC,OAAOI,EAAQjC,IAAIX,EAAOnE,IAAI+G,GAAS,SAACC,GAAD,OAAS,EAAIA,OAOjD,IAAMC,EAAb,kCAAaA,EAMJP,GAAK,SAACC,GACX,OAAOxC,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAS/F,KAAKiD,IAAI,EAAG8C,OAPjCK,EAeJH,WAAa,SAACH,GACnB,OAAOxC,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,MAO1C,IAAMM,EAAb,kCAAaA,EAMJR,GAAK,SAACC,GACX,OAAOxC,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAIA,EAAM,IAAOA,MAP7CM,EAeJJ,WAAa,SAACH,GACnB,OAAOxC,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAUA,EAAM,EAAI,EAAI,QAO1C,IAAMO,EAAb,kCAAaA,EAMJT,GAAK,SAACC,GAEX,IADA,IAAIP,EAAM,EACDgB,EAAI,EAAGA,EAAIT,EAAEvC,KAAMgD,IAC1BhB,GAAOvF,KAAKgG,IAAIF,EAAE/B,KAAKwC,GAAG,IAE5B,OAAOjD,EAAOnE,IAAI2G,GAAG,SAACC,GAAD,OAAS/F,KAAKgG,IAAID,GAAOR,MAXrCe,EAmBJL,WAAa,SAACH,GACnB,IAAMU,EAAUF,EAAkBT,GAAGC,GACrC,OAAOU,EAAQvC,IAAIX,EAAOnE,IAAIqH,GAAS,SAACL,GAAD,OAAS,EAAIA,OAOjD,IAAMM,EAAb,kCAAaA,EAOJZ,GAAK,SAACa,EAAGC,GAGd,IAFA,IAAMC,EAAatD,EAAOU,IAAI0C,EAAGC,GAC7BE,EAAO,EACFN,EAAI,EAAGA,EAAIK,EAAWrD,KAAMgD,IACnC,IAAK,IAAIO,EAAI,EAAGA,EAAIF,EAAWpD,KAAMsD,IACnCD,GAAQ,YAAMD,EAAW7C,KAAKwC,GAAGO,GAAM,GAG3C,OAAOD,GAfEJ,EA0BJM,YAAc,SAACjB,EAAGY,EAAGC,EAAGK,GAE7B,OAD2B1D,EAAOU,IAAI0C,EAAGC,GACf1C,IAAI+C,EAAyBf,WAAWH,KAItE,IAAMmB,EAAO,SAAG,IAAO,KAKVC,EAAb,kCAAaA,EAOJrB,GAAK,SAACa,EAAGC,GACd,IAAMQ,EAAS7D,EAAOW,IACpBX,EAAOmC,UAAUkB,GACjBrD,EAAOnE,IAAIuH,GAAG,SAACP,GAEb,OAAOnG,KAAK4D,IAAIuC,EAAMc,OAGpBG,EAAU9D,EAAOW,IACrBX,EAAOmC,UAAUnC,EAAOnE,IAAIwH,GAAG,SAACU,GAAD,OAAS,EAAIA,MAC5C/D,EAAOnE,IAAIuH,GAAG,SAACP,GAEb,OAAOnG,KAAK4D,IAAI,EAAIuC,EAAMc,OAG9B,QAASE,EAAOpD,KAAK,GAAG,GAAKqD,EAAQrD,KAAK,GAAG,KAtBpCmD,EAiCJH,YAAc,SAACjB,EAAGY,EAAGC,EAAGK,GAO7B,OAN2B1D,EAAOU,IAAI0C,EAAGC,GAAG1C,IAC1CX,EAAOnE,IAAIuH,GAAG,SAACP,GAEb,OAAO,GAAKA,GAAO,EAAIA,GAAOc,OAGRhD,IAAI+C,EAAyBf,WAAWH,KAS/D,IAAMwB,EAAU,SAAClD,GACtB,IAAK,IAAIxC,EAAIwC,EAAIuB,OAAS,EAAG/D,EAAI,EAAGA,IAAK,CACvC,IAAM2F,EAAcvH,KAAKwH,MAAMxH,KAAK0E,UAAY9C,EAAI,IAC9C6F,EAAOrD,EAAIxC,GACjBwC,EAAIxC,GAAKwC,EAAImD,GACbnD,EAAImD,GAAeE,EAErB,OAAOrD,GCpLHsD,EAMJ,WAAYC,EAAOC,GAAgB,IAAD,OAChC,GADgC,yBA0DlCC,YAAc,SAAClG,GAGb,IAFA,IAAImG,EAASnG,EAEJC,EAAI,EAAGA,EAAI,EAAKmG,UAAY,EAAGnG,IAAK,CAC3C,IAAMoG,EAAO,EAAKC,OAAOrG,GACnBsG,EAAS,EAAKC,QAAQvG,GAGtBkE,EAAIxC,EAAOW,IAAIiE,EAAQJ,GAC7BhC,EAAEpC,IAAIsE,GACNF,EACElG,IAAM,EAAKmG,UAAY,EACnB,EAAKf,yBAAyBnB,GAAGC,GACjC,EAAKsC,yBAAyBvC,GAAGC,GAGzC,OAAOgC,EAAO3D,WA1EkB,KAsFlCkE,0BAA4B,SAC1BC,EACAC,EACAC,EACAC,EACAC,GAOA,IALI,IADJC,EACG,uDADS,KAGNC,EAAmBN,EAAc3C,OAG9B/D,EAAI,EAAGA,EAAI2G,EAAQ3G,IAAK,CAE/B0F,EAAQgB,GAIR,IADA,IAAMO,EAAc,GACX/E,EAAI,EAAGA,EAAI8E,EAAkB9E,GAAK0E,EAAe,CAKxD,IAHA,IAAMM,EAAY,GAGTtD,EAAI1B,EAAG0B,EAAI1B,EAAI0E,EAAehD,IACrCsD,EAAUzE,KAAKiE,EAAc9C,IAE/BqD,EAAYxE,KAAKyE,GAInB,IAAK,IAAIhF,EAAI,EAAGA,EAAI+E,EAAYlD,OAAQ7B,IAAK,CAC3C,EAAKiF,gBACHF,EAAY/E,GACZ2E,EACAC,EACAE,GAqBAjF,QAAQC,IACN,wBAA0BE,EAAI,GAAK,IAAM+E,EAAYlD,QAsB3D,GAAkB,OAAdgD,EAAoB,CACtB,IAAMK,EAAW,EAAKA,SAASL,GAC/BhF,QAAQC,IACN,kBACGhC,EAAI,GACL,IACA2G,EACA,KACAS,EACA,IACAL,EAAUhD,OACV,KACC,IAAMqD,EAAYL,EAAUhD,OAC7B,KA1LW,IAQa,KAmMlCoD,gBAAkB,SAChBD,EACAL,EACAC,EACAE,GAGA,IAFG,EAEGK,EAAiB,EAAKC,oBAAoB,EAAKjB,QAC/CkB,EAAkB,EAAKD,oBAAoB,EAAKf,SAHnD,cAMsBW,GANtB,IAMH,2BA0BE,IA1BmC,IAA5BM,EAA2B,QAC5BzH,EAAQyH,EAAa,GACrBC,EAAgBD,EAAa,GAC7BE,EAAgB,EAAKC,cAAc5H,EAAO0H,GAC1CG,EAAsBF,EAAc,GACpCG,EAAuBH,EAAc,GAqBlC1H,EAAI,EAAGA,EAAI,EAAKmG,UAAY,EAAGnG,IACtCqH,EAAerH,GAAG8B,IAAI8F,EAAoB5H,IAC1CuH,EAAgBvH,GAAG8B,IAAI+F,EAAqB7H,IAlC7C,8BAuCH,IAAK,IAAIA,EAAI,EAAGA,EAAI,EAAKmG,UAAY,EAAGnG,IAAK,CAC3C,IAAM8H,EAAsBjB,EAAeK,EAAUnD,OAGrD,EAAKsC,OAAOrG,GAAGoC,IAAIiF,EAAerH,GAAGqC,IAAIyF,IAGzC,EAAKvB,QAAQvG,GAAGqC,IACd,EAAIwE,GAAgBC,EAAiBE,IAIvC,EAAKT,QAAQvG,GAAGoC,IAAImF,EAAgBvH,GAAGqC,IAAIyF,MA3Pb,KAqQlCH,cAAgB,SAAC5H,EAAO0H,GACtB,IAAMJ,EAAiB,EAAKC,oBAAoB,EAAKjB,QAC/CkB,EAAkB,EAAKD,oBAAoB,EAAKf,SAGhDwB,EAAK,GACLC,EAAc,CAACjI,GACrB,EAAKkI,oBAAoBF,EAAIC,GAG7B,IAAM7C,EAAc,EAAKF,KAAKE,YAC5B4C,EAAGA,EAAGhE,OAAS,GACfiE,EAAYA,EAAYjE,OAAS,GACjC0D,EACA,EAAKrC,0BAIPiC,EAAeA,EAAetD,OAAS,GAAKoB,EAG5CoC,EAAgBA,EAAgBxD,OAAS,GAAKrC,EAAOW,IACnD8C,EACAzD,EAAOmC,UAAUmE,EAAYA,EAAYjE,OAAS,KAKpD,IADA,IAAImE,EAAc/C,EACTnF,EAAI,EAAGA,EAAI,EAAKmG,UAAWnG,IAAK,CAEvC,IAAMmI,EAAuBzG,EAAOmC,UAClC,EAAK0C,QAAQ,EAAKA,QAAQxC,OAAS/D,EAAI,IAEnCoI,EAAqC,EAAK5B,yBAAyBnC,WACvE0D,EAAGA,EAAGhE,OAAS/D,IAEjBkI,EAAcxG,EAAOW,IAAI8F,EAAsBD,GAAa7F,IAC1D+F,GAIFf,EAAeA,EAAetD,OAAS/D,GAAKkI,EAG5CX,EAAgBA,EAAgBxD,OAAS/D,GAAK0B,EAAOW,IACnD6F,EACAxG,EAAOmC,UAAUmE,EAAYA,EAAYjE,OAAS/D,EAAI,KAI1D,MAAO,CAACqH,EAAgBE,IAvTQ,KA+TlCU,oBAAsB,SAACF,EAAIC,GACzB,IAAK,IAAIhI,EAAI,EAAGA,EAAI,EAAKmG,UAAY,EAAGnG,IAAK,CAC3C,IAAMoG,EAAO,EAAKC,OAAOrG,GACnBsG,EAAS,EAAKC,QAAQvG,GAGtBkE,EAAIxC,EAAOW,IAAIiE,EAAQ0B,EAAYhI,IACzCkE,EAAEpC,IAAIsE,GACN2B,EAAGtF,KAAKyB,GAER,IAAMY,EACJ9E,IAAM,EAAKmG,UAAY,EACnB,EAAKf,yBAAyBnB,GAAGC,GACjC,EAAKsC,yBAAyBvC,GAAGC,GACvC8D,EAAYvF,KAAKqC,KA7Ua,KAsVlCwC,oBAAsB,SAACpG,GACrB,IADgC,EAC1BmH,EAAW,GADe,cAEPnH,GAFO,IAEhC,2BAAiC,CAAC,IAAzBoH,EAAwB,QACzBC,EAAiB,IAAI7G,EAAO4G,EAAa3G,KAAM2G,EAAa1G,MAClEyG,EAAS5F,KAAK8F,IAJgB,8BAMhC,OAAOF,GA5VyB,KAoWlCjB,SAAW,SAACL,GACV,IADwB,EACpByB,EAAQ,EADY,cAGHzB,GAHG,IAGxB,2BAAgC,CAAC,IAAxB0B,EAAuB,QACxB1I,EAAQ0I,EAAS,GACjBC,EAAY,EAAKzC,YAAYlG,GAC7B4I,EAAmBF,EAAS,GAAGlG,UACfmG,EAAUE,QAAQxK,KAAKiD,IAAL,MAAAjD,KAAI,YAAQsK,OACvBC,EAAiBC,QAC5CxK,KAAKiD,IAAL,MAAAjD,KAAI,YAAQuK,MAKZH,KAdoB,8BAkBxB,OAAOA,GAtXyB,KA+XlCK,aAAe,SAACC,EAAOhC,GACrB,IADwC,EACpC7B,EAAO,EACPuD,EAAQ,EAF4B,cAKvBM,GALuB,IAKxC,2BAAwB,CAAC,IAAhB3G,EAAe,QAChBpC,EAAQoC,EAAK,GACbsF,EAAgBtF,EAAK,GAErBuG,EAAY,EAAKzC,YAAYlG,GAC7B4I,EAAmBlB,EAAclF,UACjBmG,EAAUE,QAAQxK,KAAKiD,IAAL,MAAAjD,KAAI,YAAQsK,OACvBC,EAAiBC,QAC5CxK,KAAKiD,IAAL,MAAAjD,KAAI,YAAQuK,MAKZH,IAIFvD,GACE,EAAKA,KAAKhB,GAAGvC,EAAOoC,gBAAgB4E,GAAYjB,GAChDqB,EAAM/E,OAGR,IAtBsB,EAsBlBgF,EAAiB,EAtBC,cAuBH,EAAKxC,SAvBF,IAuBtB,2BACE,IADgC,IAAzBD,EAAwB,QACtB3B,EAAI,EAAGA,EAAI2B,EAAO3E,KAAMgD,IAC/B,IAAK,IAAIO,EAAI,EAAGA,EAAIoB,EAAO1E,KAAMsD,IAC/B6D,GAAc,SAAIzC,EAAOnE,KAAKwC,GAAGO,GAAM,GA1BvB,8BA8BtBD,GAAe6B,EAAiBgC,EAAM/E,OAA9B,GAAwCgF,GAnCV,8BAsCxC,MAAO,CAAC9D,EAAMuD,IArakB,KAgblCQ,cAAgB,SAACX,EAAUnH,EAAQnB,EAAO0H,GAKxC,IAJA,IAAMwB,EAAaxB,EAAclF,UAC3B2G,EAAU9K,KAAK+K,IAAI,IAAK,GACxBC,EAAa,EAAK9B,oBAAoBe,GAEnCrI,EAAI,EAAGA,EAAIoJ,EAAWrF,OAAQ/D,IACrC,IAAK,IAAI2E,EAAI,EAAGA,EAAIyE,EAAWpJ,GAAG2B,KAAMgD,IACtC,IAAK,IAAIO,EAAI,EAAGA,EAAIkE,EAAWpJ,GAAG4B,KAAMsD,IAAK,CAE3C,IAAMmE,EAAWnI,EAAOlB,GAAGmC,KAAKwC,GAAGO,GAGnChE,EAAOlB,GAAGmC,KAAKwC,GAAGO,GAAKmE,EAAWH,EAGlC,IAFA,IAAMI,EAAa,EAAKrD,YAAYlG,GAChCwJ,EAAW,EACNrH,EAAI,EAAGA,EAAIoH,EAAWvF,OAAQ7B,IACrCqH,GAAY,GAAMnL,KAAK+K,IAAIF,EAAW/G,GAAKoH,EAAWpH,GAAI,GAI5DhB,EAAOlB,GAAGmC,KAAKwC,GAAGO,GAAKmE,EAAWH,EAGlC,IAFA,IAAMM,EAAc,EAAKvD,YAAYlG,GACjC0J,EAAY,EACPvH,EAAI,EAAGA,EAAIsH,EAAYzF,OAAQ7B,IACtCuH,GAAa,GAAMrL,KAAK+K,IAAIF,EAAW/G,GAAKsH,EAAYtH,GAAI,GAI9D,IAAMwH,GAAiBH,EAAWE,IAAc,EAAIP,GACpDE,EAAWpJ,GAAGmC,KAAKwC,GAAGO,GAAKwE,EAG3BxI,EAAOlB,GAAGmC,KAAKwC,GAAGO,GAAKmE,EAU7B,IALA,IAAIM,EAAW,EACXC,EAAiB,EACjBC,EAAW,EAGN7J,EAAI,EAAGA,EAAIoJ,EAAWrF,OAAQ/D,IACrC,IAAK,IAAI2E,EAAI,EAAGA,EAAIyE,EAAWpJ,GAAG2B,KAAMgD,IACtC,IAAK,IAAIO,EAAI,EAAGA,EAAIkE,EAAWpJ,GAAG4B,KAAMsD,IAAK,CAC3C,IAAM4E,EAAczB,EAASrI,GAAGmC,KAAKwC,GAAGO,GAClCwE,EAAgBN,EAAWpJ,GAAGmC,KAAKwC,GAAGO,GAE5CyE,GAAYvL,KAAK+K,IAAIW,EAAa,GAClCF,GAAkBxL,KAAK+K,IAAIO,EAAe,GAC1CG,GAAYzL,KAAK+K,IAAIO,EAAgBI,EAAa,GAKxD,OACE1L,KAAK8E,KAAK2G,IAAazL,KAAK8E,KAAK0G,GAAkBxL,KAAK8E,KAAKyG,KAve3D3D,EAAe,CAEjB5F,KAAK+F,UAAYH,EAAcD,MAAMhC,OACrC3D,KAAK2F,MAAQ,GAHI,oBAIAC,EAAcD,OAJd,IAIjB,2BAAsC,CAAC,IAA9BgE,EAA6B,QACpC3J,KAAK2F,MAAMtD,KAAKsH,IALD,8BASjB3J,KAAKiG,OAAS,GATG,oBAUAL,EAAcK,QAVd,IAUjB,2BAAuC,CAAC,IAA/BD,EAA8B,QACrChG,KAAKiG,OAAO5D,KAAK,IAAIf,EAAO,KAAM,KAAM0E,KAXzB,8BAejBhG,KAAKmG,QAAU,GAfE,oBAgBEP,EAAcO,SAhBhB,IAgBjB,2BAA0C,CAAC,IAAlCD,EAAiC,QACxClG,KAAKmG,QAAQ9D,KAAK,IAAIf,EAAO,KAAM,KAAM4E,KAjB1B,mCAmBZ,CACLlG,KAAK+F,UAAYJ,EAAMhC,OACvB3D,KAAK2F,MAAQA,EAGb3F,KAAKiG,OAAS,GACd,IAAK,IAAIrG,EAAI,EAAGA,EAAI+F,EAAMhC,OAAQ/D,IAAK,CACrC,IAAMoG,EAAO,IAAI1E,EAAOqE,EAAM/F,GAAI,GAGlCoG,EAAK7I,KAAI,SAACyM,GAAD,OAAO,KAEhB5J,KAAKiG,OAAO5D,KAAK2D,GAInBhG,KAAKmG,QAAU,GACf,IAjBK,eAiBIvG,GACP,IAAMsG,EAAS,IAAI5E,EAAOqE,EAAM/F,GAAI+F,EAAM/F,EAAI,IAG9CsG,EAAOvD,kBACPuD,EAAO/I,KAAI,SAAC0M,GAAD,OAAOA,EAAI7L,KAAK8E,KAAK,EAAI6C,EAAM/F,EAAI,OAE9C,EAAKuG,QAAQ9D,KAAK6D,IAPXtG,EAAI,EAAGA,EAAI+F,EAAMhC,OAAQ/D,IAAM,EAA/BA,GAWXI,KAAKoG,yBAA2BhC,EAChCpE,KAAKgF,yBAA2BV,EAChCtE,KAAK6E,KAAOK,GAxDVQ,EAwfGoE,qBAAuB,SAACxD,EAAeyD,EAAepD,GAW3D,IAVA,IAAMqD,EAAmB,CAAC,EAAG,GAAI,GAAI,GAAI,KACnCC,EAAsB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACnDC,EAAwB,CAAC,IAAM,IAAM,GAAK,GAAK,EAAG,EAAG,IACvDC,EAAgB,EAChBC,EAAmB,IACnBC,EAAqB,IACrBC,EAAe,EACfC,EAAc,KAGT3K,EAAI,EAAGA,EAAIoK,EAAiBrG,OAAQ/D,IAC3C,IAAK,IAAIkC,EAAI,EAAGA,EAAImI,EAAoBtG,OAAQ7B,IAC9C,IAAK,IAAI0B,EAAI,EAAGA,EAAI0G,EAAsBvG,OAAQH,IAAK,CACrD,IAAMgH,EAAeR,EAAiBpK,GAChC6K,EAAkBR,EAAoBnI,GACtC4I,EAAoBR,EAAsB1G,GAG1CmH,EAAa,IAAIjF,EAAc,CAAC,IAAK,GAAI,KAC/CiF,EAAWtE,0BACTC,EACA,EACAkE,EACAC,EACAC,GAIF,IAAME,EAAmBD,EAAW3D,SAAS+C,GAGzCa,EAAmBN,IACrBH,EAAgBK,EAChBJ,EAAmBK,EACnBJ,EAAqBK,EACrBJ,EAAeM,EACfL,EAAcI,GAMtBhJ,QAAQC,IAAI,yBAA2BuI,GACvCxI,QAAQC,IAAI,uBAAyBwI,GACrCzI,QAAQC,IAAI,wBAA0ByI,GACtC1I,QAAQC,IACN,8BACE0I,EACA,IACAP,EAAcpG,OACd,KACC,IAAM2G,EAAgBP,EAAcpG,OACrC,KAIJ,IAAMkH,EAAyBN,EAAYvD,SAASL,GACpDhF,QAAQC,IACN,kBACEiJ,EACA,IACAlE,EAAUhD,OACV,KACC,IAAMkH,EAA0BlE,EAAUhD,OAC3C,KAIJhC,QAAQC,IAAI,gBAAiBkJ,KAAKC,UAAUR,KAIjC7E,Q,iCCxjBAsF,E,8EAAf,WAAwBC,GAAxB,iCAAAvG,EAAA,sEACuBwG,MAAMD,GAD7B,cACME,EADN,gBAEqBA,EAASC,cAF9B,UAEMC,EAFN,OAGMC,EAAc,EACdC,EAAa,IAAIC,SAASH,EAAQ,EAAG,EAAIC,GAM1B,QALfG,EAAU,IAAItI,MAAM8H,EAAMK,GAC3BlI,OACAjG,KAAI,SAACoF,EAAG3C,GAAJ,OAAU2L,EAAWG,UAAU,EAAI9L,GAAG,OAGjC,GAVd,iBAWIgB,EAAO,QACP+K,EAAa,EACbL,EAAc,EAblB,2BAc4B,OAAfG,EAAQ,GAdrB,iBAeI7K,EAAO,QACP+K,EAAaF,EAAQ,GAAKA,EAAQ,GAhBtC,8BAkBU,IAAIG,MAAM,qBAAuBH,EAAQ,IAlBnD,WAqBM1J,EAAO,IAAI8J,WAAWR,EAAsB,EAAdC,GACrB,UAAT1K,EAtBN,iBAwBI,IADIkL,EAAU,GACLlM,EAAI,EAAGA,EAAI6L,EAAQ,GAAI7L,IAC9BkM,EAAQzJ,KAAKN,EAAKgK,SAASJ,EAAa/L,EAAG+L,GAAc/L,EAAI,KAzBnE,OA2BI+B,QAAQC,IAAI,eAAgBqJ,GA3BhC,kBA4BWa,GA5BX,eA8BEnK,QAAQC,IAAI,eAAgBqJ,GA9B9B,kBA+BSlJ,GA/BT,6C,sBAkCeiK,MAtDf,SAAmBC,GACjB,IAAIC,EAAQ,GACRC,EAAQ,CACVC,eAAgB,4BAChBC,eAAgB,4BAChBC,WAAY,2BACZC,WAAY,4BAEd,OAAOC,QAAQC,IACbC,OAAOC,KAAKR,GAAOhP,IAAnB,iBAAAuP,OAAA,IAAAA,CAAA,UAAuB,WAAOzB,GAAP,SAAAvG,EAAA,sEACDsG,EAASmB,EAAMlB,IADd,OACrBiB,EAAMjB,GADe,kDAAvB,wDAGA2B,MAAK,kBAAMX,EAASC,O,yBCClBjH,EAAO,SAAG,IAAO,KAuXR4H,E,kDAnXb,WAAY3O,GAAQ,IAAD,8BACjB,cAAMA,IAwBR4O,iBAAmB,gBACUC,IAAvB,EAAKnH,gBACP,EAAKoH,SAAS,CAAEC,YAAY,IAE5B,EAAKC,MAAQC,YAAW,YAlCa,IAqCjC,EAAKvH,cAAcwH,kCAElB,EAAKC,mBAEN,EAAKC,aAEH,EAAKC,kBAIP,EAAKF,kBAAmB,GAG1B1L,QAAQC,IAAI,qBACZ,EAAKgE,cAAcS,0BACjB,EAAKC,cAAckH,MAAM,EAAG,EAAKC,MAAMC,cACvC,EACA,GACA,IACA,EACA,EAAK/G,WASP,EAAKqG,UAAS,SAACW,GAAD,MAAgB,CAC5BpH,OAAQoH,EAAUpH,OAAS,EAC3B0G,YAAY,MAGdW,aAAa,EAAKV,SACjB,OAnEY,EAmGnBW,UAAY,SAACC,EAAQC,GAGnB,IAFA,IAAMrF,EAAQ,GAEL9I,EAAI,EAAGA,EAAIkO,EAAOnK,OAAQ/D,IAAK,CAKtC,IAJA,IAAMoO,EAAWF,EAAOlO,GAClBqO,EAAiBF,EAAOnO,GACxBiJ,EAAa,GAEV/G,EAAI,EAAGA,EAAI,GAAIA,IAClBmM,IAAmBnM,EACrB+G,EAAWxG,KAAK,GAEhBwG,EAAWxG,KAAK,GAIpBqG,EAAMrG,KAAK,CACTf,EAAOoC,gBAAgBsK,GACvB1M,EAAOoC,gBAAgBmF,KAI3B,OAAOH,GAzHU,EA4HnB6E,gBAAkB,WAEhB,IAAK,EAAK3H,cAAcnI,eAAe,gBAAiB,CACtD,IAAMyQ,EAAO,IAAI5M,EAAO,IAAK,GACvB6M,EAAM,IAAI7M,EAAO,IAAK,GAG5BK,QAAQC,IAAI,kCAL0C,oBAM7B,EAAK0E,eANwB,IAMtD,2BAA6C,CAAC,IAArCc,EAAoC,QAC3C8G,EAAKxM,IAAI0F,EAAa,KAP8B,8BAWtD8G,EAAK/Q,KAAI,SAAC0E,GAAD,OAAOA,EAAI,EAAKyE,cAAc3C,UAGvChC,QAAQC,IAAI,gDAd0C,oBAe7B,EAAK0E,eAfwB,IAetD,2BAA6C,CAAC,IAArCc,EAAoC,QAC3C+G,EAAIzM,IAAIJ,EAAOU,IAAIoF,EAAa,GAAI8G,GAAM/Q,KAAI,SAAC0E,GAAD,gBAAOA,EAAK,QAhBN,8BAoBtDsM,EAAIhR,KAAI,SAAC0E,GAAD,OAAO7D,KAAK8E,KAAKjB,EAAI,EAAKyE,cAAc3C,WAGhD,EAAKiC,cAAcwI,aAAeF,EAClC,EAAKtI,cAAcyI,YAAcF,EAInC,IAAMD,EAAO,EAAKtI,cAAcwI,aAC1BD,EAAM,EAAKvI,cAAcyI,YAG/B1M,QAAQC,IAAI,+BACZ,IAAK,IAAIhC,EAAI,EAAGA,EAAI,EAAK0G,cAAc3C,OAAQ/D,IAC7C,EAAK0G,cAAc1G,GAAG,GACnBoC,IAAIkM,GACJhM,IAAIZ,EAAOnE,IAAIgR,GAAK,SAACtM,GAAD,OAAOA,EAAIoD,MAcpCtD,QAAQC,IAAI,8BACZ,IAAK,IAAIhC,EAAI,EAAGA,EAAI,EAAK+G,UAAUhD,OAAQ/D,IACzC,EAAK+G,UAAU/G,GAAG,GAAGoC,IAAIkM,GAAMhM,IAAIZ,EAAOnE,IAAIgR,GAAK,SAACtM,GAAD,OAAOA,EAAIoD,MAGhE,EAAKW,cAAcwH,kCAAmC,GArLrC,EAwLnBkB,cAAgB,WAAM,oBAEK,EAAKhI,eAFV,IAEpB,2BAA6C,SAC9B,GAAGpE,IAAI,MAHF,kDAcC,EAAKyE,WAdN,IAcpB,2BAAqC,SAC1B,GAAGzE,IAAI,MAfE,8BAkBpB,EAAK0D,cAAcwH,kCAAmC,GA1MrC,EA6MnBmB,iBAAmB,WACjB,QAA2BxB,IAAvB,EAAKnH,cAA6B,CACpC,IAAMjG,EAAQ2B,EAAOoC,gBAAgB,EAAK+J,MAAM3N,QAG5C,EAAK8F,cAAcwH,iCACrBzN,EACGqC,IAAI,EAAK4D,cAAcwI,cACvBlM,IAAIZ,EAAOnE,IAAI,EAAKyI,cAAcyI,aAAa,SAACxM,GAAD,OAAOA,EAAIoD,MAE7DtF,EAAMuC,IAAI,KAGZ,IAAMoG,EAAY,EAAK1C,cAAcC,YAAYlG,GAC3C6O,EAAQlG,EAAUE,QAAQxK,KAAKiD,IAAL,MAAAjD,KAAI,YAAQsK,KAG5C,EAAK0E,SAAS,CACZwB,QACAlG,gBAhOa,EAqOnBmG,iBAAmB,WACjB,EAAKzB,SAAS,CAAErO,gBAAgB,KAtOf,EAyOnB+P,YAAc,WACZ,EAAK1B,SAAS,CACZlN,OAAQqD,MAAM,KAAKC,KAAK,GACxBzE,gBAAgB,EAChB6P,MAAO,GACPlG,UAAW,MA9OI,EAkPnBqG,WAAa,SAAC7O,GACZ,EAAKkN,SAAS,CACZlN,YApPe,EAwPnB8O,mBAAqB,WACnB,EAAK5B,UACH,SAACW,GAAD,MAAgB,CAAEkB,eAAgBlB,EAAUkB,kBAC5C,WACE,EAAKjJ,cAAgB,EAAK6H,MAAMoB,cAC5B,IAAInJ,EAAc,KAAMoJ,GACxB,IAAIpJ,EAAc,CAAC,IAAK,GAAI,KAChC,EAAKsH,SAAS,CAAEzG,OAAQ,QA/PX,EAoQnBwI,mBAAqB,SAAClO,GACpB,EAAKmM,SAAS,CAAEU,aAAcsB,OAAOnO,EAAEC,OAAOP,UAnQ9C,EAAKkN,MAAQ,CACXlH,OAAQ,EACRiI,MAAO,GACP1O,OAAQqD,MAAM,KAAKC,KAAK,GACxBzE,gBAAgB,EAChBsO,YAAY,EACZ4B,eAAe,EACfvG,UAAW,GACXoF,aAAc,KAGhB,EAAKuB,eAAgB,EACrBjD,GAAU,SAACjK,GACT,EAAKmK,MAAQnK,EACb,EAAK6D,cAAgB,IAAIF,EAAc,KAAMoJ,GAC7CnN,QAAQC,IAAI,uBAjBG,E,yDAwEjBD,QAAQC,IAAI,4BACZ5B,KAAKsG,cAAgBtG,KAAK6N,UACxB7N,KAAKkM,MAAME,eAAeoB,MAAM,EAlFjB,KAmFfxN,KAAKkM,MAAMG,eAAemB,MAAM,EAnFjB,MAoGjB7L,QAAQC,IAAI,2BACZ5B,KAAK2G,UAAY3G,KAAK6N,UACpB7N,KAAKkM,MAAMI,WAAWkB,MAAM,EApGd,KAqGdxN,KAAKkM,MAAMK,WAAWiB,MAAM,EArGd,Q,+BA8QR,IAAD,OACD0B,EAAgBlP,KAAKyN,MAAMnF,UAAUnL,KAAI,SAACgS,EAAaC,GAAd,OAC7C,wBAAI9R,IAAK8R,GACNA,EADH,MAC4B,IAAdD,GAAmBE,QAAQ,GADzC,QAKF,OACE,yBAAK1O,UAAU,kCACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAO3D,KAAK,wCAGhB,yBAAK2D,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CACE3D,KACE,kYAKR,yBAAK2D,UAAU,mCACb,yBAAKA,UAAU,oCACb,2BACEC,KAAK,WACLD,UAAU,uBACVR,GAAG,eACHmP,QAAStP,KAAKyN,MAAMoB,cACpBzN,SAAUpB,KAAK4O,qBAEjB,2BAAOjO,UAAU,uBAAuB4O,QAAQ,gBAAhD,oCAKJ,yBAAK5O,UAAU,mCACb,yBAAKA,UAAU,gBACb,yBAAKA,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CACE1C,IAAK,IACLgD,IAAK,IACLC,KAAM,IACNC,aAAcnB,KAAKyN,MAAMC,aACzBvN,GAAG,eACHiB,SAAUpB,KAAK+O,uBAIrB,yBAAKpO,UAAU,OACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CAAO3D,KAAK,gBAAgBuD,MAAOP,KAAKyN,MAAMC,mBAKtD,yBAAK/M,UAAU,mCACb,yBAAKA,UAAU,2BACb,kBAAC,EAAD,CACEJ,MAAM,QACNC,aAAa,cACbC,UAAWT,KAAKyN,MAAMR,WACtBvM,QAASV,KAAK8M,oBAGlB,yBAAKnM,UAAU,2BACb,kBAAC,EAAD,CAAQJ,MAAM,QAAQG,QAASV,KAAKuO,oBAEtC,yBAAK5N,UAAU,2BACb,kBAAC,EAAD,CAAQJ,MAAM,QAAQG,QAASV,KAAKyO,qBAGxC,yBAAK9N,UAAU,YACb,yBAAKA,UAAU,OACb,kBAAC,EAAD,CACE5C,MAAO,IACPM,OAAQ,IACR0B,OAAQ,SAACD,GAAD,OAAY,EAAK6O,WAAW7O,IACpCnB,eAAgBqB,KAAKyN,MAAM9O,eAC3BC,QAASoB,KAAK0O,gBAIpB,yBAAK/N,UAAU,8BACb,yBAAKA,UAAU,kBACb,uCAAaX,KAAKyN,MAAMlH,SAE1B,yBAAK5F,UAAU,kBACb,sCAAYX,KAAKyN,MAAMe,SAG3B,yBAAK7N,UAAU,mCACb,yBAAKA,UAAU,OAAOuO,IAExB,kBAAC,IAAD,CACEM,KAAK,oEACLC,YAAY,OACZC,UAAU,UACV5O,OAAO,gB,GA7WCV,aCTEuP,QACW,cAA7BxR,OAAOyR,SAASC,UAEe,UAA7B1R,OAAOyR,SAASC,UAEhB1R,OAAOyR,SAASC,SAASC,MACvB,2D,YCXNC,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,SD4H3C,kBAAmBC,WACrBA,UAAUC,cAAcC,MAAMzD,MAAK,SAAA0D,GACjCA,EAAaC,kB","file":"static/js/main.973dbf97.chunk.js","sourcesContent":["import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Title = ({ text }) => {\r\n  return <h1>{text}</h1>;\r\n};\r\n\r\nTitle.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Title;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Description = ({ text }) => {\r\n  const addLineBreaks = string =>\r\n    string.split(\"\\n\").map((text, index) => (\r\n      <React.Fragment key={`${text}-${index}`}>\r\n        {text}\r\n        <br />\r\n      </React.Fragment>\r\n    ));\r\n\r\n  return <h5>{addLineBreaks(text)}</h5>;\r\n};\r\n\r\nDescription.propTypes = {\r\n  text: PropTypes.string\r\n};\r\n\r\nexport default Description;\r\n","import React, { Component } from \"react\";\r\nimport p5 from \"p5\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nclass Sketch extends Component {\r\n  componentDidMount() {\r\n    this.newSketch();\r\n    window.addEventListener(\"resize\", this.newSketch);\r\n  }\r\n\r\n  componentWillUnmount() {\r\n    window.removeEventListener(\"resize\", this.newSketch);\r\n  }\r\n\r\n  newSketch = () => {\r\n    if (this.hasOwnProperty(\"myp5\")) {\r\n      this.myp5.remove();\r\n    }\r\n\r\n    this.myp5 = new p5((sketch) => {\r\n      sketch.setup = () => {\r\n        let width = Math.min(this.props.width, window.innerWidth * 0.8);\r\n        let height = this.props.isSquare\r\n          ? width\r\n          : Math.min(this.props.height, window.innerHeight * 0.8);\r\n        sketch.createCanvas(width, height);\r\n        sketch.background(\"#d3d3d3\");\r\n      };\r\n\r\n      sketch.draw = () => {\r\n        if (this.props.clearRequested) {\r\n          sketch.background(\"#d3d3d3\");\r\n          this.props.onClear();\r\n        }\r\n      };\r\n\r\n      sketch.mouseDragged = () => {\r\n        if (withinCanvas()) {\r\n          sketch.strokeWeight(32);\r\n          sketch.stroke(0);\r\n          sketch.line(\r\n            sketch.pmouseX,\r\n            sketch.pmouseY,\r\n            sketch.mouseX,\r\n            sketch.mouseY\r\n          );\r\n          return false;\r\n        }\r\n      };\r\n\r\n      sketch.mouseReleased = () => {\r\n        if (withinCanvas()) {\r\n          let img = sketch.get();\r\n          img.resize(28, 28);\r\n          img.loadPixels();\r\n\r\n          let input = [];\r\n          for (let i = 0; i < 28 * 28; i++) {\r\n            let color = img.pixels[i * 4];\r\n\r\n            /*\r\n              MNIST is black background = 0 with white text = 255.\r\n              Sketch background is light gray = 211, so map it to black = 0.\r\n              Sketch drawing is black = 0, so map it to white = 255.\r\n              Normalization is delegated to the moment of guessing.\r\n            */\r\n            input[i] = color === 211 ? 0 : 255 - color;\r\n          }\r\n          this.props.onDraw(input);\r\n          return false;\r\n        }\r\n      };\r\n\r\n      const withinCanvas = () => {\r\n        return (\r\n          sketch.mouseX > 0 &&\r\n          sketch.mouseX < sketch.width &&\r\n          sketch.mouseY > 0 &&\r\n          sketch.mouseY < sketch.height\r\n        );\r\n      };\r\n    }, \"p5sketch\");\r\n  };\r\n\r\n  render() {\r\n    return <div id=\"p5sketch\"></div>;\r\n  }\r\n}\r\n\r\nSketch.defaultProps = {\r\n  width: 100,\r\n  height: 100,\r\n  isSquare: true,\r\n};\r\n\r\nSketch.propTypes = {\r\n  width: PropTypes.number,\r\n  height: PropTypes.number,\r\n  isSquare: PropTypes.bool,\r\n  onDraw: PropTypes.func,\r\n  clearRequested: PropTypes.bool,\r\n  onClear: PropTypes.func,\r\n};\r\n\r\nexport default Sketch;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Button = ({ value, loadingValue, isLoading, onClick }) => {\r\n  const handleOnClick = e => {\r\n    e.target.blur();\r\n    onClick();\r\n  };\r\n\r\n  const content = () => {\r\n    if (isLoading) {\r\n      return (\r\n        <React.Fragment>\r\n          <span className=\"spinner-grow spinner-grow-sm mr-2 mb-1\"></span>\r\n          {loadingValue}\r\n        </React.Fragment>\r\n      );\r\n    } else {\r\n      return value;\r\n    }\r\n  };\r\n\r\n  return (\r\n    <button\r\n      className=\"btn btn-primary btn-lg\"\r\n      type=\"button\"\r\n      onClick={handleOnClick}\r\n    >\r\n      {content()}\r\n    </button>\r\n  );\r\n};\r\n\r\nButton.propTypes = {\r\n  value: PropTypes.string,\r\n  loadingValue: PropTypes.string,\r\n  isLoading: PropTypes.bool,\r\n  onClick: PropTypes.func\r\n};\r\n\r\nexport default Button;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst RangeInput = ({ min, max, step, defaultValue, id, onChange }) => {\r\n  return (\r\n    <input\r\n      type=\"range\"\r\n      min={min}\r\n      max={max}\r\n      step={step}\r\n      defaultValue={defaultValue}\r\n      id={id}\r\n      onChange={onChange}\r\n    />\r\n  );\r\n};\r\n\r\nRangeInput.defaultProps = {\r\n  min: 0,\r\n  max: 1,\r\n  step: 1,\r\n  defaultValue: 0,\r\n  id: \"\"\r\n};\r\n\r\nRangeInput.propTypes = {\r\n  min: PropTypes.number,\r\n  max: PropTypes.number,\r\n  step: PropTypes.number,\r\n  defaultValue: PropTypes.number,\r\n  id: PropTypes.string,\r\n  onChange: PropTypes.func.isRequired\r\n};\r\n\r\nexport default RangeInput;\r\n","import React from \"react\";\r\nimport PropTypes from \"prop-types\";\r\n\r\nconst Label = ({ text, value }) => {\r\n  return (\r\n    <h5 className=\"text-break\">\r\n      {text}: {value}\r\n    </h5>\r\n  );\r\n};\r\n\r\nLabel.propTypes = {\r\n  text: PropTypes.string,\r\n  value: PropTypes.oneOfType([PropTypes.number, PropTypes.string])\r\n};\r\n\r\nexport default Label;\r\n","class Matrix {\r\n  constructor(rows, cols, matrix) {\r\n    if (matrix) {\r\n      // Deep copy\r\n      this.rows = matrix.rows;\r\n      this.cols = matrix.cols;\r\n      this.data = [];\r\n      for (let i = 0; i < this.rows; i++) {\r\n        this.data.push([]);\r\n        for (let j = 0; j < this.cols; j++) {\r\n          this.data[i].push(matrix.data[i][j]);\r\n        }\r\n      }\r\n    } else {\r\n      this.rows = rows;\r\n      this.cols = cols;\r\n      this.data = Array(rows)\r\n        .fill()\r\n        .map(() => Array(cols).fill(0));\r\n    }\r\n  }\r\n\r\n  add = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Add: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x + matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x + matrix);\r\n  };\r\n\r\n  static add = (matrix1, matrix2) => {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Add: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] + matrix2.data[i][j]\r\n    );\r\n  };\r\n\r\n  sub = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Subtract: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x - matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x - matrix);\r\n  };\r\n\r\n  static sub = (matrix1, matrix2) => {\r\n    if (matrix1.rows !== matrix2.rows || matrix1.cols !== matrix2.cols) {\r\n      console.log(\"Subtract: matrix dimensions must match.\");\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix1.cols).map(\r\n      (_, i, j) => matrix1.data[i][j] - matrix2.data[i][j]\r\n    );\r\n  };\r\n\r\n  mul = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Multiply: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x * matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x * matrix);\r\n  };\r\n\r\n  static mul = (matrix1, matrix2) => {\r\n    if (matrix1.cols !== matrix2.rows) {\r\n      console.log(\r\n        \"Multiply: first matrix's columns must match second matrix's rows\"\r\n      );\r\n      return;\r\n    }\r\n    return new Matrix(matrix1.rows, matrix2.cols).map((_, i, j) => {\r\n      let sum = 0;\r\n      for (let k = 0; k < matrix1.cols; k++) {\r\n        sum += matrix1.data[i][k] * matrix2.data[k][j];\r\n      }\r\n      return sum;\r\n    });\r\n  };\r\n\r\n  div = (matrix) => {\r\n    if (matrix instanceof Matrix) {\r\n      if (this.rows !== matrix.rows || this.cols !== matrix.cols) {\r\n        console.log(\"Division: matrix dimensions must match.\");\r\n        return;\r\n      }\r\n      return this.map((x, i, j) => x / matrix.data[i][j]);\r\n    }\r\n    return this.map((x) => x / matrix);\r\n  };\r\n\r\n  static transpose = (matrix) => {\r\n    return new Matrix(matrix.cols, matrix.rows).map(\r\n      (_, i, j) => matrix.data[j][i]\r\n    );\r\n  };\r\n\r\n  static vectorFromArray = (arr) => {\r\n    return new Matrix(arr.length, 1).map((_, i) => arr[i]);\r\n  };\r\n\r\n  toArray = () => {\r\n    const arr = [];\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        arr.push(this.data[i][j]);\r\n      }\r\n    }\r\n    return arr;\r\n  };\r\n\r\n  copy = () => {\r\n    return new Matrix(this.rows, this.cols).map((_, i, j) => this.data[i][j]);\r\n  };\r\n\r\n  map = (func) => {\r\n    for (let i = 0; i < this.rows; i++) {\r\n      for (let j = 0; j < this.cols; j++) {\r\n        this.data[i][j] = func(this.data[i][j], i, j);\r\n      }\r\n    }\r\n    return this;\r\n  };\r\n\r\n  static map = (matrix, func) => {\r\n    return new Matrix(matrix.rows, matrix.cols).map((_, i, j) =>\r\n      func(matrix.data[i][j], i, j)\r\n    );\r\n  };\r\n\r\n  randomize = () => {\r\n    return this.map(() => Math.random() * 2 - 1);\r\n  };\r\n\r\n  // Box-Muller Transform for normal distribution, mean = 0, variance = 1\r\n  randomizeNormal = () => {\r\n    return this.map(() => {\r\n      let u = 0;\r\n      let v = 0;\r\n      while (u === 0) u = Math.random();\r\n      while (v === 0) v = Math.random();\r\n      return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\r\n    });\r\n  };\r\n\r\n  print = () => {\r\n    console.table(this.data);\r\n    return this;\r\n  };\r\n}\r\n\r\nexport default Matrix;\r\n","import Matrix from \"./matrix\";\r\n\r\n/**\r\n * The sigmoid activation function and derivative.\r\n */\r\nexport class SigmoidActivation {\r\n  /**\r\n   * Returns the matrix mapped with sigmoid.\r\n   * @param {Matrix} z The matrix to apply the sigmoid function to\r\n   * @return {Matrix} The matrix mapped with sigmoid\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => 1 / (1 + Math.exp(-z_i)));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with sigmoid derivative.\r\n   * @param {Matrix} z The matrix to apply the sigmoid derivative function to\r\n   * @return {Matrix} The matrix mapped with sigmoid derivative\r\n   */\r\n  static derivative = (z) => {\r\n    const sigmoid = SigmoidActivation.fn(z);\r\n    return sigmoid.mul(Matrix.map(sigmoid, (a_i) => 1 - a_i));\r\n  };\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class ReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with ReLU.\r\n   * @param {Matrix} z The matrix to apply the ReLu function to\r\n   * @return {Matrix} The matrix mapped with ReLu\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => Math.max(0, z_i));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with ReLU derivative\r\n   */\r\n  static derivative = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0));\r\n  };\r\n}\r\n\r\n/**\r\n * The ReLU activation function and derivative.\r\n */\r\nexport class LeakyReLUActivation {\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLu function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLu\r\n   */\r\n  static fn = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? z_i : 0.01 * z_i));\r\n  };\r\n\r\n  /**\r\n   * Returns the matrix mapped with leaky ReLU derivative.\r\n   * @param {Matrix} z The matrix to apply the leaky ReLU derivative function to\r\n   * @return {Matrix} The matrix mapped with leaky ReLU derivative\r\n   */\r\n  static derivative = (z) => {\r\n    return Matrix.map(z, (z_i) => (z_i > 0 ? 1 : 0.01));\r\n  };\r\n}\r\n\r\n/**\r\n * The softmax activation function and derivative.\r\n */\r\nexport class SoftmaxActivation {\r\n  /**\r\n   * Returns the matrix mapped with softmax.\r\n   * @param {Matrix} z The matrix to apply the softmax function to\r\n   * @return {Matrix} The matrix mapped with softmax\r\n   */\r\n  static fn = (z) => {\r\n    let sum = 0;\r\n    for (let r = 0; r < z.rows; r++) {\r\n      sum += Math.exp(z.data[r][0]);\r\n    }\r\n    return Matrix.map(z, (z_i) => Math.exp(z_i) / sum);\r\n  };\r\n\r\n  /**\r\n   * Returns the softmax derivative of the given number.\r\n   * @param {Matrix} z The matrix to apply the softmax derivative function to\r\n   * @return {Matrix} The matrix mapped with softmax derivative\r\n   */\r\n  static derivative = (z) => {\r\n    const softmax = SoftmaxActivation.fn(z);\r\n    return softmax.mul(Matrix.map(softmax, (a_i) => 1 - a_i));\r\n  };\r\n}\r\n\r\n/**\r\n * The quadratic cost function and output layer error.\r\n */\r\nexport class QuadraticCost {\r\n  /**\r\n   * Returns the cost = sum over all (0.5 * (a - y)^2).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The cost\r\n   */\r\n  static fn = (a, y) => {\r\n    const diffMatrix = Matrix.sub(a, y);\r\n    let cost = 0;\r\n    for (let r = 0; r < diffMatrix.rows; r++) {\r\n      for (let c = 0; c < diffMatrix.cols; c++) {\r\n        cost += 0.5 * diffMatrix.data[r][c] ** 2;\r\n      }\r\n    }\r\n    return cost;\r\n  };\r\n\r\n  /**\r\n   * Returns the output error = (a - y) hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The output error\r\n   */\r\n  static outputError = (z, a, y, outputActivationFunction) => {\r\n    const costDerivativeWRTa = Matrix.sub(a, y);\r\n    return costDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  };\r\n}\r\n\r\nconst EPSILON = 10 ** -100;\r\n\r\n/**\r\n * The cross entropy cost function and output layer error.\r\n */\r\nexport class CrossEntropyCost {\r\n  /**\r\n   * Returns the cost = sum over all -(y * ln(a) + (1 - y) * ln(1 - a)).\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @return {number} The cost\r\n   */\r\n  static fn = (a, y) => {\r\n    const yIsOne = Matrix.mul(\r\n      Matrix.transpose(y),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 0, not doing log(0)\r\n        return Math.log(a_i + EPSILON);\r\n      })\r\n    );\r\n    const yIsZero = Matrix.mul(\r\n      Matrix.transpose(Matrix.map(y, (y_i) => 1 - y_i)),\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so if a_i = 1, not doing log(0)\r\n        return Math.log(1 - a_i + EPSILON);\r\n      })\r\n    );\r\n    return -(yIsOne.data[0][0] + yIsZero.data[0][0]);\r\n  };\r\n\r\n  /**\r\n   * Returns the output error = [(a - y) / (a * (1 - a))] hadamardProduct outputActivationFunctionDerivative(z).\r\n   * @param {Matrix} z The z of the output layer\r\n   * @param {Matrix} a The activation of the output layer\r\n   * @param {Matrix} y The desired output\r\n   * @param {Function} outputActivationFunction The activation function of the output layer\r\n   * @return {Matrix} The derivative with respect to a\r\n   */\r\n  static outputError = (z, a, y, outputActivationFunction) => {\r\n    const costDerivativeWRTa = Matrix.sub(a, y).mul(\r\n      Matrix.map(a, (a_i) => {\r\n        // Add small epsilon so never divide by zero\r\n        return 1 / (a_i * (1 - a_i) + EPSILON);\r\n      })\r\n    );\r\n    return costDerivativeWRTa.mul(outputActivationFunction.derivative(z));\r\n  };\r\n}\r\n\r\n/**\r\n * Fisher-Yates shuffle.\r\n * @param {Array} arr The array to shuffle\r\n * @return {Array} The shuffled array\r\n */\r\nexport const shuffle = (arr) => {\r\n  for (let i = arr.length - 1; i > 0; i--) {\r\n    const randomIndex = Math.floor(Math.random() * (i + 1));\r\n    const temp = arr[i];\r\n    arr[i] = arr[randomIndex];\r\n    arr[randomIndex] = temp;\r\n  }\r\n  return arr;\r\n};\r\n","import Matrix from \"./matrix\";\r\nimport {\r\n  SigmoidActivation,\r\n  ReLUActivation,\r\n  LeakyReLUActivation,\r\n  SoftmaxActivation,\r\n  QuadraticCost,\r\n  CrossEntropyCost,\r\n  shuffle,\r\n} from \"./helpers\";\r\n\r\nconst CHECK_GRADIENTS = false;\r\nconst LOG_MINI_BATCH_ACCURACY = false;\r\nconst LOG_MINI_BATCH_COST = false;\r\nconst OUTPUT_NETWORK = false;\r\n\r\nclass NeuralNetwork {\r\n  /**\r\n   * Creates a NeuralNetwork with the givens layer sizes or using the preset settings from the optional NeuralNetwork.\r\n   * @param {Array} sizes An array of layer sizes\r\n   * @param {NeuralNetwork} neuralNetwork Optional initial settings\r\n   */\r\n  constructor(sizes, neuralNetwork) {\r\n    if (neuralNetwork) {\r\n      // Deep copy\r\n      this.numLayers = neuralNetwork.sizes.length;\r\n      this.sizes = [];\r\n      for (let size of neuralNetwork.sizes) {\r\n        this.sizes.push(size);\r\n      }\r\n\r\n      // Copy bias vectors\r\n      this.biases = [];\r\n      for (let bias of neuralNetwork.biases) {\r\n        this.biases.push(new Matrix(null, null, bias));\r\n      }\r\n\r\n      // Copy weight matrices\r\n      this.weights = [];\r\n      for (let weight of neuralNetwork.weights) {\r\n        this.weights.push(new Matrix(null, null, weight));\r\n      }\r\n    } else {\r\n      this.numLayers = sizes.length;\r\n      this.sizes = sizes;\r\n\r\n      // Create bias vectors\r\n      this.biases = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const bias = new Matrix(sizes[i], 1);\r\n\r\n        // He initialization, biases = 0\r\n        bias.map((b) => 0);\r\n\r\n        this.biases.push(bias);\r\n      }\r\n\r\n      // Create weight matrices\r\n      this.weights = [];\r\n      for (let i = 1; i < sizes.length; i++) {\r\n        const weight = new Matrix(sizes[i], sizes[i - 1]);\r\n\r\n        // He initialization, weights random standard normal * sqrt(2 / # incoming connections)\r\n        weight.randomizeNormal();\r\n        weight.map((w) => w * Math.sqrt(2 / sizes[i - 1]));\r\n\r\n        this.weights.push(weight);\r\n      }\r\n    }\r\n\r\n    this.hiddenActivationFunction = ReLUActivation;\r\n    this.outputActivationFunction = SoftmaxActivation;\r\n    this.cost = CrossEntropyCost;\r\n  }\r\n\r\n  /**\r\n   * Performs feedforward and returns the result as an array.\r\n   * @param {Matrix} input The input as a Matrix object (vector)\r\n   * @return {Array} The result as an array\r\n   */\r\n  feedforward = (input) => {\r\n    let output = input;\r\n\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wx + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, output);\r\n      z.add(bias);\r\n      output =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n    }\r\n\r\n    return output.toArray();\r\n  };\r\n\r\n  /**\r\n   * Performs stochastic gradient descent with the specified hyperparameters.\r\n   * @param {Array} trainingDatas The array of training datas\r\n   * @param {number} epochs The number of epochs to train for\r\n   * @param {number} miniBatchSize The size of the mini batches\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {Array} testDatas The optional test datas\r\n   */\r\n  stochasticGradientDescent = (\r\n    trainingDatas,\r\n    epochs,\r\n    miniBatchSize,\r\n    learningRate,\r\n    regularization,\r\n    testDatas = null\r\n  ) => {\r\n    // Training datas = [trainingData == [Matrix(input), Matrix(desiredOutput)]]\r\n    const trainingDataSize = trainingDatas.length;\r\n\r\n    // Train for specified number of epochs\r\n    for (let i = 0; i < epochs; i++) {\r\n      // Shuffle the training datas every epoch\r\n      shuffle(trainingDatas);\r\n\r\n      // Mini batches = [miniBatch == [trainingData == [Matrix(input), Matrix(desiredOutput)]]]\r\n      const miniBatches = [];\r\n      for (let j = 0; j < trainingDataSize; j += miniBatchSize) {\r\n        // Mini batch = [trainingData == [Matrix(input), Matrix(desiredOutput)]]\r\n        const miniBatch = [];\r\n\r\n        // Training data = [Matrix(input), Matrix(desiredOutput)]\r\n        for (let k = j; k < j + miniBatchSize; k++) {\r\n          miniBatch.push(trainingDatas[k]);\r\n        }\r\n        miniBatches.push(miniBatch);\r\n      }\r\n\r\n      // Update each mini batch\r\n      for (let j = 0; j < miniBatches.length; j++) {\r\n        this.updateMiniBatch(\r\n          miniBatches[j],\r\n          learningRate,\r\n          regularization,\r\n          trainingDataSize\r\n        );\r\n\r\n        // Accuracy on test set\r\n        if (LOG_MINI_BATCH_ACCURACY) {\r\n          const accuracy = this.accuracy(testDatas);\r\n          console.log(\r\n            \"Testing mini batch \" +\r\n              (j + 1) +\r\n              \"/\" +\r\n              miniBatches.length +\r\n              \": \" +\r\n              accuracy +\r\n              \"/\" +\r\n              testDatas.length +\r\n              \", \" +\r\n              (100 * accuracy) / testDatas.length +\r\n              \"%\"\r\n          );\r\n        } else {\r\n          // Only log this if not doing the more detailed accuracy logging\r\n          console.log(\r\n            \"Finished mini batch \" + (j + 1) + \"/\" + miniBatches.length\r\n          );\r\n        }\r\n\r\n        // Cost on training set\r\n        if (LOG_MINI_BATCH_COST) {\r\n          const trainingCost = this.trainingCost(trainingDatas, regularization);\r\n          console.log(\r\n            \"Training cost: \" +\r\n              trainingCost[0] +\r\n              \", \" +\r\n              trainingCost[1] +\r\n              \"/\" +\r\n              trainingDatas.length +\r\n              \", \" +\r\n              (100 * trainingCost[1]) / trainingDatas.length +\r\n              \"%\"\r\n          );\r\n        }\r\n      }\r\n\r\n      // Testing\r\n      if (testDatas !== null) {\r\n        const accuracy = this.accuracy(testDatas);\r\n        console.log(\r\n          \"Testing epoch \" +\r\n            (i + 1) +\r\n            \"/\" +\r\n            epochs +\r\n            \": \" +\r\n            accuracy +\r\n            \"/\" +\r\n            testDatas.length +\r\n            \", \" +\r\n            (100 * accuracy) / testDatas.length +\r\n            \"%\"\r\n        );\r\n      }\r\n\r\n      if (OUTPUT_NETWORK) {\r\n        console.log(JSON.stringify(this));\r\n      }\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Updates the mini batch by getting the gradient and then applying it.\r\n   * @param {Array} miniBatch The mini batch of training data\r\n   * @param {number} learningRate The learning rate\r\n   * @param {number} regularization The regularization parameter\r\n   * @param {number} trainingDataSize The size of the training data set\r\n   */\r\n  updateMiniBatch = (\r\n    miniBatch,\r\n    learningRate,\r\n    regularization,\r\n    trainingDataSize\r\n  ) => {\r\n    // Cumulative gradients for mini batch\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Calculates the cumulative biases and weights gradients for all training data in the mini batch\r\n    for (let trainingData of miniBatch) {\r\n      const input = trainingData[0];\r\n      const desiredOutput = trainingData[1];\r\n      const gradientDelta = this.backpropagate(input, desiredOutput);\r\n      const biasesGradientDelta = gradientDelta[0];\r\n      const weightsGradientDelta = gradientDelta[1];\r\n\r\n      // Do gradient checking\r\n      if (CHECK_GRADIENTS) {\r\n        const biasesCheck = this.gradientCheck(\r\n          biasesGradientDelta,\r\n          this.biases,\r\n          input,\r\n          desiredOutput\r\n        );\r\n        console.log(\"Gradient check biases:\", biasesCheck);\r\n        const weightsCheck = this.gradientCheck(\r\n          weightsGradientDelta,\r\n          this.weights,\r\n          input,\r\n          desiredOutput\r\n        );\r\n        console.log(\"Gradient check weights:\", weightsCheck);\r\n      }\r\n\r\n      // Add gradient delta to miniBatch\r\n      for (let i = 0; i < this.numLayers - 1; i++) {\r\n        biasesGradient[i].add(biasesGradientDelta[i]);\r\n        weightsGradient[i].add(weightsGradientDelta[i]);\r\n      }\r\n    }\r\n\r\n    // Apply the cumulative biases and weights gradients to the network's biases and weights\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const learningRateWithAvg = learningRate / miniBatch.length;\r\n\r\n      // Bias adjustment by gradient, no regularization\r\n      this.biases[i].sub(biasesGradient[i].mul(learningRateWithAvg));\r\n\r\n      // Weight regularization\r\n      this.weights[i].mul(\r\n        1 - learningRate * (regularization / trainingDataSize)\r\n      );\r\n\r\n      // Weight adjustment by gradient\r\n      this.weights[i].sub(weightsGradient[i].mul(learningRateWithAvg));\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Performs backpropagation to calculate the gradient for one training data.\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} desiredOutput The desired output matrix\r\n   * @return {Array} The array consisting of the biasesGradient and weightsGradient for this one training data\r\n   */\r\n  backpropagate = (input, desiredOutput) => {\r\n    const biasesGradient = this.createEmptyGradient(this.biases);\r\n    const weightsGradient = this.createEmptyGradient(this.weights);\r\n\r\n    // Feedforward, store zs and activations by layer\r\n    const zs = [];\r\n    const activations = [input];\r\n    this.trainingFeedforward(zs, activations);\r\n\r\n    // Output error = costDerivativeWRTa hadamardProduct outputActivationFunctionDerivative(outputZ)\r\n    const outputError = this.cost.outputError(\r\n      zs[zs.length - 1],\r\n      activations[activations.length - 1],\r\n      desiredOutput,\r\n      this.outputActivationFunction\r\n    );\r\n\r\n    // Output biasesGradient is simply the output error\r\n    biasesGradient[biasesGradient.length - 1] = outputError;\r\n\r\n    // Output weightsGradient = outputError * beforeOutputActivationTranspose\r\n    weightsGradient[weightsGradient.length - 1] = Matrix.mul(\r\n      outputError,\r\n      Matrix.transpose(activations[activations.length - 2])\r\n    );\r\n\r\n    // Backpropagate error to hidden layers\r\n    let hiddenError = outputError;\r\n    for (let i = 2; i < this.numLayers; i++) {\r\n      // Hidden error = (nextWeightsTranspose * nextError which is last pass's hidden error) hadamardProduct hiddenActivationFunctionDerivative(z)\r\n      const nextWeightsTranspose = Matrix.transpose(\r\n        this.weights[this.weights.length - i + 1]\r\n      );\r\n      const hiddenActivationFunctionDerivative = this.hiddenActivationFunction.derivative(\r\n        zs[zs.length - i]\r\n      );\r\n      hiddenError = Matrix.mul(nextWeightsTranspose, hiddenError).mul(\r\n        hiddenActivationFunctionDerivative\r\n      );\r\n\r\n      // Hidden biasesGradient is simply the hidden error\r\n      biasesGradient[biasesGradient.length - i] = hiddenError;\r\n\r\n      // Hidden weightsGradient = hiddenError * beforeHiddenActivationsTranspose\r\n      weightsGradient[weightsGradient.length - i] = Matrix.mul(\r\n        hiddenError,\r\n        Matrix.transpose(activations[activations.length - i - 1])\r\n      );\r\n    }\r\n\r\n    return [biasesGradient, weightsGradient];\r\n  };\r\n\r\n  /**\r\n   * Feedforward, but also keeping record of the z's and activations per layer.\r\n   * @param {Array} zs The array to store the z records\r\n   * @param {Array} activations The array to store the activation records\r\n   */\r\n  trainingFeedforward = (zs, activations) => {\r\n    for (let i = 0; i < this.numLayers - 1; i++) {\r\n      const bias = this.biases[i];\r\n      const weight = this.weights[i];\r\n\r\n      // z = wa + b, a = activationFunction(z)\r\n      const z = Matrix.mul(weight, activations[i]);\r\n      z.add(bias);\r\n      zs.push(z);\r\n\r\n      const a =\r\n        i === this.numLayers - 2\r\n          ? this.outputActivationFunction.fn(z)\r\n          : this.hiddenActivationFunction.fn(z);\r\n      activations.push(a);\r\n    }\r\n  };\r\n\r\n  /**\r\n   * Creates an empty gradient with the target array's shape.\r\n   * @param {Array} target The target array\r\n   * @return {Array} The empty gradient array with in the shape of the target array\r\n   */\r\n  createEmptyGradient = (target) => {\r\n    const gradient = [];\r\n    for (let targetMatrix of target) {\r\n      const gradientMatrix = new Matrix(targetMatrix.rows, targetMatrix.cols);\r\n      gradient.push(gradientMatrix);\r\n    }\r\n    return gradient;\r\n  };\r\n\r\n  /**\r\n   * Returns a count of how many test cases were passed.\r\n   * @param {Array} testDatas The array of test datas\r\n   * @return {number} The number of test cases passed\r\n   */\r\n  accuracy = (testDatas) => {\r\n    let count = 0;\r\n\r\n    for (let testData of testDatas) {\r\n      const input = testData[0];\r\n      const outputArr = this.feedforward(input);\r\n      const desiredOutputArr = testData[1].toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const desiredOutputInteger = desiredOutputArr.indexOf(\r\n        Math.max(...desiredOutputArr)\r\n      );\r\n\r\n      // Count number correct\r\n      if (outputInteger === desiredOutputInteger) {\r\n        count++;\r\n      }\r\n    }\r\n\r\n    return count;\r\n  };\r\n\r\n  /**\r\n   * Returns the training cost and correct count for the data set using the regularization parameter.\r\n   * @param {Array} datas The array of data to get the training cost for\r\n   * @param {number} regularization The regularization parameter\r\n   * @return {Array} The training cost and correct count\r\n   */\r\n  trainingCost = (datas, regularization) => {\r\n    let cost = 0;\r\n    let count = 0;\r\n\r\n    // Add cost of each data point\r\n    for (let data of datas) {\r\n      const input = data[0];\r\n      const desiredOutput = data[1];\r\n\r\n      const outputArr = this.feedforward(input);\r\n      const desiredOutputArr = desiredOutput.toArray();\r\n      const outputInteger = outputArr.indexOf(Math.max(...outputArr));\r\n      const desiredOutputInteger = desiredOutputArr.indexOf(\r\n        Math.max(...desiredOutputArr)\r\n      );\r\n\r\n      // Count correct\r\n      if (outputInteger === desiredOutputInteger) {\r\n        count++;\r\n      }\r\n\r\n      // Output cost\r\n      cost +=\r\n        this.cost.fn(Matrix.vectorFromArray(outputArr), desiredOutput) /\r\n        datas.length;\r\n\r\n      // Regularization cost\r\n      let squaredWeights = 0;\r\n      for (let weight of this.weights) {\r\n        for (let r = 0; r < weight.rows; r++) {\r\n          for (let c = 0; c < weight.cols; c++) {\r\n            squaredWeights += weight.data[r][c] ** 2;\r\n          }\r\n        }\r\n      }\r\n      cost += 0.5 * (regularization / datas.length) * squaredWeights;\r\n    }\r\n\r\n    return [cost, count];\r\n  };\r\n\r\n  /**\r\n   * Performs gradient checking technique, manually calculating the gradient using the limit definition the derivative and a small epsilon.\r\n   * @param {Array} gradient The gradient to check\r\n   * @param {Array} target A reference to the neural network's biases or weights\r\n   * @param {Matrix} input The input matrix\r\n   * @param {Matrix} desiredOutput The desired output matrix\r\n   * @return {number} The euclidean norm ratio which should be less than 10^-7\r\n   */\r\n  gradientCheck = (gradient, target, input, desiredOutput) => {\r\n    const desiredArr = desiredOutput.toArray();\r\n    const epsilon = Math.pow(10, -7);\r\n    const gradApprox = this.createEmptyGradient(gradient);\r\n\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          // Save the original bias or weight value to restore it at the end\r\n          const original = target[i].data[r][c];\r\n\r\n          // Calculate the cost with plus epsilon\r\n          target[i].data[r][c] = original + epsilon;\r\n          const outputPlus = this.feedforward(input);\r\n          let costPlus = 0;\r\n          for (let j = 0; j < outputPlus.length; j++) {\r\n            costPlus += 0.5 * Math.pow(desiredArr[j] - outputPlus[j], 2);\r\n          }\r\n\r\n          // Calculate the cost with minus epsilon\r\n          target[i].data[r][c] = original - epsilon;\r\n          const outputMinus = this.feedforward(input);\r\n          let costMinus = 0;\r\n          for (let j = 0; j < outputMinus.length; j++) {\r\n            costMinus += 0.5 * Math.pow(desiredArr[j] - outputMinus[j], 2);\r\n          }\r\n\r\n          // Limit definition of derivative\r\n          const gradApproxVal = (costPlus - costMinus) / (2 * epsilon);\r\n          gradApprox[i].data[r][c] = gradApproxVal;\r\n\r\n          // Restore the initial bias or weight value\r\n          target[i].data[r][c] = original;\r\n        }\r\n      }\r\n    }\r\n\r\n    let paramSum = 0;\r\n    let paramApproxSum = 0;\r\n    let errorSum = 0;\r\n\r\n    // Sum all Euclidean components\r\n    for (let i = 0; i < gradApprox.length; i++) {\r\n      for (let r = 0; r < gradApprox[i].rows; r++) {\r\n        for (let c = 0; c < gradApprox[i].cols; c++) {\r\n          const gradientVal = gradient[i].data[r][c];\r\n          const gradApproxVal = gradApprox[i].data[r][c];\r\n\r\n          paramSum += Math.pow(gradientVal, 2);\r\n          paramApproxSum += Math.pow(gradApproxVal, 2);\r\n          errorSum += Math.pow(gradApproxVal - gradientVal, 2);\r\n        }\r\n      }\r\n    }\r\n\r\n    return (\r\n      Math.sqrt(errorSum) / (Math.sqrt(paramApproxSum) + Math.sqrt(paramSum))\r\n    );\r\n  };\r\n\r\n  /**\r\n   * Automation for choosing the regularization parameter.\r\n   * @param {Array} trainingDatas The array of training datas\r\n   * @param {Array} crossValDatas The array of cross validation datas\r\n   * @param {Array} testDatas The array of testing datas\r\n   */\r\n  static chooseHypeparameters = (trainingDatas, crossValDatas, testDatas) => {\r\n    const miniBatchOptions = [1, 10, 20, 50, 100];\r\n    const learningRateOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    const regularizationOptions = [0.01, 0.03, 0.1, 0.3, 1, 3, 10];\r\n    let bestMiniBatch = 1;\r\n    let bestLearningRate = 0.01;\r\n    let bestRegularization = 0.01;\r\n    let bestAccuracy = 0;\r\n    let bestNetwork = null;\r\n\r\n    // Train a different model for each combination of options\r\n    for (let i = 0; i < miniBatchOptions.length; i++) {\r\n      for (let j = 0; j < learningRateOptions.length; j++) {\r\n        for (let k = 0; k < regularizationOptions.length; k++) {\r\n          const curMiniBatch = miniBatchOptions[i];\r\n          const curLearningRate = learningRateOptions[j];\r\n          const curRegularization = regularizationOptions[k];\r\n\r\n          // Train the network using the current settings\r\n          const curNetwork = new NeuralNetwork([784, 30, 10]);\r\n          curNetwork.stochasticGradientDescent(\r\n            trainingDatas,\r\n            1,\r\n            curMiniBatch,\r\n            curLearningRate,\r\n            curRegularization\r\n          );\r\n\r\n          // Evaluate accuracy using cross validation set\r\n          const crossValAccuracy = curNetwork.accuracy(crossValDatas);\r\n\r\n          // Choose best neural network based on cross validation set\r\n          if (crossValAccuracy > bestAccuracy) {\r\n            bestMiniBatch = curMiniBatch;\r\n            bestLearningRate = curLearningRate;\r\n            bestRegularization = curRegularization;\r\n            bestAccuracy = crossValAccuracy;\r\n            bestNetwork = curNetwork;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    console.log(\"Best mini batch size: \" + bestMiniBatch);\r\n    console.log(\"Best learning rate: \" + bestLearningRate);\r\n    console.log(\"Best regularization: \" + bestRegularization);\r\n    console.log(\r\n      \"Best cross validation set: \" +\r\n        bestAccuracy +\r\n        \"/\" +\r\n        crossValDatas.length +\r\n        \", \" +\r\n        (100 * bestAccuracy) / crossValDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Test the generalization of the selected network on the test set\r\n    const generalizationAccuracy = bestNetwork.accuracy(testDatas);\r\n    console.log(\r\n      \"Best test set: \" +\r\n        generalizationAccuracy +\r\n        \"/\" +\r\n        testDatas.length +\r\n        \", \" +\r\n        (100 * generalizationAccuracy) / testDatas.length +\r\n        \"%\"\r\n    );\r\n\r\n    // Log the best neural network\r\n    console.log(\"Best network:\", JSON.stringify(bestNetwork));\r\n  };\r\n}\r\n\r\nexport default NeuralNetwork;\r\n","/**\r\n * Loads the MNIST data.\r\n * @param {function} callback The callback function to be called when loading is finished\r\n * @return {Promise} The resolved promise\r\n */\r\nfunction loadMNIST(callback) {\r\n  let mnist = {};\r\n  let files = {\r\n    trainingImages: \"./train-images.idx3-ubyte\",\r\n    trainingLabels: \"./train-labels.idx1-ubyte\",\r\n    testImages: \"./t10k-images.idx3-ubyte\",\r\n    testLabels: \"./t10k-labels.idx1-ubyte\",\r\n  };\r\n  return Promise.all(\r\n    Object.keys(files).map(async (file) => {\r\n      mnist[file] = await loadFile(files[file]);\r\n    })\r\n  ).then(() => callback(mnist));\r\n}\r\n\r\n/**\r\n * Parses the MNIST file into an array of data.\r\n * @param {string} file The filename\r\n * @return {Array} The MNIST data\r\n */\r\nasync function loadFile(file) {\r\n  let response = await fetch(file);\r\n  let buffer = await response.arrayBuffer();\r\n  let headerCount = 4;\r\n  let headerView = new DataView(buffer, 0, 4 * headerCount);\r\n  let headers = new Array(file, headerCount)\r\n    .fill()\r\n    .map((_, i) => headerView.getUint32(4 * i, false));\r\n\r\n  let type, dataLength;\r\n  if (headers[0] === 2049) {\r\n    type = \"label\";\r\n    dataLength = 1;\r\n    headerCount = 2;\r\n  } else if (headers[0] === 2051) {\r\n    type = \"image\";\r\n    dataLength = headers[2] * headers[3];\r\n  } else {\r\n    throw new Error(\"Unknown file type \" + headers[0]);\r\n  }\r\n\r\n  let data = new Uint8Array(buffer, headerCount * 4);\r\n  if (type === \"image\") {\r\n    let dataArr = [];\r\n    for (let i = 0; i < headers[1]; i++) {\r\n      dataArr.push(data.subarray(dataLength * i, dataLength * (i + 1)));\r\n    }\r\n    console.log(\"Loaded file:\", file);\r\n    return dataArr;\r\n  }\r\n  console.log(\"Loaded file:\", file);\r\n  return data;\r\n}\r\n\r\nexport default loadMNIST;\r\n","import React, { Component } from \"react\";\nimport Title from \"./components/title\";\nimport Description from \"./components/description\";\nimport Sketch from \"./components/sketch\";\nimport Button from \"./components/button\";\nimport RangeInput from \"./components/range-input\";\nimport Label from \"./components/label\";\nimport NeuralNetwork from \"./logic/neural-network\";\nimport Matrix from \"./logic/matrix\";\nimport loadMNIST from \"./logic/mnist\";\nimport neuralNetworkPretrained from \"./neural-network-pretrained.json\";\nimport GithubCorner from \"react-github-corner\";\n\nconst OUTPUT_MNIST = false;\nconst NUM_TRAINING = 50000;\nconst NUM_CROSS_VAL = 10000;\nconst NUM_TESTING = 10000;\nconst STANDARDIZATION_OVER_NORMALIZATION = true;\nconst EPSILON = 10 ** -100;\nconst INCLUDE_CROSS_VAL_SET = false;\n\nclass App extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      epochs: 0,\n      guess: \"\",\n      pixels: Array(784).fill(0),\n      clearRequested: false,\n      isTraining: false,\n      usePretrained: true,\n      outputArr: [],\n      trainingSize: 5000,\n    };\n\n    this.dataFormatted = false;\n    loadMNIST((data) => {\n      this.mnist = data;\n      this.neuralNetwork = new NeuralNetwork(null, neuralNetworkPretrained);\n      console.log(\"All files loaded\");\n\n      if (OUTPUT_MNIST) {\n        console.log(this.mnist);\n      }\n    });\n  }\n\n  handleClickTrain = () => {\n    if (this.neuralNetwork !== undefined) {\n      this.setState({ isTraining: true });\n\n      this.timer = setTimeout(() => {\n        // Only need to format if the current setting disagrees OR it's the first time formatting\n        if (\n          this.neuralNetwork.standardizationOverNormalization !==\n            STANDARDIZATION_OVER_NORMALIZATION ||\n          !this.alreadyFormatted\n        ) {\n          this.formatData();\n          if (STANDARDIZATION_OVER_NORMALIZATION) {\n            this.standardizeData();\n          } else {\n            this.normalizeData();\n          }\n          this.alreadyFormatted = true;\n        }\n\n        console.log(\"Starting training\");\n        this.neuralNetwork.stochasticGradientDescent(\n          this.trainingDatas.slice(0, this.state.trainingSize),\n          1,\n          10,\n          0.03,\n          1.0,\n          this.testDatas\n        );\n\n        // NeuralNetwork.chooseHypeparameters(\n        //   this.trainingDatas,\n        //   this.crossValDatas,\n        //   this.testDatas\n        // );\n\n        this.setState((prevState) => ({\n          epochs: prevState.epochs + 1,\n          isTraining: false,\n        }));\n\n        clearTimeout(this.timer);\n      }, 250);\n    }\n  };\n\n  formatData() {\n    console.log(\"Formatting training data\");\n    this.trainingDatas = this.loadDatas(\n      this.mnist.trainingImages.slice(0, NUM_TRAINING),\n      this.mnist.trainingLabels.slice(0, NUM_TRAINING)\n    );\n\n    if (INCLUDE_CROSS_VAL_SET) {\n      console.log(\"Formatting cross validation data\");\n      this.crossValDatas = this.loadDatas(\n        this.mnist.trainingImages.slice(\n          NUM_TRAINING,\n          NUM_TRAINING + NUM_CROSS_VAL\n        ),\n        this.mnist.trainingLabels.slice(\n          NUM_TRAINING,\n          NUM_TRAINING + NUM_CROSS_VAL\n        )\n      );\n    }\n\n    console.log(\"Formatting testing data\");\n    this.testDatas = this.loadDatas(\n      this.mnist.testImages.slice(0, NUM_TESTING),\n      this.mnist.testLabels.slice(0, NUM_TESTING)\n    );\n  }\n\n  loadDatas = (images, labels) => {\n    const datas = [];\n\n    for (let i = 0; i < images.length; i++) {\n      const inputArr = images[i];\n      const desiredInteger = labels[i];\n      const desiredArr = [];\n\n      for (let j = 0; j < 10; j++) {\n        if (desiredInteger === j) {\n          desiredArr.push(1);\n        } else {\n          desiredArr.push(0);\n        }\n      }\n\n      datas.push([\n        Matrix.vectorFromArray(inputArr),\n        Matrix.vectorFromArray(desiredArr),\n      ]);\n    }\n\n    return datas;\n  };\n\n  standardizeData = () => {\n    // Neural network does NOT have predefined training mean and STD, calculate them and use that to standardize everything\n    if (!this.neuralNetwork.hasOwnProperty(\"trainingMean\")) {\n      const mean = new Matrix(784, 1); // mean = sum(pixels) / numTraining\n      const std = new Matrix(784, 1); // std = sqrt(sum((pixels - mean)^2) / numTraining)\n\n      // Calculate sum(pixels)\n      console.log(\"Calculating training data mean\");\n      for (let trainingData of this.trainingDatas) {\n        mean.add(trainingData[0]);\n      }\n\n      // Divide by total number of training datas\n      mean.map((x) => x / this.trainingDatas.length);\n\n      // Calculate sum((pixels - mean)^2)\n      console.log(\"Calculating training data standard deviation\");\n      for (let trainingData of this.trainingDatas) {\n        std.add(Matrix.sub(trainingData[0], mean).map((x) => x ** 2));\n      }\n\n      // Divide by total number of training datas and square root\n      std.map((x) => Math.sqrt(x / this.trainingDatas.length));\n\n      // Save to neural network\n      this.neuralNetwork.trainingMean = mean;\n      this.neuralNetwork.trainingSTD = std;\n    }\n\n    // Retrieve mean and std from neural network\n    const mean = this.neuralNetwork.trainingMean;\n    const std = this.neuralNetwork.trainingSTD;\n\n    // Standardize training images, add small epsilon so never divide by zero\n    console.log(\"Standardizing training data\");\n    for (let i = 0; i < this.trainingDatas.length; i++) {\n      this.trainingDatas[i][0]\n        .sub(mean)\n        .div(Matrix.map(std, (x) => x + EPSILON));\n    }\n\n    if (INCLUDE_CROSS_VAL_SET) {\n      // Standardize validation images, add small epsilon so never divide by zero\n      console.log(\"Standardizing cross validation data\");\n      for (let i = 0; i < this.crossValDatas.length; i++) {\n        this.crossValDatas[i][0]\n          .sub(mean)\n          .div(Matrix.map(std, (x) => x + EPSILON));\n      }\n    }\n\n    // Standardize test images, add small epsilon so never divide by zero\n    console.log(\"Standardizing testing data\");\n    for (let i = 0; i < this.testDatas.length; i++) {\n      this.testDatas[i][0].sub(mean).div(Matrix.map(std, (x) => x + EPSILON));\n    }\n\n    this.neuralNetwork.standardizationOverNormalization = true;\n  };\n\n  normalizeData = () => {\n    // Normalize training images\n    for (let trainingData of this.trainingDatas) {\n      trainingData[0].div(255);\n    }\n\n    if (INCLUDE_CROSS_VAL_SET) {\n      // Normalize validation images\n      for (let crossValData of this.crossValDatas) {\n        crossValData[0].div(255);\n      }\n    }\n\n    // Normalize test images\n    for (let testData of this.testDatas) {\n      testData[0].div(255);\n    }\n\n    this.neuralNetwork.standardizationOverNormalization = false;\n  };\n\n  handleClickGuess = () => {\n    if (this.neuralNetwork !== undefined) {\n      const input = Matrix.vectorFromArray(this.state.pixels);\n\n      // Standardize or normalize input pixels\n      if (this.neuralNetwork.standardizationOverNormalization) {\n        input\n          .sub(this.neuralNetwork.trainingMean)\n          .div(Matrix.map(this.neuralNetwork.trainingSTD, (x) => x + EPSILON));\n      } else {\n        input.div(255);\n      }\n\n      const outputArr = this.neuralNetwork.feedforward(input);\n      const guess = outputArr.indexOf(Math.max(...outputArr));\n\n      // Update state about guess and displayed probabilities\n      this.setState({\n        guess,\n        outputArr,\n      });\n    }\n  };\n\n  handleClickClear = () => {\n    this.setState({ clearRequested: true });\n  };\n\n  handleClear = () => {\n    this.setState({\n      pixels: Array(784).fill(0),\n      clearRequested: false,\n      guess: \"\",\n      outputArr: [],\n    });\n  };\n\n  handleDraw = (pixels) => {\n    this.setState({\n      pixels,\n    });\n  };\n\n  handleSwitchChange = () => {\n    this.setState(\n      (prevState) => ({ usePretrained: !prevState.usePretrained }),\n      () => {\n        this.neuralNetwork = this.state.usePretrained\n          ? new NeuralNetwork(null, neuralNetworkPretrained)\n          : new NeuralNetwork([784, 30, 10]);\n        this.setState({ epochs: 0 });\n      }\n    );\n  };\n\n  updateTrainingSize = (e) => {\n    this.setState({ trainingSize: Number(e.target.value) });\n  };\n\n  render() {\n    const probabilities = this.state.outputArr.map((probability, number) => (\n      <h5 key={number}>\n        {number}: {(probability * 100).toFixed(1)}%\n      </h5>\n    ));\n\n    return (\n      <div className=\"App container text-center pt-5\">\n        <div className=\"row\">\n          <div className=\"col\">\n            <Title text=\"Handwritten Digits Neural Network\" />\n          </div>\n        </div>\n        <div className=\"row\">\n          <div className=\"col\">\n            <Description\n              text={\n                \"Recognizes handwritten digits using a neural network.\\nDraw a number from 0 to 9 and have the neural network guess what you drew.\\nTry to center and scale your drawing to fill the majority of the canvas.\\nYou can train the neural network with the specified training size for an epoch.\\n*Open the console for training progress.\\nOr you can just use the pre-trained neural network.\"\n              }\n            />\n          </div>\n        </div>\n        <div className=\"row justify-content-center pt-3\">\n          <div className=\"col custom-control custom-switch\">\n            <input\n              type=\"checkbox\"\n              className=\"custom-control-input\"\n              id=\"customSwitch\"\n              checked={this.state.usePretrained}\n              onChange={this.handleSwitchChange}\n            />\n            <label className=\"custom-control-label\" htmlFor=\"customSwitch\">\n              Use pre-trained neural network\n            </label>\n          </div>\n        </div>\n        <div className=\"row justify-content-center pt-3\">\n          <div className=\"col col-lg-4\">\n            <div className=\"row\">\n              <div className=\"col\">\n                <RangeInput\n                  min={1000}\n                  max={50000}\n                  step={1000}\n                  defaultValue={this.state.trainingSize}\n                  id=\"trainingSize\"\n                  onChange={this.updateTrainingSize}\n                />\n              </div>\n            </div>\n            <div className=\"row\">\n              <div className=\"col\">\n                <Label text=\"Training size\" value={this.state.trainingSize} />\n              </div>\n            </div>\n          </div>\n        </div>\n        <div className=\"row justify-content-center pt-3\">\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button\n              value=\"Train\"\n              loadingValue=\"Training...\"\n              isLoading={this.state.isTraining}\n              onClick={this.handleClickTrain}\n            />\n          </div>\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Guess\" onClick={this.handleClickGuess} />\n          </div>\n          <div className=\"col-4 col-md-3 col-xl-2\">\n            <Button value=\"Clear\" onClick={this.handleClickClear} />\n          </div>\n        </div>\n        <div className=\"row pt-3\">\n          <div className=\"col\">\n            <Sketch\n              width={500}\n              height={500}\n              onDraw={(pixels) => this.handleDraw(pixels)}\n              clearRequested={this.state.clearRequested}\n              onClear={this.handleClear}\n            />\n          </div>\n        </div>\n        <div className=\"row justify-content-center\">\n          <div className=\"col-6 col-lg-4\">\n            <h5>Epochs: {this.state.epochs}</h5>\n          </div>\n          <div className=\"col-6 col-lg-4\">\n            <h5>Guess: {this.state.guess}</h5>\n          </div>\n        </div>\n        <div className=\"row justify-content-center pb-5\">\n          <div className=\"col\">{probabilities}</div>\n        </div>\n        <GithubCorner\n          href=\"https://github.com/ryantran2165/handwritten-digits-neural-network\"\n          bannerColor=\"#222\"\n          octoColor=\"#7fffd4\"\n          target=\"_blank\"\n        />\n      </div>\n    );\n  }\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.0/8 are considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl, {\n    headers: { 'Service-Worker': 'script' }\n  })\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport App from \"./App\";\nimport * as serviceWorker from \"./serviceWorker\";\nimport \"bootstrap/dist/css/bootstrap.css\";\nimport \"./index.scss\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}